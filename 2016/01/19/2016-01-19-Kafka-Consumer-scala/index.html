<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Kafka源码分析 Consumer | zqhxuyuan</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Kafka Consumer">
<meta property="og:type" content="article">
<meta property="og:title" content="Kafka源码分析 Consumer">
<meta property="og:url" content="http://github.com/zqhxuyuan/2016/01/19/2016-01-19-Kafka-Consumer-scala/index.html">
<meta property="og:site_name" content="zqhxuyuan">
<meta property="og:description" content="Kafka Consumer">
<meta property="og:image" content="http://img.blog.csdn.net/20160126150532822">
<meta property="og:image" content="http://img.blog.csdn.net/20160125104919159">
<meta property="og:image" content="http://img.blog.csdn.net/20160125104937050">
<meta property="og:image" content="http://img.blog.csdn.net/20160126084058247">
<meta property="og:image" content="http://img.blog.csdn.net/20160126084038512">
<meta property="og:image" content="http://img.blog.csdn.net/20160126084015605">
<meta property="og:image" content="http://img.blog.csdn.net/20160126084118702">
<meta property="og:image" content="http://img.blog.csdn.net/20160126162107763">
<meta property="og:updated_time" content="2016-01-26T09:04:10.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Kafka源码分析 Consumer">
<meta name="twitter:description" content="Kafka Consumer">
  
    <link rel="alternative" href="/atom.xml" title="zqhxuyuan" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link rel="stylesheet" href="/css/style.css" type="text/css">
  <link rel="stylesheet" href="/font-awesome/css/font-awesome.min.css">
  <link rel="apple-touch-icon" href="/apple-touch-icon.png">
</head>
<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			
			<img lazy-src="https://avatars1.githubusercontent.com/u/1088525?v=3&amp;s=180" class="js-avatar">
			
		</a>

		<hgroup>
		  <h1 class="header-author"><a href="/">任何忧伤,都抵不过世界的美丽</a></h1>
		</hgroup>

		
				


		
			<div id="switch-btn" class="switch-btn">
				<div class="icon">
					<div class="icon-ctn">
						<div class="icon-wrap icon-house" data-idx="0">
							<div class="birdhouse"></div>
							<div class="birdhouse_holes"></div>
						</div>
						<div class="icon-wrap icon-ribbon hide" data-idx="1">
							<div class="ribbon"></div>
						</div>
						
						
						<div class="icon-wrap icon-me hide" data-idx="3">
							<div class="user"></div>
							<div class="shoulder"></div>
						</div>
						
					</div>
					
				</div>
				<div class="tips-box hide">
					<div class="tips-arrow"></div>
					<ul class="tips-inner">
						<li>菜单</li>
						<li>标签</li>
						
						
						<li>关于我</li>
						
					</ul>
				</div>
			</div>
		

		<div id="switch-area" class="switch-area">
			<div class="switch-wrap">
				<section class="switch-part switch-part1">
					<nav class="header-menu">
						<ul>
						
							<li><a href="/">主页</a></li>
				        
							<li><a href="/archives/">归档</a></li>
				        
							<li><a href="/tags/">标签</a></li>
				        
							<li><a href="/about/">关于</a></li>
				        
						</ul>
					</nav>
					<nav class="header-nav">
						<ul class="social">
							
								<li id="新浪微博"><a class="新浪微博" target="_blank" href="http://weibo.com/xuyuantree" title="新浪微博"></a></li>
					        
								<li id="GitHub"><a class="GitHub" target="_blank" href="http://github.com/zqhxuyuan" title="GitHub"></a></li>
					        
						</ul>
					</nav>
				</section>
				
				
				<section class="switch-part switch-part2">
					<div class="widget tagcloud" id="js-tagcloud">
						<a href="/tags/apex/" style="font-size: 10px;">apex</a> <a href="/tags/cassandra/" style="font-size: 18.33px;">cassandra</a> <a href="/tags/clojure/" style="font-size: 10px;">clojure</a> <a href="/tags/drill/" style="font-size: 18.33px;">drill</a> <a href="/tags/druid/" style="font-size: 15px;">druid</a> <a href="/tags/elasticsearch/" style="font-size: 10px;">elasticsearch</a> <a href="/tags/geode/" style="font-size: 10px;">geode</a> <a href="/tags/hbase/" style="font-size: 16.67px;">hbase</a> <a href="/tags/ignite/" style="font-size: 10px;">ignite</a> <a href="/tags/kafka/" style="font-size: 20px;">kafka</a> <a href="/tags/redis/" style="font-size: 10px;">redis</a> <a href="/tags/scala/" style="font-size: 13.33px;">scala</a> <a href="/tags/spark/" style="font-size: 15px;">spark</a> <a href="/tags/storm/" style="font-size: 16.67px;">storm</a> <a href="/tags/timeseries/" style="font-size: 13.33px;">timeseries</a> <a href="/tags/translate/" style="font-size: 10px;">translate</a> <a href="/tags/work/" style="font-size: 11.67px;">work</a>
					</div>
				</section>
				
				
				

				
				
				<section class="switch-part switch-part3">
				
					<div id="js-aboutme">BIG(DATA)</div>
				</section>
				
			</div>
		</div>
	</header>				
</div>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
  	<div class="overlay">
  		<div class="slider-trigger"></div>
  		<h1 class="header-author js-mobile-header hide"><a href="/" title="回到主页">任何忧伤,都抵不过世界的美丽</a></h1>
  	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<a href="/" class="profilepic">
				<img lazy-src="https://avatars1.githubusercontent.com/u/1088525?v=3&amp;s=180" class="js-avatar">
			</a>
			<hgroup>
			  <h1 class="header-author"><a href="/" title="回到主页">任何忧伤,都抵不过世界的美丽</a></h1>
			</hgroup>
			
			<nav class="header-menu">
				<ul>
				
					<li><a href="/">主页</a></li>
		        
					<li><a href="/archives/">归档</a></li>
		        
					<li><a href="/tags/">标签</a></li>
		        
					<li><a href="/about/">关于</a></li>
		        
		        <div class="clearfix"></div>
				</ul>
			</nav>
			<nav class="header-nav">
						<ul class="social">
							
								<li id="新浪微博"><a class="新浪微博" target="_blank" href="http://weibo.com/xuyuantree" title="新浪微博"></a></li>
					        
								<li id="GitHub"><a class="GitHub" target="_blank" href="http://github.com/zqhxuyuan" title="GitHub"></a></li>
					        
						</ul>
			</nav>
		</header>				
	</div>
</nav>
      <div class="body-wrap"><article id="post-2016-01-19-Kafka-Consumer-scala" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/01/19/2016-01-19-Kafka-Consumer-scala/" class="article-date">
  	<time datetime="2016-01-18T16:00:00.000Z" itemprop="datePublished">2016-01-19</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Kafka源码分析 Consumer
    </h1>
  

      </header>
      
      <div class="article-info article-info-post">
        
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/Source/">Source</a>
	</div>


        
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/kafka/">kafka</a></li></ul>
	</div>

        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <p>Kafka Consumer<br><a id="more"></a></p>
<h2 id="Consumer_Example(old_and_high-level)">Consumer Example(old and high-level)</h2><p>消费者示例, 指定要消费的topic和线程数,返回每个topic对应的KafkaStream列表,每个线程对应一个KafkaStream.<br>下面的示例中只使用了一个线程,所以通过streams.get(0)获取到该线程对应的KafkaStream.然后从流中读取出消息.    </p>
<p>topicCountMap表示客户端可以同时消费多个topic,那为什么要设置线程数呢? 因为一个topic有多个partition分布在<br>多个broker节点上.即使是同一个broker,也可能有这个topic的多个partition. 用不同的线程来隔离不同的partition.   </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">ConsumerConfig conf = <span class="keyword">new</span> ConsumerConfig(props);</span><br><span class="line">ConsumerConnector consumer = kafka.consumer.Consumer.createJavaConsumerConnector(conf);</span><br><span class="line">Map&lt;String, Integer&gt; topicCountMap = <span class="keyword">new</span> HashMap&lt;String, Integer&gt;();</span><br><span class="line">topicCountMap.put(topic, <span class="keyword">new</span> Integer(<span class="number">1</span>));</span><br><span class="line">Map&lt;String, List&lt;KafkaStream&lt;<span class="keyword">byte</span>[], <span class="keyword">byte</span>[]&gt;&gt;&gt; consumerMap = consumer.createMessageStreams(topicCountMap);</span><br><span class="line"></span><br><span class="line">List&lt;KafkaStream&lt;<span class="keyword">byte</span>[], <span class="keyword">byte</span>[]&gt;&gt; streams = consumerMap.get(topic);</span><br><span class="line">KafkaStream&lt;<span class="keyword">byte</span>[], <span class="keyword">byte</span>[]&gt; stream = streams.get(<span class="number">0</span>); </span><br><span class="line">ConsumerIterator&lt;<span class="keyword">byte</span>[], <span class="keyword">byte</span>[]&gt; it = stream.iterator();</span><br><span class="line"><span class="keyword">while</span> (it.hasNext())&#123;</span><br><span class="line">    System.out.println(<span class="string">"message: "</span> + <span class="keyword">new</span> String(it.next().message()));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="ConsumerConnector">ConsumerConnector</h2><p>Consumer定义在ConsumerConnector接口同一个文件中. 它默认创建的ConsumerConnector是基于ZK的ZookeeperConsumerConnector  </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Consumer</span> <span class="keyword"><span class="keyword">extends</span></span> <span class="title">Logging</span> &#123;</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">createJavaConsumerConnector</span>(</span>config: <span class="type">ConsumerConfig</span>): kafka.javaapi.consumer.<span class="type">ConsumerConnector</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> consumerConnect = <span class="keyword">new</span> kafka.javaapi.consumer.<span class="type">ZookeeperConsumerConnector</span>(config)</span><br><span class="line">    consumerConnect</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>ConsumerConnector主要有创建消息流(createMessageStreams)和提交offset(commitOffsets)两种方法.<br>Consumer会根据消息流消费数据, 并且定时提交offset.由客户端自己保存offset是kafka采用pull拉取消息的一个附带工作.  </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">trait</span> <span class="title">ConsumerConnector</span> &#123;</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">createMessageStreams</span>(</span>topicCountMap: <span class="type">Map</span>[<span class="type">String</span>,<span class="type">Int</span>]): <span class="type">Map</span>[<span class="type">String</span>, <span class="type">List</span>[<span class="type">KafkaStream</span>[<span class="type">Array</span>[<span class="type">Byte</span>],<span class="type">Array</span>[<span class="type">Byte</span>]]]]</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">createMessageStreams</span>[</span><span class="type">K</span>,<span class="type">V</span>](topicCountMap: <span class="type">Map</span>[<span class="type">String</span>,<span class="type">Int</span>], keyDecoder: <span class="type">Decoder</span>[<span class="type">K</span>], valueDecoder: <span class="type">Decoder</span>[<span class="type">V</span>]) : <span class="type">Map</span>[<span class="type">String</span>,<span class="type">List</span>[<span class="type">KafkaStream</span>[<span class="type">K</span>,<span class="type">V</span>]]]</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">createMessageStreamsByFilter</span>[</span><span class="type">K</span>,<span class="type">V</span>](topicFilter: <span class="type">TopicFilter</span>, numStreams: <span class="type">Int</span> = <span class="number">1</span>, keyDecoder: <span class="type">Decoder</span>[<span class="type">K</span>] = <span class="keyword">new</span> <span class="type">DefaultDecoder</span>(), valueDecoder: <span class="type">Decoder</span>[<span class="type">V</span>] = <span class="keyword">new</span> <span class="type">DefaultDecoder</span>()) : <span class="type">Seq</span>[<span class="type">KafkaStream</span>[<span class="type">K</span>,<span class="type">V</span>]]</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">commitOffsets</span>(</span>retryOnFailure: <span class="type">Boolean</span>)</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">commitOffsets</span>(</span>offsetsToCommit: immutable.<span class="type">Map</span>[<span class="type">TopicAndPartition</span>, <span class="type">OffsetAndMetadata</span>], retryOnFailure: <span class="type">Boolean</span>)</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">setConsumerRebalanceListener</span>(</span>listener: <span class="type">ConsumerRebalanceListener</span>)</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">shutdown</span>(</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="ZookeeperConsumerConnector">ZookeeperConsumerConnector</h2><p>一个Consumer会创建一个ZookeeperConsumerConnector,代表一个消费者进程.  </p>
<ul>
<li>fetcher: 消费者获取数据, 使用ConsumerFetcherManager fetcher线程抓取数据</li>
<li>zkUtils: 消费者要和ZK通信, 除了注册自己,还有其他信息也会写到ZK中</li>
<li>topicThreadIdAndQueues: 消费者会指定自己消费哪些topic,并指定线程数, 所以topicThreadId都对应一个队列</li>
<li>messageStreamCreated: 消费者会创建消息流, 每个队列都对应一个消息流</li>
<li>offsetsChannel: offset可以存储在ZK或者kafka中,如果存在kafka里,像其他请求一样,需要和Broker通信</li>
<li>还有其他几个Listener监听器,分别用于topicPartition的更新,负载均衡,消费者重新负载等</li>
</ul>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span>[kafka] <span class="class"><span class="keyword">class</span> <span class="title">ZookeeperConsumerConnector</span>(</span><span class="keyword">val</span> config: <span class="type">ConsumerConfig</span>, <span class="keyword">val</span> enableFetcher: <span class="type">Boolean</span>) </span><br><span class="line">        <span class="keyword">extends</span> <span class="type">ConsumerConnector</span> <span class="keyword">with</span> <span class="type">Logging</span> <span class="keyword">with</span> <span class="type">KafkaMetricsGroup</span> &#123;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> fetcher: <span class="type">Option</span>[<span class="type">ConsumerFetcherManager</span>] = <span class="type">None</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> zkUtils: <span class="type">ZkUtils</span> = <span class="literal">null</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> topicRegistry = <span class="keyword">new</span> <span class="type">Pool</span>[<span class="type">String</span>, <span class="type">Pool</span>[<span class="type">Int</span>, <span class="type">PartitionTopicInfo</span>]]</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> checkpointedZkOffsets = <span class="keyword">new</span> <span class="type">Pool</span>[<span class="type">TopicAndPartition</span>, <span class="type">Long</span>]</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> topicThreadIdAndQueues = <span class="keyword">new</span> <span class="type">Pool</span>[(<span class="type">String</span>, <span class="type">ConsumerThreadId</span>), <span class="type">BlockingQueue</span>[<span class="type">FetchedDataChunk</span>]]</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> scheduler = <span class="keyword">new</span> <span class="type">KafkaScheduler</span>(threads = <span class="number">1</span>, threadNamePrefix = <span class="string">"kafka-consumer-scheduler-"</span>)</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> messageStreamCreated = <span class="keyword">new</span> <span class="type">AtomicBoolean</span>(<span class="literal">false</span>)</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> offsetsChannel: <span class="type">BlockingChannel</span> = <span class="literal">null</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> sessionExpirationListener: <span class="type">ZKSessionExpireListener</span> = <span class="literal">null</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> topicPartitionChangeListener: <span class="type">ZKTopicPartitionChangeListener</span> = <span class="literal">null</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> loadBalancerListener: <span class="type">ZKRebalancerListener</span> = <span class="literal">null</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> wildcardTopicWatcher: <span class="type">ZookeeperTopicEventWatcher</span> = <span class="literal">null</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> consumerRebalanceListener: <span class="type">ConsumerRebalanceListener</span> = <span class="literal">null</span></span><br><span class="line"></span><br><span class="line">  connectZk()                       <span class="comment">// ① 创建ZkUtils,会创建对应的ZkConnection和ZkClient</span></span><br><span class="line">  createFetcher()                   <span class="comment">// ② 创建ConsumerFetcherManager,消费者fetcher线程</span></span><br><span class="line">  ensureOffsetManagerConnected()    <span class="comment">// ③ 确保连接上OffsetManager.</span></span><br><span class="line">  <span class="keyword">if</span> (config.autoCommitEnable) &#123;    <span class="comment">// ④ 启动定时提交offset线程</span></span><br><span class="line">    scheduler.startup              </span><br><span class="line">    scheduler.schedule(<span class="string">"kafka-consumer-autocommit"</span>, autoCommit, delay = config.autoCommitIntervalMs, period = config.autoCommitIntervalMs, unit = <span class="type">TimeUnit</span>.<span class="type">MILLISECONDS</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="zk_and_broker">zk and broker</h3><ul>
<li>① <code>/brokers</code> -&gt;&gt; <code>topics</code>和<code>ids</code>: 集群中所有的topics,以及所有的brokers.</li>
<li>② <code>/brokers/ids/broker_id</code> -&gt; 主机的基本信息,包括主机地址和端口号</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[zk: <span class="number">192.168</span><span class="number">.47</span><span class="number">.83</span>:<span class="number">2181</span>,<span class="number">192.168</span><span class="number">.47</span><span class="number">.84</span>:<span class="number">2181</span>,<span class="number">192.168</span><span class="number">.47</span><span class="number">.86</span>:<span class="number">2181</span>(CONNECTED) <span class="number">1</span>] ls /brokers</span><br><span class="line">[topics, ids]</span><br><span class="line"></span><br><span class="line">[zk: <span class="number">192.168</span><span class="number">.47</span><span class="number">.83</span>:<span class="number">2181</span>,<span class="number">192.168</span><span class="number">.47</span><span class="number">.84</span>:<span class="number">2181</span>,<span class="number">192.168</span><span class="number">.47</span><span class="number">.86</span>:<span class="number">2181</span>(CONNECTED) <span class="number">2</span>] ls /brokers/ids</span><br><span class="line">[<span class="number">3</span>, <span class="number">5</span>, <span class="number">4</span>]</span><br><span class="line">[zk: <span class="number">192.168</span><span class="number">.47</span><span class="number">.83</span>:<span class="number">2181</span>,<span class="number">192.168</span><span class="number">.47</span><span class="number">.84</span>:<span class="number">2181</span>,<span class="number">192.168</span><span class="number">.47</span><span class="number">.86</span>:<span class="number">2181</span>(CONNECTED) <span class="number">4</span>] get /brokers/ids/<span class="number">3</span></span><br><span class="line">&#123;<span class="string">"jmx_port"</span>:<span class="number">10055</span>,<span class="string">"timestamp"</span>:<span class="string">"1453380999577"</span>,<span class="string">"host"</span>:<span class="string">"192.168.48.153"</span>,<span class="string">"version"</span>:<span class="number">1</span>,<span class="string">"port"</span>:<span class="number">9092</span>&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>③ <code>/brokers/topics/topic_name</code> -&gt; topic的每个partition,以及分配的replicas(AR)</li>
<li>④ <code>/brokers/topics/topic_name/partitions/partition_id/state</code> -&gt; 这个partition的leader,isr</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[zk: <span class="number">192.168</span><span class="number">.47</span><span class="number">.83</span>:<span class="number">2181</span>,<span class="number">192.168</span><span class="number">.47</span><span class="number">.84</span>:<span class="number">2181</span>,<span class="number">192.168</span><span class="number">.47</span><span class="number">.86</span>:<span class="number">2181</span>(CONNECTED) <span class="number">17</span>] get /brokers/topics/topic1</span><br><span class="line">&#123;<span class="string">"version"</span>:<span class="number">1</span>,<span class="string">"partitions"</span>:&#123;<span class="string">"2"</span>:[<span class="number">5</span>,<span class="number">4</span>],<span class="string">"1"</span>:[<span class="number">4</span>,<span class="number">3</span>],<span class="string">"0"</span>:[<span class="number">3</span>,<span class="number">5</span>]&#125;&#125;</span><br><span class="line"></span><br><span class="line">[zk: <span class="number">192.168</span><span class="number">.47</span><span class="number">.83</span>:<span class="number">2181</span>,<span class="number">192.168</span><span class="number">.47</span><span class="number">.84</span>:<span class="number">2181</span>,<span class="number">192.168</span><span class="number">.47</span><span class="number">.86</span>:<span class="number">2181</span>(CONNECTED) <span class="number">12</span>] ls /brokers/topics/topic1/partitions</span><br><span class="line">[<span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>]</span><br><span class="line">[zk: <span class="number">192.168</span><span class="number">.47</span><span class="number">.83</span>:<span class="number">2181</span>,<span class="number">192.168</span><span class="number">.47</span><span class="number">.84</span>:<span class="number">2181</span>,<span class="number">192.168</span><span class="number">.47</span><span class="number">.86</span>:<span class="number">2181</span>(CONNECTED) <span class="number">13</span>] ls /brokers/topics/topic1/partitions/<span class="number">0</span></span><br><span class="line">[state]</span><br><span class="line">[zk: <span class="number">192.168</span><span class="number">.47</span><span class="number">.83</span>:<span class="number">2181</span>,<span class="number">192.168</span><span class="number">.47</span><span class="number">.84</span>:<span class="number">2181</span>,<span class="number">192.168</span><span class="number">.47</span><span class="number">.86</span>:<span class="number">2181</span>(CONNECTED) <span class="number">15</span>] get /brokers/topics/topic1/partitions/<span class="number">0</span>/state</span><br><span class="line">&#123;<span class="string">"controller_epoch"</span>:<span class="number">1775</span>,<span class="string">"leader"</span>:<span class="number">3</span>,<span class="string">"version"</span>:<span class="number">1</span>,<span class="string">"leader_epoch"</span>:<span class="number">145</span>,<span class="string">"isr"</span>:[<span class="number">3</span>,<span class="number">5</span>]&#125;</span><br></pre></td></tr></table></figure>
<p><img src="http://img.blog.csdn.net/20160126150532822" alt="k_partition_info"></p>
<blockquote>
<p>上图是kafka manager中某个topic的PartitionInfo, 集群只有3个节点,这个topic有3个partition,2个副本.  </p>
</blockquote>
<p><strong>② Broker node registry</strong>  </p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/brokers/ids/<span class="number">0</span> --&gt; &#123; <span class="string">"host"</span> : <span class="string">"host:port"</span>, <span class="string">"topics"</span> : &#123;<span class="string">"topic1"</span>: [<span class="string">"partition1"</span> <span class="keyword">...</span> <span class="string">"partitionN"</span>], <span class="keyword">...</span>, <span class="string">"topicN"</span>: [<span class="string">"partition1"</span> <span class="keyword">...</span> <span class="string">"partitionN"</span>] &#125; &#125;</span><br></pre></td></tr></table></figure>
<p>每个Broker节点在自己启动的时候,会在/brokers下创建一个逻辑节点. 内容包括了Broker的主机和端口, Broker服务的所有topic,<br>以及分配到当前Broker的这个topic的partition列表(并不是topic的全部partition,会将所有partition分布在不同的brokers). </p>
<blockquote>
<p>A consumer subscribes to event changes of the broker node registry.<br>当Broker挂掉的时候,在这个Broker上的所有Partition都丢失了,而Partition是给消费者服务的.<br>所以Broker挂掉后在做迁移的时候,会将其上的Partition转移到其他Broker上,因此消费者要消费的Partition也跟着变化.  </p>
</blockquote>
<p><strong>③ Broker topic registry</strong>  </p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/brokers/topics/topic1 -&gt; &#123;<span class="string">"version"</span>:<span class="number">1</span>,<span class="string">"partitions"</span>:&#123;<span class="string">"2"</span>:[<span class="number">5</span>,<span class="number">4</span>],<span class="string">"1"</span>:[<span class="number">4</span>,<span class="number">3</span>],<span class="string">"0"</span>:[<span class="number">3</span>,<span class="number">5</span>]&#125;&#125;</span><br></pre></td></tr></table></figure>
<p>虽然topic是在/brokers下,但是这个topic的信息是全局的.在创建topic的时候,这个topic的每个partition的编号以及replicas.<br>具体每个partition的Leader以及isr信息则是在<code>/brokers/topics/topic_name/partitions/partition_id/state</code>  </p>
<h3 id="zk_and_consumer">zk and consumer</h3><p><strong>Consumer id registry</strong>: <code>/consumers/[group_id]/ids/[consumer_id] -&gt; topic1,...topicN</code>  </p>
<p>每个消费者会将它的id注册为临时znode并且将它所消费的topic设置为znode的值,当客户端(消费者)退出时,znode(consumer_id)会被删除.  </p>
<blockquote>
<p><code>A consumer subscribes to event changes of the consumer id registry within its group.</code><br>每个consumer会订阅它所在的消费组中关于consumer_id注册的更新事件. 为什么要注册呢,因为Kafka只会将一条消息发送到一个消费组中唯一的一个消费者.<br>如果某个消费者挂了,它要把本来发给挂的消费者的消费转给这个消费组中其他的消费者.同理,有新消费者加入消费组时,也会进行负载均衡.  </p>
</blockquote>
<p><strong>Partition owner registry</strong>: <code>/consumers/[group_id]/owner/[topic]/[broker_id-partition_id] --&gt; consumer_node_id</code>  </p>
<p>在消费时,每个topic的partition只能被一个消费者组中的唯一的一个消费者消费.在每次重新负载的时候,这个映射策略就会重新构建.  </p>
<p><strong>Consumer offset tracking</strong>: <code>/consumers/[group_id]/offsets/[topic]/[broker_id-partition_id] --&gt; offset_counter_value</code>  </p>
<p>每个消费者都要跟踪自己消费的每个Partition最近的offset.表示自己读取到Partition的最新位置.<br>由于一个Partition只能被消费组中的一个消费者消费,所以offset是以<code>消费组</code>为级别的,而不是消费者.<br>因为如果原来的消费者挂了后,应当将这个Partition交给同一个消费组中别的消费者,而此时offset是没有变化的.<br>一个partition可以被不同的<code>消费者组</code>中的不同消费者消费，所以不同的消费者组必须维护他们各自对该partition消费的最新的offset</p>
<h2 id="init">init</h2><p>在创建ZookeeperConsumerConnector时,有几个初始化方法需要事先执行.  </p>
<ul>
<li>因为消费者要和ZK通信,所以connectZk会确保连接上ZooKeeper</li>
<li>消费者要消费数据,需要有抓取线程,所有的抓取线程交给ConsumerFetcherManager统一管理</li>
<li>由消费者客户端自己保存offset,而消费者会消费多个topic的多个partition.  </li>
<li>类似多个数据抓取线程有管理类,多个partition的offset管理类OffsetManager是一个GroupCoordinator  </li>
<li>定时提交线程会使用OffsetManager建立的通道定时提交offset到zk或者kafka.  </li>
</ul>
<p><img src="http://img.blog.csdn.net/20160125104919159" alt="k_consumer_connector_init"></p>
<h3 id="AbstractFetcherManager">AbstractFetcherManager</h3><p>每个消费者都有自己的ConsumerFetcherManager.fetch动作不仅只有消费者有,Partition的副本也会拉取Leader的数据.<br>createFetcherThread抽象方法对于Consumer和Replica会分别创建ConsumerFetcherThread和ReplicaFetcherThread.  </p>
<p><img src="http://img.blog.csdn.net/20160125104937050" alt="k_abstract_fetcher"></p>
<p>由于消费者可以消费多个topic的多个partition.每个TopicPartition组合都会有一个fetcherId.<br>所以fetcherThreadMap的key实际上在由(broker_id, topic_id, partition_id)组成的.<br>针对每个source broker的每个partition都会有拉取线程,即拉取是针对partition级别拉取数据的.  </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">AbstractFetcherManager</span>(</span><span class="keyword">protected</span> <span class="keyword">val</span> name: <span class="type">String</span>, clientId: <span class="type">String</span>, numFetchers: <span class="type">Int</span> = <span class="number">1</span>) &#123;</span><br><span class="line">  <span class="comment">// map of (source broker_id, fetcher_id per source broker) =&gt; fetcher</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> fetcherThreadMap = <span class="keyword">new</span> mutable.<span class="type">HashMap</span>[<span class="type">BrokerAndFetcherId</span>, <span class="type">AbstractFetcherThread</span>]</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">BrokerAndFetcherId</span>(</span>broker: <span class="type">BrokerEndPoint</span>, fetcherId: <span class="type">Int</span>)</span><br><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">BrokerAndInitialOffset</span>(</span>broker: <span class="type">BrokerEndPoint</span>, initOffset: <span class="type">Long</span>)</span><br></pre></td></tr></table></figure>
<p>所以BrokerAndFetcherId可以表示Borker上某个topic的PartitionId, 而BrokerAndInitialOffset只是Broker级别的offset.<br>addFetcherForPartitions的参数中BrokerAndInitialOffset是和TopicAndPartition有关的,即Partition的offset.<br>为Partition添加Fetcher是为Partition创建Fetcher线程. 因为Fetcher线程是用来抓取Partition的消息.  </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// to be defined in subclass to create a specific fetcher</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createFetcherThread</span>(</span>fetcherId: <span class="type">Int</span>, sourceBroker: <span class="type">BrokerEndPoint</span>): <span class="type">AbstractFetcherThread</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">addFetcherForPartitions</span>(</span>partitionAndOffsets: <span class="type">Map</span>[<span class="type">TopicAndPartition</span>, <span class="type">BrokerAndInitialOffset</span>]) &#123;</span><br><span class="line">    <span class="comment">// 根据broker-topic-partition分组. 所以相同partition的只会有一个fetcher线程  </span></span><br><span class="line">    <span class="keyword">val</span> partitionsPerFetcher = partitionAndOffsets.groupBy&#123; <span class="keyword">case</span>(topicAndPartition, brokerAndInitialOffset) =&gt;</span><br><span class="line">      <span class="type">BrokerAndFetcherId</span>(brokerAndInitialOffset.broker, getFetcherId(topicAndPartition.topic, topicAndPartition.partition))&#125;</span><br><span class="line">    <span class="comment">// 分组之后的value仍然不变,还是partitionAndOffsets,但是相同的partition的多个partitionAndOffsets都聚合在一起了 </span></span><br><span class="line">    <span class="keyword">for</span> ((brokerAndFetcherId, partitionAndOffsets) &lt;- partitionsPerFetcher) &#123;</span><br><span class="line">      <span class="comment">// 在这里想要为每个fetcherId创建拉取线程的. 如果在缓存中直接返回,否则创建一个新的拉取线程</span></span><br><span class="line">      <span class="keyword">var</span> fetcherThread: <span class="type">AbstractFetcherThread</span> = <span class="literal">null</span></span><br><span class="line">      fetcherThreadMap.get(brokerAndFetcherId) <span class="keyword">match</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> <span class="type">Some</span>(f) =&gt; fetcherThread = f</span><br><span class="line">        <span class="keyword">case</span> <span class="type">None</span> =&gt;</span><br><span class="line">          fetcherThread = createFetcherThread(brokerAndFetcherId.fetcherId, brokerAndFetcherId.broker)</span><br><span class="line">          fetcherThreadMap.put(brokerAndFetcherId, fetcherThread)</span><br><span class="line">          fetcherThread.start         <span class="comment">// 启动刚刚创建的拉取线程</span></span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// 由于partitionAndOffsets现在已经是在同一个partition里. 取得所有partition对应的offset</span></span><br><span class="line">      fetcherThreadMap(brokerAndFetcherId).addPartitions(partitionAndOffsets.map &#123; </span><br><span class="line">        <span class="keyword">case</span> (topicAndPartition, brokerAndInitOffset) =&gt; topicAndPartition -&gt; brokerAndInitOffset.initOffset</span><br><span class="line">      &#125;)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="http://img.blog.csdn.net/20160126084058247" alt="k_abstract_fetcher_map"></p>
<h3 id="AbstractFetcherThread_addPartitions">AbstractFetcherThread addPartitions</h3><p>Consumer和Replica的FetcherManager都会负责将自己要抓取的partitionAndOffsets传给对应的Fetcher线程.  </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">AbstractFetcherManager</span>.addFetcherForPartitions(<span class="type">Map</span>&lt;<span class="type">TopicAndPartition</span>, <span class="type">BrokerAndInitialOffset</span>&gt;)  (kafka.server)</span><br><span class="line">    |-- <span class="type">LeaderFinderThread</span> in <span class="type">ConsumerFetcherManager</span>.doWork()  (kafka.consumer)</span><br><span class="line">    |-- <span class="type">ReplicaManager</span>.makeFollowers(int, int, <span class="type">Map</span>&lt;<span class="type">Partition</span>, <span class="type">PartitionState</span>&gt;, int, <span class="type">Map</span>&lt;<span class="type">TopicPartition</span>, <span class="type">Object</span>&gt;, <span class="type">MetadataCache</span>)  (kafka.server)</span><br></pre></td></tr></table></figure>
<p>抓取线程也是用partitionMap缓存来保存每个TopicAndPartition的抓取状态.即<code>管理者负责线程</code>相关,而<code>线程负责状态</code>相关.<br>Partition的状态就是offset信息.但是拉取状态并不是实时更新的,PartitionFetchState还包括了isActive表示是否延迟.<br>对一个Partition延迟,判断isActive状态后,用延迟时间封装到DelayedItem. 一般出错的拉取会被延迟back-off毫秒.  </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Abstract class for fetching data from multiple partitions from the same broker.</span></span><br><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">AbstractFetcherThread</span>(</span>name: <span class="type">String</span>, clientId: <span class="type">String</span>, sourceBroker: <span class="type">BrokerEndPoint</span>, fetchBackOffMs: <span class="type">Int</span> = <span class="number">0</span>, isInterruptible: <span class="type">Boolean</span> = <span class="literal">true</span>) <span class="keyword">extends</span> <span class="type">ShutdownableThread</span>(name, isInterruptible) &#123;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> partitionMap = <span class="keyword">new</span> mutable.<span class="type">HashMap</span>[<span class="type">TopicAndPartition</span>, <span class="type">PartitionFetchState</span>] <span class="comment">// a (topic, partition) -&gt; partitionFetchState map</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">addPartitions</span>(</span>partitionAndOffsets: <span class="type">Map</span>[<span class="type">TopicAndPartition</span>, <span class="type">Long</span>]) &#123;</span><br><span class="line">    partitionMapLock.lockInterruptibly()</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="keyword">for</span> ((topicAndPartition, offset) &lt;- partitionAndOffsets) &#123;</span><br><span class="line">        <span class="comment">// If the partitionMap already has the topic/partition, then do not update the map with the old offset</span></span><br><span class="line">        <span class="keyword">if</span> (!partitionMap.contains(topicAndPartition))</span><br><span class="line">          partitionMap.put(topicAndPartition,</span><br><span class="line">            <span class="keyword">if</span> (<span class="type">PartitionTopicInfo</span>.isOffsetInvalid(offset)) <span class="keyword">new</span> <span class="type">PartitionFetchState</span>(handleOffsetOutOfRange(topicAndPartition))</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">new</span> <span class="type">PartitionFetchState</span>(offset)</span><br><span class="line">          )&#125;</span><br><span class="line">      partitionMapCond.signalAll()</span><br><span class="line">    &#125; <span class="keyword">finally</span> partitionMapLock.unlock()</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<h3 id="FetchRequest_&amp;_PartitionData">FetchRequest &amp; PartitionData</h3><p>拉取请求指定要拉取哪个TopicAndPartition(offset来自于PartitionFetchState), PartitionData返回要拉取的消息集.  </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">type</span> <span class="title">REQ</span> <span class="title">&lt;</span>:</span> <span class="type">FetchRequest</span>  <span class="comment">//拉取请求的子类</span></span><br><span class="line"><span class="class"><span class="keyword">type</span> <span class="title">PD</span> <span class="title">&lt;</span>:</span> <span class="type">PartitionData</span>  <span class="comment">//Partition数据,即拉取结果</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">trait</span> <span class="title">FetchRequest</span> &#123;</span>      <span class="comment">//定义了拉取接口</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">isEmpty</span>:</span> <span class="type">Boolean</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">offset</span>(</span>topicAndPartition: <span class="type">TopicAndPartition</span>): <span class="type">Long</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">trait</span> <span class="title">PartitionData</span> &#123;</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">errorCode</span>:</span> <span class="type">Short</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">exception</span>:</span> <span class="type">Option</span>[<span class="type">Throwable</span>]</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">toByteBufferMessageSet</span>:</span> <span class="type">ByteBufferMessageSet</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">highWatermark</span>:</span> <span class="type">Long</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>FetchRequest和PartitionData也有Consumer和Replica之分. ConsumerFetcherThread中的方法交给了underlying(类似于装饰模式).  </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ConsumerFetcherThread</span> &#123;</span></span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">FetchRequest</span>(</span><span class="keyword">val</span> underlying: kafka.api.<span class="type">FetchRequest</span>) <span class="keyword">extends</span> <span class="type">AbstractFetcherThread</span>.<span class="type">FetchRequest</span> &#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">isEmpty</span>:</span> <span class="type">Boolean</span> = underlying.requestInfo.isEmpty</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">offset</span>(</span>topicAndPartition: <span class="type">TopicAndPartition</span>): <span class="type">Long</span> = underlying.requestInfo(topicAndPartition).offset</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">PartitionData</span>(</span><span class="keyword">val</span> underlying: <span class="type">FetchResponsePartitionData</span>) <span class="keyword">extends</span> <span class="type">AbstractFetcherThread</span>.<span class="type">PartitionData</span> &#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">errorCode</span>:</span> <span class="type">Short</span> = underlying.error</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">toByteBufferMessageSet</span>:</span> <span class="type">ByteBufferMessageSet</span> = underlying.messages.asInstanceOf[<span class="type">ByteBufferMessageSet</span>]</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">highWatermark</span>:</span> <span class="type">Long</span> = underlying.hw</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">exception</span>:</span> <span class="type">Option</span>[<span class="type">Throwable</span>] = <span class="keyword">if</span> (errorCode == <span class="type">ErrorMapping</span>.<span class="type">NoError</span>) <span class="type">None</span> <span class="keyword">else</span> <span class="type">Some</span>(<span class="type">ErrorMapping</span>.exceptionFor(errorCode))</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>来自于kafka.api的FetchRequest才是真正面向KafkaApis的请求.PartitionFetchInfo除了offset还有fetchSize.<br>RequestOrResponse是作为KafkaApis中数据传递的介质接口. 参数requestId表示了请求的类型(PRODUCE,FETCH等)  </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">PartitionFetchInfo</span>(</span>offset: <span class="type">Long</span>, fetchSize: <span class="type">Int</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">FetchRequest</span>(</span>versionId: <span class="type">Short</span> = <span class="type">FetchRequest</span>.<span class="type">CurrentVersion</span>,correlationId: <span class="type">Int</span> = <span class="type">FetchRequest</span>.<span class="type">DefaultCorrelationId</span>,</span><br><span class="line">                        clientId: <span class="type">String</span> = <span class="type">ConsumerConfig</span>.<span class="type">DefaultClientId</span>,replicaId: <span class="type">Int</span> = <span class="type">Request</span>.<span class="type">OrdinaryConsumerId</span>,</span><br><span class="line">                        maxWait: <span class="type">Int</span> = <span class="type">FetchRequest</span>.<span class="type">DefaultMaxWait</span>,minBytes: <span class="type">Int</span> = <span class="type">FetchRequest</span>.<span class="type">DefaultMinBytes</span>,</span><br><span class="line">                        requestInfo: <span class="type">Map</span>[<span class="type">TopicAndPartition</span>, <span class="type">PartitionFetchInfo</span>])</span><br><span class="line">        <span class="keyword">extends</span> <span class="type">RequestOrResponse</span>(<span class="type">Some</span>(<span class="type">ApiKeys</span>.<span class="type">FETCH</span>.id))</span><br></pre></td></tr></table></figure>
<p><img src="http://img.blog.csdn.net/20160126084038512" alt="k_fetchRequest_partitionData"></p>
<p><strong>ConsumerFetcherThread.buildFetchRequest</strong>  </p>
<p>AbstractFetcherThread的doWork会抽象出buildFetchRequest,ConsumerFetcherThread会使用FetchRequestBuilder<br>build出来的是和kafka.api.FetchRequestBuilder相同文件下的kafka.api.FetchRequest,作为underlying.  </p>
<p>注意其中Partition的offset最开始源自于<code>AbstractFetcherManager</code>.addFetcherForPartitions的BrokerAndInitialOffset<br>然后获取brokerAndInitOffset.initOffset作为<code>AbstractFetcherThread</code>.addPartitions方法参数Map的value,<br>并转化为<code>PartitionFetchState</code>加入到<strong>partitionMap</strong>中,在buildFetchRequest又转化为了<code>PartitionFetchInfo</code>.  </p>
<p>注意:上面只是一种来源,拉取线程在拉取数据之后,会<code>更新这批数据最后一条消息的下一个offset</code>作为<strong>partitionMap</strong>中Partition的<br>最新PartitionFetchState,所以下一次调用buildFetchRequest构建新的FetchRequest时,PartitionFetchInfo的offset也是最新的.  </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConsumerFetcherThread</span>(</span>...)&#123;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> fetchRequestBuilder = <span class="keyword">new</span> <span class="type">FetchRequestBuilder</span>().</span><br><span class="line">    clientId(clientId).replicaId(<span class="type">Request</span>.<span class="type">OrdinaryConsumerId</span>).maxWait(config.fetchWaitMaxMs).</span><br><span class="line">    minBytes(config.fetchMinBytes).requestVersion(kafka.api.<span class="type">FetchRequest</span>.<span class="type">CurrentVersion</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment">// partitionMap来自于AbstractFetcherThread.addPartitions或者delayPartitions</span></span><br><span class="line">  <span class="keyword">protected</span> <span class="function"><span class="keyword">def</span> <span class="title">buildFetchRequest</span>(</span>partitionMap: collection.<span class="type">Map</span>[<span class="type">TopicAndPartition</span>, <span class="type">PartitionFetchState</span>]): <span class="type">FetchRequest</span> = &#123;</span><br><span class="line">    partitionMap.foreach &#123; <span class="keyword">case</span> ((topicAndPartition, partitionFetchState)) =&gt;</span><br><span class="line">      <span class="keyword">if</span> (partitionFetchState.isActive)</span><br><span class="line">        fetchRequestBuilder.addFetch(topicAndPartition.topic, topicAndPartition.partition, partitionFetchState.offset, fetchSize)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">new</span> <span class="type">FetchRequest</span>(fetchRequestBuilder.build())  <span class="comment">//构造器模式,在最后才进行build</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FetchRequestBuilder</span>(</span>) &#123;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> requestMap = <span class="keyword">new</span> collection.mutable.<span class="type">HashMap</span>[<span class="type">TopicAndPartition</span>, <span class="type">PartitionFetchInfo</span>]</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">addFetch</span>(</span>topic: <span class="type">String</span>, partition: <span class="type">Int</span>, offset: <span class="type">Long</span>, fetchSize: <span class="type">Int</span>) = &#123;</span><br><span class="line">    requestMap.put(<span class="type">TopicAndPartition</span>(topic, partition), <span class="type">PartitionFetchInfo</span>(offset, fetchSize))</span><br><span class="line">    <span class="keyword">this</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">build</span>(</span>) = &#123;</span><br><span class="line">    <span class="keyword">val</span> fetchRequest = <span class="type">FetchRequest</span>(versionId, correlationId.getAndIncrement, clientId, replicaId, maxWait, minBytes, requestMap.toMap)</span><br><span class="line">    requestMap.clear()</span><br><span class="line">    fetchRequest</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="AbstractFetcherThread_doWork">AbstractFetcherThread doWork</h3><p>AbstractFetcherThread定义了多个回调方法,它的doWork方法会构建FetchRequest,然后处理拉取请求.<br>因为拉取分为Consumer和Replica,所以将具体的拉取动作要留给子类自己实现.  </p>
<blockquote>
<p>注意:下面的partitionMap在addPartitions中被添加.在doWork拉取到数据后被更新offset,表示最新拉取的位置  </p>
</blockquote>
<p><img src="http://img.blog.csdn.net/20160126084015605" alt="k_fetch_update_offset"></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">AbstractFetcherThread</span>(</span>..)&#123;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> partitionMap = <span class="keyword">new</span> mutable.<span class="type">HashMap</span>[<span class="type">TopicAndPartition</span>, <span class="type">PartitionFetchState</span>] <span class="comment">// a (topic, partition) -&gt; partitionFetchState map</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// ① 根据partitionMap构建FetchRequest请求</span></span><br><span class="line">  <span class="keyword">protected</span> <span class="function"><span class="keyword">def</span> <span class="title">buildFetchRequest</span>(</span>partitionMap: <span class="type">Map</span>[<span class="type">TopicAndPartition</span>, <span class="type">PartitionFetchState</span>]): <span class="type">REQ</span></span><br><span class="line">  <span class="comment">// ② 根据抓取请求向Broker拉取消息</span></span><br><span class="line">  <span class="keyword">protected</span> <span class="function"><span class="keyword">def</span> <span class="title">fetch</span>(</span>fetchRequest: <span class="type">REQ</span>): <span class="type">Map</span>[<span class="type">TopicAndPartition</span>, <span class="type">PD</span>]</span><br><span class="line">  <span class="comment">// ③ process fetched data 处理抓取到的数据</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">processPartitionData</span>(</span>topicAndPartition: <span class="type">TopicAndPartition</span>, fetchOffset: <span class="type">Long</span>, partitionData: <span class="type">PD</span>)</span><br><span class="line">  <span class="comment">// ④ handle a partition whose offset is out of range and return a new fetch offset 处理超出范围的offset</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">handleOffsetOutOfRange</span>(</span>topicAndPartition: <span class="type">TopicAndPartition</span>): <span class="type">Long</span></span><br><span class="line">  <span class="comment">// ⑤ deal with partitions with errors, potentially due to leadership changes 处理出错的partitions</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">handlePartitionsWithErrors</span>(</span>partitions: <span class="type">Iterable</span>[<span class="type">TopicAndPartition</span>])</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 拉取线程工作, doWork是被循环调用的,所以一旦partiionMap发生了变化(比如拉取一次之后),新的FetchRequest中的offset也发生了变化 </span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">doWork</span>(</span>) &#123;</span><br><span class="line">    <span class="keyword">val</span> fetchRequest = inLock(partitionMapLock) &#123;</span><br><span class="line">      <span class="keyword">val</span> fetchRequest = buildFetchRequest(partitionMap)</span><br><span class="line">      <span class="comment">// 如果没有拉取请求, 则延迟back-off毫秒后继续发送请求</span></span><br><span class="line">      <span class="keyword">if</span> (fetchRequest.isEmpty) partitionMapCond.await(fetchBackOffMs, <span class="type">TimeUnit</span>.<span class="type">MILLISECONDS</span>)</span><br><span class="line">      fetchRequest</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (!fetchRequest.isEmpty) processFetchRequest(fetchRequest)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">processFetchRequest</span>(</span>fetchRequest: <span class="type">REQ</span>) &#123;</span><br><span class="line">    <span class="keyword">val</span> partitionsWithError = <span class="keyword">new</span> mutable.<span class="type">HashSet</span>[<span class="type">TopicAndPartition</span>]</span><br><span class="line">    <span class="keyword">var</span> responseData: <span class="type">Map</span>[<span class="type">TopicAndPartition</span>, <span class="type">PD</span>] = <span class="type">Map</span>.empty</span><br><span class="line">    responseData = fetch(fetchRequest)</span><br><span class="line">    responseData.foreach &#123; <span class="keyword">case</span> (topicAndPartition, partitionData) =&gt;</span><br><span class="line">      <span class="comment">// 响应结果:TopicAndPartition-&gt;PartitionData,根据TopicAndPartition,就能从partitionMap中的PartitionFetchState</span></span><br><span class="line">      partitionMap.get(topicAndPartition).foreach(currentPartitionFetchState =&gt;</span><br><span class="line">        <span class="comment">// we append to the log if the current offset is defined and it is the same as the offset requested during fetch</span></span><br><span class="line">        <span class="comment">// fetchRequest是由partitionMap通过buildFetchRequest构建出来的,而currentPartitionFetchState也来自于partitionMap</span></span><br><span class="line">        <span class="keyword">if</span> (fetchRequest.offset(topicAndPartition) == currentPartitionFetchState.offset) &#123;</span><br><span class="line">          <span class="type">Errors</span>.forCode(partitionData.errorCode) <span class="keyword">match</span> &#123;</span><br><span class="line">            <span class="keyword">case</span> <span class="type">Errors</span>.<span class="type">NONE</span> =&gt;</span><br><span class="line">                <span class="comment">// responseData的PartitionData,包含了拉取的消息内容</span></span><br><span class="line">                <span class="keyword">val</span> messages = partitionData.toByteBufferMessageSet</span><br><span class="line">                <span class="comment">// 最后一条消息的offset+1,为新的offset,即下一次要拉取的offset的开始位置从newOffset开始</span></span><br><span class="line">                <span class="keyword">val</span> newOffset = messages.shallowIterator.toSeq.lastOption <span class="keyword">match</span> &#123;  <span class="comment">//正常的迭代器迭代之后消息就没有了,使用shallow拷贝,消息仍然存在</span></span><br><span class="line">                  <span class="keyword">case</span> <span class="type">Some</span>(m: <span class="type">MessageAndOffset</span>) =&gt; m.nextOffset</span><br><span class="line">                  <span class="keyword">case</span> <span class="type">None</span> =&gt; currentPartitionFetchState.offset</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">// 更新partitionMap中的Partition拉取状态, 这样下次请求时,因为partitionMap内容更新了,重新构造的buildFetchRequest的offset也变化了</span></span><br><span class="line">                partitionMap.put(topicAndPartition, <span class="keyword">new</span> <span class="type">PartitionFetchState</span>(newOffset))</span><br><span class="line">                processPartitionData(topicAndPartition, currentPartitionFetchState.offset, partitionData)</span><br><span class="line">            <span class="keyword">case</span> <span class="type">Errors</span>.<span class="type">OFFSET_OUT_OF_RANGE</span> =&gt; partitionMap.put(topicAndPartition, <span class="keyword">new</span> <span class="type">PartitionFetchState</span>(handleOffsetOutOfRange(topicAndPartition)))</span><br><span class="line">            <span class="keyword">case</span> _ =&gt; <span class="keyword">if</span> (isRunning.get) partitionsWithError += topicAndPartition</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (partitionsWithError.nonEmpty) &#123;</span><br><span class="line">      handlePartitionsWithErrors(partitionsWithError)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="http://img.blog.csdn.net/20160126084118702" alt="k_abstractFetcherThread_doWork"></p>
<p>基本上我们把关于Fetcher的Manager和Thread的抽象类都分析完了,现在看看Consumer是如何Fetch消息的.  </p>
<h2 id="createMessageStreams">createMessageStreams</h2><p>由ConsumerConnector创建消息流,需要指定解码器,因为要将日志反序列化(生产者写消息时对消息序列化到日志文件).  </p>
<p>consume并不真正的消费数据,只是初始化存放数据的queue.真正消费数据的是对该queue进行shallow iterator.<br>在kafka的运行过程中,会有其他的线程将数据放入partition对应的queue中. 而queue是用于KafkaStream的.<br>一旦数据添加到queue后,KafkaStream的阻塞队列就有数据了,消费者就可以从队列中消费消息.  </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createMessageStreams</span>[</span><span class="type">K</span>,<span class="type">V</span>](topicCountMap: <span class="type">Map</span>[<span class="type">String</span>,<span class="type">Int</span>], keyDecoder: <span class="type">Decoder</span>[<span class="type">K</span>], valueDecoder: <span class="type">Decoder</span>[<span class="type">V</span>]) : <span class="type">Map</span>[<span class="type">String</span>, <span class="type">List</span>[<span class="type">KafkaStream</span>[<span class="type">K</span>,<span class="type">V</span>]]] = &#123;</span><br><span class="line">  consume(topicCountMap, keyDecoder, valueDecoder)</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">consume</span>[</span><span class="type">K</span>, <span class="type">V</span>](topicCountMap: scala.collection.<span class="type">Map</span>[<span class="type">String</span>,<span class="type">Int</span>], keyDecoder: <span class="type">Decoder</span>[<span class="type">K</span>], valueDecoder: <span class="type">Decoder</span>[<span class="type">V</span>]) : <span class="type">Map</span>[<span class="type">String</span>,<span class="type">List</span>[<span class="type">KafkaStream</span>[<span class="type">K</span>,<span class="type">V</span>]]] = &#123;</span><br><span class="line">  <span class="keyword">val</span> topicCount = <span class="type">TopicCount</span>.constructTopicCount(consumerIdString, topicCountMap)</span><br><span class="line">  <span class="keyword">val</span> topicThreadIds = topicCount.getConsumerThreadIdsPerTopic</span><br><span class="line"></span><br><span class="line">  <span class="comment">// make a list of (queue,stream) pairs, one pair for each threadId 只是准备了队列和流,数据什么时候填充呢?</span></span><br><span class="line">  <span class="keyword">val</span> queuesAndStreams = topicThreadIds.values.map(threadIdSet =&gt;</span><br><span class="line">    threadIdSet.map(_ =&gt; &#123;</span><br><span class="line">      <span class="keyword">val</span> queue =  <span class="keyword">new</span> <span class="type">LinkedBlockingQueue</span>[<span class="type">FetchedDataChunk</span>](config.queuedMaxMessages)</span><br><span class="line">      <span class="keyword">val</span> stream = <span class="keyword">new</span> <span class="type">KafkaStream</span>[<span class="type">K</span>,<span class="type">V</span>](queue, config.consumerTimeoutMs, keyDecoder, valueDecoder, config.clientId)</span><br><span class="line">      (queue, stream)</span><br><span class="line">    &#125;)</span><br><span class="line">  ).flatten.toList  <span class="comment">//threadIdSet是个集合,外层的topicThreadIds.values也是集合,所以用flatten压扁为queue-stream对</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> dirs = <span class="keyword">new</span> <span class="type">ZKGroupDirs</span>(config.groupId)                  <span class="comment">// /consumers/[group_id]</span></span><br><span class="line">  registerConsumerInZK(dirs, consumerIdString, topicCount)    <span class="comment">// /consumers/[group_id]/ids/[consumer_id]</span></span><br><span class="line">  reinitializeConsumer(topicCount, queuesAndStreams)          <span class="comment">// 重新初始化消费者 ⬅️</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// 返回KafkaStream, 每个Topic都对应了多个KafkaStream. 数量和topicCount中的count一样</span></span><br><span class="line">  loadBalancerListener.kafkaMessageAndMetadataStreams.asInstanceOf[<span class="type">Map</span>[<span class="type">String</span>, <span class="type">List</span>[<span class="type">KafkaStream</span>[<span class="type">K</span>,<span class="type">V</span>]]]]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>consumerIdString</code>会返回当前Consumer在哪个ConsumerGroup的编号.每个consumer在消费组中的编号都是唯一的.<br>一个消费者,对一个topic可以使用多个线程一起消费(一个进程可以有多个线程). 当然一个消费者也可以消费多个topic.  </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">makeConsumerThreadIdsPerTopic</span>(</span>consumerIdString: <span class="type">String</span>, topicCountMap: <span class="type">Map</span>[<span class="type">String</span>,  <span class="type">Int</span>]) = &#123;</span><br><span class="line">  <span class="keyword">val</span> consumerThreadIdsPerTopicMap = <span class="keyword">new</span> mutable.<span class="type">HashMap</span>[<span class="type">String</span>, <span class="type">Set</span>[<span class="type">ConsumerThreadId</span>]]()</span><br><span class="line">  <span class="keyword">for</span> ((topic, nConsumers) &lt;- topicCountMap) &#123;                <span class="comment">// 每个topic有几个消费者线程</span></span><br><span class="line">    <span class="keyword">val</span> consumerSet = <span class="keyword">new</span> mutable.<span class="type">HashSet</span>[<span class="type">ConsumerThreadId</span>]   <span class="comment">// 一个消费者线程对应一个ConsumerThreadId</span></span><br><span class="line">    <span class="keyword">for</span> (i &lt;- <span class="number">0</span> until nConsumers)</span><br><span class="line">      consumerSet += <span class="type">ConsumerThreadId</span>(consumerIdString, i)</span><br><span class="line">    consumerThreadIdsPerTopicMap.put(topic, consumerSet)      <span class="comment">// 每个topic都有多个Consumer线程,但是只有一个消费者进程</span></span><br><span class="line">  &#125;</span><br><span class="line">  consumerThreadIdsPerTopicMap                                <span class="comment">// topic到消费者线程集合的映射</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>假设消费者C1声明了topic1:2, topic2:3. topicThreadIds=consumerThreadIdsPerTopicMap.<br>topicThreadIds.values = [ (C1_1,C1_2), (C1_1,C1_2,C1_3)]一共有5个线程,queuesAndStreams也有5个元素.  </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">consumerThreadIdsPerTopicMap = &#123;</span><br><span class="line">    topic1: [<span class="type">C1_1</span>, <span class="type">C1_2</span>],</span><br><span class="line">    topic2: [<span class="type">C1_1</span>, <span class="type">C1_2</span>, <span class="type">C1_3</span>]</span><br><span class="line">&#125;</span><br><span class="line">topicThreadIds.values = [</span><br><span class="line">    [<span class="type">C1_1</span>, <span class="type">C1_2</span>],</span><br><span class="line">    [<span class="type">C1_1</span>, <span class="type">C1_2</span>, <span class="type">C1_3</span>]</span><br><span class="line">]</span><br><span class="line">threadIdSet循环[<span class="type">C1_1</span>, <span class="type">C1_2</span>]时, 生成两个queue-&gt;stream pair. </span><br><span class="line">threadIdSet循环[<span class="type">C1_1</span>, <span class="type">C1_2</span>, <span class="type">C1_3</span>]时, 生成三个queue-&gt;stream pair. </span><br><span class="line">queuesAndStreams = [</span><br><span class="line">    (<span class="type">LinkedBlockingQueue_1</span>,<span class="type">KafkaStream_1</span>),      <span class="comment">//topic1:C1_1</span></span><br><span class="line">    (<span class="type">LinkedBlockingQueue_2</span>,<span class="type">KafkaStream_2</span>),      <span class="comment">//topic1:C1_2</span></span><br><span class="line">    (<span class="type">LinkedBlockingQueue_3</span>,<span class="type">KafkaStream_3</span>),      <span class="comment">//topic2:C1_1</span></span><br><span class="line">    (<span class="type">LinkedBlockingQueue_4</span>,<span class="type">KafkaStream_4</span>),      <span class="comment">//topic2:C1_2</span></span><br><span class="line">    (<span class="type">LinkedBlockingQueue_5</span>,<span class="type">KafkaStream_5</span>),      <span class="comment">//topic2:C1_3</span></span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<p>对于消费者而言,它只要指定要消费的topic和线程数量就可以了,其他具体这个topic分成多少个partition,<br>以及topic-partition是分布是哪个broker上,对于客户端而言都是透明的.<br>客户端关注的是我的每个线程都对应了一个队列,每个队列都是一个消息流就可以了.<br>在Producer以及前面分析的Fetcher,都是以Broker-Topic-Partition为级别的.<br>AbstractFetcherManager的fetcherThreadMap就是以brokerAndFetcherId来创建拉取线程的.<br>而消费者是通过拉取线程才有数据可以消费的,所以客户端的每个线程实际上也是针对Partition级别的.  </p>
<h3 id="registerConsumerInZK">registerConsumerInZK</h3><p>消费者需要向ZK注册,所以在一开始的时候,要连接ZK:connectZk.  </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">registerConsumerInZK</span>(</span>dirs: <span class="type">ZKGroupDirs</span>, consumerIdString: <span class="type">String</span>, topicCount: <span class="type">TopicCount</span>) &#123;</span><br><span class="line">  <span class="keyword">val</span> consumerRegistrationInfo = <span class="type">Json</span>.encode(<span class="type">Map</span>(<span class="string">"version"</span> -&gt; <span class="number">1</span>, <span class="string">"subscription"</span> -&gt; topicCount.getTopicCountMap, <span class="string">"pattern"</span> -&gt; topicCount.pattern, <span class="string">"timestamp"</span> -&gt; timestamp))</span><br><span class="line">  <span class="keyword">val</span> zkWatchedEphemeral = <span class="keyword">new</span> <span class="type">ZKCheckedEphemeral</span>(dirs.consumerRegistryDir + <span class="string">"/"</span> + consumerIdString, consumerRegistrationInfo, zkUtils.zkConnection.getZookeeper, <span class="literal">false</span>)</span><br><span class="line">  zkWatchedEphemeral.create()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="reinitializeConsumer_listener">reinitializeConsumer listener</h3><p>当前Consumer在ZK注册之后,需要重新初始化Consumer. 对于全新的消费者,注册多个监听器,在zk的对应节点的注册事件发生时,会回调监听器的方法.  </p>
<ul>
<li>将topic对应的消费者线程id及对应的LinkedBlockingQueue放入topicThreadIdAndQueues中,LinkedBlockingQueue是真正存放数据的queue</li>
<li>① 注册<code>sessionExpirationListener</code>,监听状态变化事件.在session失效重新创建session时调用</li>
<li>② 向<code>/consumers/group/ids</code>注册Child变更事件的<code>loadBalancerListener</code>,当消费组下的消费者发生变化时调用</li>
<li>③ 向<code>/brokers/topics/topic</code>注册Data变更事件的<code>topicPartitionChangeListener</code>,在topic数据发生变化时调用</li>
<li>显式调用<code>loadBalancerListener.syncedRebalance()</code>, 会调用reblance方法进行consumer的初始化工作</li>
</ul>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">reinitializeConsumer</span>[</span><span class="type">K</span>,<span class="type">V</span>](topicCount: <span class="type">TopicCount</span>, queuesAndStreams: <span class="type">List</span>[(<span class="type">LinkedBlockingQueue</span>[<span class="type">FetchedDataChunk</span>],<span class="type">KafkaStream</span>[<span class="type">K</span>,<span class="type">V</span>])]) &#123;</span><br><span class="line">  <span class="keyword">val</span> dirs = <span class="keyword">new</span> <span class="type">ZKGroupDirs</span>(config.groupId)</span><br><span class="line">  <span class="comment">// ② listener to consumer and partition changes</span></span><br><span class="line">  <span class="keyword">if</span> (loadBalancerListener == <span class="literal">null</span>) &#123;</span><br><span class="line">    <span class="keyword">val</span> topicStreamsMap = <span class="keyword">new</span> mutable.<span class="type">HashMap</span>[<span class="type">String</span>,<span class="type">List</span>[<span class="type">KafkaStream</span>[<span class="type">K</span>,<span class="type">V</span>]]]</span><br><span class="line">    loadBalancerListener = <span class="keyword">new</span> <span class="type">ZKRebalancerListener</span>(config.groupId, consumerIdString, topicStreamsMap.asInstanceOf[scala.collection.mutable.<span class="type">Map</span>[<span class="type">String</span>, <span class="type">List</span>[<span class="type">KafkaStream</span>[_,_]]]])</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// ① create listener for session expired event if not exist yet</span></span><br><span class="line">  <span class="keyword">if</span> (sessionExpirationListener == <span class="literal">null</span>) sessionExpirationListener = <span class="keyword">new</span> <span class="type">ZKSessionExpireListener</span>(dirs, consumerIdString, topicCount, loadBalancerListener)</span><br><span class="line">  <span class="comment">// ③ create listener for topic partition change event if not exist yet</span></span><br><span class="line">  <span class="keyword">if</span> (topicPartitionChangeListener == <span class="literal">null</span>) topicPartitionChangeListener = <span class="keyword">new</span> <span class="type">ZKTopicPartitionChangeListener</span>(loadBalancerListener)</span><br><span class="line"></span><br><span class="line">  <span class="comment">// listener to consumer and partition changes</span></span><br><span class="line">  zkUtils.zkClient.subscribeStateChanges(sessionExpirationListener)</span><br><span class="line">  zkUtils.zkClient.subscribeChildChanges(dirs.consumerRegistryDir, loadBalancerListener)</span><br><span class="line">  <span class="comment">// register on broker partition path changes.</span></span><br><span class="line">  topicStreamsMap.foreach &#123; topicAndStreams =&gt; </span><br><span class="line">    zkUtils.zkClient.subscribeDataChanges(<span class="type">BrokerTopicsPath</span> + <span class="string">"/"</span> + topicAndStreams._1, topicPartitionChangeListener)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// explicitly trigger load balancing for this consumer</span></span><br><span class="line">  loadBalancerListener.syncedRebalance()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>ZKRebalancerListener传入ZKSessionExpireListener和ZKTopicPartitionChangeListener.它们都会使用ZKRebalancerListener完成自己的工作. </p>
<p><strong>ZKSessionExpireListener</strong>  </p>
<p>当Session失效时,新的会话建立时,立即进行rebalance操作.  </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ZKSessionExpireListener</span>(</span><span class="keyword">val</span> dirs: <span class="type">ZKGroupDirs</span>, <span class="keyword">val</span> consumerIdString: <span class="type">String</span>, <span class="keyword">val</span> topicCount: <span class="type">TopicCount</span>, <span class="keyword">val</span> loadBalancerListener: <span class="type">ZKRebalancerListener</span>) </span><br><span class="line">  <span class="keyword">extends</span> <span class="type">IZkStateListener</span> &#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">handleNewSession</span>(</span>) &#123;</span><br><span class="line">    loadBalancerListener.resetState()</span><br><span class="line">    registerConsumerInZK(dirs, consumerIdString, topicCount)</span><br><span class="line">    loadBalancerListener.syncedRebalance()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>ZKTopicPartitionChangeListener</strong>  </p>
<p>当topic的数据变化时,通过触发的方式启动rebalance操作.  </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ZKTopicPartitionChangeListener</span>(</span><span class="keyword">val</span> loadBalancerListener: <span class="type">ZKRebalancerListener</span>) </span><br><span class="line">  <span class="keyword">extends</span> <span class="type">IZkDataListener</span> &#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">handleDataChange</span>(</span>dataPath : <span class="type">String</span>, data: <span class="type">Object</span>) &#123;</span><br><span class="line">    loadBalancerListener.rebalanceEventTriggered()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>ZKRebalancerListener</strong>  </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ZKRebalancerListener</span>(</span><span class="keyword">val</span> group: <span class="type">String</span>, <span class="keyword">val</span> consumerIdString: <span class="type">String</span>,</span><br><span class="line">                           <span class="keyword">val</span> kafkaMessageAndMetadataStreams: mutable.<span class="type">Map</span>[<span class="type">String</span>,<span class="type">List</span>[<span class="type">KafkaStream</span>[_,_]]])</span><br><span class="line">  <span class="keyword">extends</span> <span class="type">IZkChildListener</span> &#123;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> isWatcherTriggered = <span class="literal">false</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> lock = <span class="keyword">new</span> <span class="type">ReentrantLock</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> cond = lock.newCondition()</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> watcherExecutorThread = <span class="keyword">new</span> <span class="type">Thread</span>(consumerIdString + <span class="string">"_watcher_executor"</span>) &#123;</span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">run</span>(</span>) &#123;</span><br><span class="line">      <span class="keyword">var</span> doRebalance = <span class="literal">false</span></span><br><span class="line">      <span class="keyword">while</span> (!isShuttingDown.get) &#123;</span><br><span class="line">          lock.lock()</span><br><span class="line">          <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">// 如果isWatcherTriggered=false,则不会触发syncedRebalance. 等待1秒后,继续判断</span></span><br><span class="line">            <span class="keyword">if</span> (!isWatcherTriggered)</span><br><span class="line">              cond.await(<span class="number">1000</span>, <span class="type">TimeUnit</span>.<span class="type">MILLISECONDS</span>) <span class="comment">// wake up periodically so that it can check the shutdown flag</span></span><br><span class="line">          &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            <span class="comment">// 不管isWatcherTriggered值是多少,在每次循环时,都会执行. 如果isWatcherTriggered=true,则会执行syncedRebalance</span></span><br><span class="line">            doRebalance = isWatcherTriggered</span><br><span class="line">            <span class="comment">// 重新设置isWatcherTriggered=false, 因为其他线程触发一次后就失效了,想要再次触发,必须再次设置isWatcherTriggered=true</span></span><br><span class="line">            isWatcherTriggered = <span class="literal">false</span></span><br><span class="line">            lock.unlock()</span><br><span class="line">          &#125;</span><br><span class="line">          <span class="keyword">if</span> (doRebalance) syncedRebalance        <span class="comment">// 只有每次rebalanceEventTriggered时,才会调用一次syncedRebalance</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  watcherExecutorThread.start()</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 触发rebalance开始进行, 修改isWatcherTriggered标志位,触发cond条件运行</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">rebalanceEventTriggered</span>(</span>) &#123;</span><br><span class="line">    inLock(lock) &#123;</span><br><span class="line">      isWatcherTriggered = <span class="literal">true</span></span><br><span class="line">      cond.signalAll()</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p><img src="http://img.blog.csdn.net/20160126162107763" alt="k_listener"></p>
<p>reinitializeConsumer的topicStreamsMap是从(topic,thread)-&gt;(queue,stream)根据topic获取stream得来的.  </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> topicStreamsMap = loadBalancerListener.kafkaMessageAndMetadataStreams</span><br><span class="line"><span class="comment">// map of &#123;topic -&gt; Set(thread-1, thread-2, ...)&#125;</span></span><br><span class="line"><span class="keyword">val</span> consumerThreadIdsPerTopic: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">Set</span>[<span class="type">ConsumerThreadId</span>]] = topicCount.getConsumerThreadIdsPerTopic</span><br><span class="line"><span class="comment">// list of (Queue, KafkaStreams): (queue1,stream1),(queue2,stream2),...</span></span><br><span class="line"><span class="keyword">val</span> allQueuesAndStreams = queuesAndStreams </span><br><span class="line"></span><br><span class="line"><span class="comment">// (topic,thread-1), (topic,thread-2), ...</span></span><br><span class="line"><span class="keyword">val</span> topicThreadIds = consumerThreadIdsPerTopic.map &#123;</span><br><span class="line">  <span class="keyword">case</span>(topic, threadIds) =&gt; threadIds.map((topic, _))  <span class="comment">//一个topic有多个线程:threadIds,将threadIds中每个threadId都添加上topic标识</span></span><br><span class="line">&#125;.flatten</span><br><span class="line"><span class="comment">// (topic,thread-1), (queue1, stream1)</span></span><br><span class="line"><span class="comment">// (topic,thread-2), (queue2, stream2)</span></span><br><span class="line"><span class="keyword">val</span> threadQueueStreamPairs = topicThreadIds.zip(allQueuesAndStreams)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> groupedByTopic = threadQueueStreamPairs.groupBy(_._1._1)</span><br><span class="line"><span class="comment">// 根据topic分组之后, groupedByTopic的每个元素的_1为topic,_2为属于这个topic的所有(topic,thread-1), (queue1, stream1)形式的列表</span></span><br><span class="line">groupedByTopic.foreach(e =&gt; &#123;</span><br><span class="line">  <span class="keyword">val</span> topic = e._1</span><br><span class="line">  <span class="comment">// e._2是一个List[((topic,thread),(queue,stream))],下面收集这个topic的所有stream</span></span><br><span class="line">  <span class="keyword">val</span> streams = e._2.map(_._2._2).toList</span><br><span class="line">  topicStreamsMap += (topic -&gt; streams)</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
<h3 id="ZKRebalancerListener_rebalance">ZKRebalancerListener rebalance</h3><ul>
<li>关闭数据抓取线程，获取之前为topic设置的存放数据的queue并清空该queue</li>
<li>为各个partition重新分配threadid</li>
<li>获取partition最新的offset并重新初始化新的PartitionTopicInf，其中queue就是上面说的存放数据的那个queue，consumedOffset和fetchedOffset都为partition最新的offset</li>
<li>重新将partition对应的新的consumer信息写入zookeeper</li>
<li>重新创建partition的fetcher线程</li>
</ul>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">rebalance</span>(</span>cluster: <span class="type">Cluster</span>): <span class="type">Boolean</span> = &#123;</span><br><span class="line">  <span class="keyword">val</span> myTopicThreadIdsMap = <span class="type">TopicCount</span>.constructTopicCount(group, consumerIdString, zkUtils, config.excludeInternalTopics).getConsumerThreadIdsPerTopic</span><br><span class="line">  <span class="keyword">val</span> brokers = zkUtils.getAllBrokersInCluster()</span><br><span class="line">  <span class="keyword">if</span> (brokers.size == <span class="number">0</span>) &#123;</span><br><span class="line">    zkUtils.zkClient.subscribeChildChanges(<span class="type">BrokerIdsPath</span>, loadBalancerListener)</span><br><span class="line">    <span class="literal">true</span></span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// 停止fetcher线程防止数据重复.如果当前调整失败了,被释放的partitions可能被其他消费者拥有.而没有先停止fetcher的话,原先的消费者仍然会和新的拥有者共同消费同一份数据.  </span></span><br><span class="line">    closeFetchers(cluster, kafkaMessageAndMetadataStreams, myTopicThreadIdsMap)</span><br><span class="line">    releasePartitionOwnership(topicRegistry)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> assignmentContext = <span class="keyword">new</span> <span class="type">AssignmentContext</span>(group, consumerIdString, config.excludeInternalTopics, zkUtils)</span><br><span class="line">    <span class="keyword">val</span> globalPartitionAssignment = partitionAssignor.assign(assignmentContext)</span><br><span class="line">    <span class="keyword">val</span> partitionAssignment = globalPartitionAssignment.get(assignmentContext.consumerId)</span><br><span class="line">    <span class="keyword">val</span> currentTopicRegistry = <span class="keyword">new</span> <span class="type">Pool</span>[<span class="type">String</span>, <span class="type">Pool</span>[<span class="type">Int</span>, <span class="type">PartitionTopicInfo</span>]](valueFactory = <span class="type">Some</span>((topic: <span class="type">String</span>) =&gt; <span class="keyword">new</span> <span class="type">Pool</span>[<span class="type">Int</span>, <span class="type">PartitionTopicInfo</span>]))</span><br><span class="line"></span><br><span class="line">    <span class="comment">// fetch current offsets for all topic-partitions</span></span><br><span class="line">    <span class="keyword">val</span> topicPartitions = partitionAssignment.keySet.toSeq</span><br><span class="line">    <span class="keyword">val</span> offsetFetchResponseOpt = fetchOffsets(topicPartitions)</span><br><span class="line">    <span class="keyword">val</span> offsetFetchResponse = offsetFetchResponseOpt.get</span><br><span class="line">    topicPartitions.foreach(topicAndPartition =&gt; &#123;</span><br><span class="line">        <span class="keyword">val</span> (topic, partition) = topicAndPartition.asTuple</span><br><span class="line">        <span class="keyword">val</span> offset = offsetFetchResponse.requestInfo(topicAndPartition).offset</span><br><span class="line">        <span class="keyword">val</span> threadId = partitionAssignment(topicAndPartition)</span><br><span class="line">        addPartitionTopicInfo(currentTopicRegistry, partition, topic, offset, threadId)</span><br><span class="line">    &#125;)</span><br><span class="line">    <span class="comment">// 在这里分配partition给consumer,只有updateFetcher才算平衡成功,即最后返回true</span></span><br><span class="line">    <span class="keyword">if</span>(reflectPartitionOwnershipDecision(partitionAssignment)) &#123;</span><br><span class="line">        allTopicsOwnedPartitionsCount = partitionAssignment.size</span><br><span class="line">        topicRegistry = currentTopicRegistry</span><br><span class="line">        updateFetcher(cluster)</span><br><span class="line">        <span class="literal">true</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>PartitionOwnership</strong>  </p>
<p>topicRegistry的数据结构是: <code>topic -&gt; (partition -&gt; PartitionTopicInfo)</code><br>当partition被consumer所拥有后, 会在zk中创建<code>/consumers/[group_id]/owner/[topic]/[partition_id] --&gt; consumer_node_id</code><br>释放所有partition的ownership, 数据来源与topicRegistry的topic-partition(消费者所属的group_id也是确定的).<br>所以deletePartitionOwnershipFromZK会删除<code>/consumers/[group_id]/owner/[topic]/[partition_id]</code>节点.<br>这样partition没有了owner,说明这个partition不会被consumer消费了,也就相当于consumer释放了partition.  </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">releasePartitionOwnership</span>(</span>localTopicRegistry: <span class="type">Pool</span>[<span class="type">String</span>, <span class="type">Pool</span>[<span class="type">Int</span>, <span class="type">PartitionTopicInfo</span>]])= &#123;</span><br><span class="line">  <span class="keyword">for</span> ((topic, infos) &lt;- localTopicRegistry) &#123;</span><br><span class="line">    <span class="keyword">for</span>(partition &lt;- infos.keys) &#123;</span><br><span class="line">      deletePartitionOwnershipFromZK(topic, partition)</span><br><span class="line">    &#125;</span><br><span class="line">    localTopicRegistry.remove(topic)</span><br><span class="line">  &#125;</span><br><span class="line">  allTopicsOwnedPartitionsCount = <span class="number">0</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">deletePartitionOwnershipFromZK</span>(</span>topic: <span class="type">String</span>, partition: <span class="type">Int</span>) &#123;</span><br><span class="line">  <span class="keyword">val</span> topicDirs = <span class="keyword">new</span> <span class="type">ZKGroupTopicDirs</span>(group, topic)</span><br><span class="line">  <span class="keyword">val</span> znode = topicDirs.consumerOwnerDir + <span class="string">"/"</span> + partition</span><br><span class="line">  zkUtils.deletePath(znode)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>重建ownership. 参数partitionAssignment会指定partition(TopicAndPartition)要分配给哪个consumer(ConsumerThreadId)消费的.  </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">reflectPartitionOwnershipDecision</span>(</span>partitionAssignment: <span class="type">Map</span>[<span class="type">TopicAndPartition</span>, <span class="type">ConsumerThreadId</span>]): <span class="type">Boolean</span> = &#123;</span><br><span class="line">  <span class="keyword">var</span> successfullyOwnedPartitions : <span class="type">List</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = <span class="type">Nil</span></span><br><span class="line">  <span class="keyword">val</span> partitionOwnershipSuccessful = partitionAssignment.map &#123; partitionOwner =&gt;</span><br><span class="line">    <span class="keyword">val</span> topic = partitionOwner._1.topic</span><br><span class="line">    <span class="keyword">val</span> partition = partitionOwner._1.partition</span><br><span class="line">    <span class="keyword">val</span> consumerThreadId = partitionOwner._2</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 返回/consumers/[group_id]/owner/[topic]/[partition_id]节点路径,然后创建节点,节点内容为:consumerThreadId</span></span><br><span class="line">    <span class="keyword">val</span> partitionOwnerPath = zkUtils.getConsumerPartitionOwnerPath(group, topic, partition)</span><br><span class="line">    zkUtils.createEphemeralPathExpectConflict(partitionOwnerPath, consumerThreadId.toString)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 成功创建的节点,加入到列表中</span></span><br><span class="line">    successfullyOwnedPartitions ::= (topic, partition)</span><br><span class="line">    <span class="literal">true</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 判断上面的创建节点操作(为consumer分配partition)是否有错误,一旦有一个有问题,就全部回滚(删除掉).只有所有成功才算成功</span></span><br><span class="line">  <span class="keyword">val</span> hasPartitionOwnershipFailed = partitionOwnershipSuccessful.foldLeft(<span class="number">0</span>)((sum, decision) =&gt; sum + (<span class="keyword">if</span>(decision) <span class="number">0</span> <span class="keyword">else</span> <span class="number">1</span>))</span><br><span class="line">  <span class="keyword">if</span>(hasPartitionOwnershipFailed &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    successfullyOwnedPartitions.foreach(topicAndPartition =&gt; deletePartitionOwnershipFromZK(topicAndPartition._1, topicAndPartition._2))</span><br><span class="line">    <span class="literal">false</span></span><br><span class="line">  &#125; <span class="keyword">else</span> <span class="literal">true</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="Ref">Ref</h2><ul>
<li><a href="http://uohzoaix.github.io/studies" target="_blank" rel="external">http://uohzoaix.github.io/studies</a></li>
</ul>

      
    </div>
    
  </div>
  
    
<div class="copyright">
  <p><span>本文标题:</span><a href="/2016/01/19/2016-01-19-Kafka-Consumer-scala/">Kafka源码分析 Consumer</a></p>
  <p><span>文章作者:</span><a href="/" title="访问 任何忧伤,都抵不过世界的美丽 的个人博客">任何忧伤,都抵不过世界的美丽</a></p>
  <p><span>发布时间:</span>2016年01月19日 - 00时00分</p>
  <p><span>最后更新:</span>2016年01月26日 - 17时04分</p>
  <p>
    <span>原始链接:</span><a href="/2016/01/19/2016-01-19-Kafka-Consumer-scala/" title="Kafka源码分析 Consumer">http://github.com/zqhxuyuan/2016/01/19/2016-01-19-Kafka-Consumer-scala/</a>
    <span class="btn" data-clipboard-text="原文: http://github.com/zqhxuyuan/2016/01/19/2016-01-19-Kafka-Consumer-scala/　　作者: 任何忧伤,都抵不过世界的美丽" title="点击复制文章链接">
        <i class="fa fa-clipboard"></i>
    </span>
  </p>
  <p><span>许可协议:</span><i class="fa fa-creative-commons"></i> <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/3.0/cn/" title="中国大陆 (CC BY-NC-SA 3.0 CN)">"署名-非商用-相同方式共享 3.0"</a> 转载请保留原文链接及作者。</p>
  <script src="/js/clipboard.min.js"></script>
  <script> var clipboard = new Clipboard('.btn'); </script>
</div>
<style type="text/css">
  .copyright p .btn {
    margin-left: 1em;
  }
  .copyright:hover p .btn::after {
    content: "复制"
  }
  .copyright p .btn:hover {
      color: gray;
      cursor: pointer;
    };
</style>



<nav id="article-nav">
  
    <div id="article-nav-newer" class="article-nav-title">
      <a href="/2016/01/22/2016-01-22-Kafka-Consumer-java/">
        Kafka源码分析 Consumer
      </a>
    </div>
  
  
    <div id="article-nav-older" class="article-nav-title">
      <a href="/2016/01/15/2015-01-15-Kafka-Delay/">
        Kafka源码分析 DelayOperation
      </a>
    </div>
  
</nav>

  
</article>

<!-- 默认显示文章目录，在文章---前输入toc: false关闭目录 -->
<!-- Show TOC and tocButton in default, Hide TOC via putting "toc: false" before "---" at [post].md -->
<div id="toc" class="toc-article">
<strong class="toc-title">文章目录</strong>
<ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Consumer_Example(old_and_high-level)"><span class="toc-number">1.</span> <span class="toc-text">Consumer Example(old and high-level)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ConsumerConnector"><span class="toc-number">2.</span> <span class="toc-text">ConsumerConnector</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ZookeeperConsumerConnector"><span class="toc-number">3.</span> <span class="toc-text">ZookeeperConsumerConnector</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#zk_and_broker"><span class="toc-number">3.1.</span> <span class="toc-text">zk and broker</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#zk_and_consumer"><span class="toc-number">3.2.</span> <span class="toc-text">zk and consumer</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#init"><span class="toc-number">4.</span> <span class="toc-text">init</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#AbstractFetcherManager"><span class="toc-number">4.1.</span> <span class="toc-text">AbstractFetcherManager</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#AbstractFetcherThread_addPartitions"><span class="toc-number">4.2.</span> <span class="toc-text">AbstractFetcherThread addPartitions</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#FetchRequest_&_PartitionData"><span class="toc-number">4.3.</span> <span class="toc-text">FetchRequest & PartitionData</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#AbstractFetcherThread_doWork"><span class="toc-number">4.4.</span> <span class="toc-text">AbstractFetcherThread doWork</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#createMessageStreams"><span class="toc-number">5.</span> <span class="toc-text">createMessageStreams</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#registerConsumerInZK"><span class="toc-number">5.1.</span> <span class="toc-text">registerConsumerInZK</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#reinitializeConsumer_listener"><span class="toc-number">5.2.</span> <span class="toc-text">reinitializeConsumer listener</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#ZKRebalancerListener_rebalance"><span class="toc-number">5.3.</span> <span class="toc-text">ZKRebalancerListener rebalance</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Ref"><span class="toc-number">6.</span> <span class="toc-text">Ref</span></a></li></ol>
</div>
<style type="text/css">
  .left-col .switch-btn {
    display: none;
  }
  .left-col .switch-area {
    display: none;
  }
</style>

<input type="button" id="tocButton" value="隐藏目录"  title="点击按钮隐藏或者显示文章目录">
<script type="text/javascript">
  var toc_button= document.getElementById("tocButton");
  var toc_div= document.getElementById("toc");
  /* Show or hide toc when click on tocButton.
  通过点击设置的按钮显示或者隐藏文章目录.*/
  toc_button.onclick=function(){
  if(toc_div.style.display=="none"){
  toc_div.style.display="block";
  toc_button.value="隐藏目录";
  document.getElementById("switch-btn").style.display="none";
  document.getElementById("switch-area").style.display="none";
  }
  else{
  toc_div.style.display="none";
  toc_button.value="显示目录";
  document.getElementById("switch-btn").style.display="block";
  document.getElementById("switch-area").style.display="block";
  }
  }
    if ($(".toc").length < 1) {
        $("#toc").css("display","none");
        $("#tocButton").css("display","none");
        $(".switch-btn").css("display","block");
        $(".switch-area").css("display","block");
    }
</script>


    <style>
        .toc {
            white-space: nowrap;
            overflow-x: hidden;
        }
    </style>

    <script>
        $(document).ready(function() {
            $(".toc li a").mouseover(function() {
                var title = $(this).attr('href');
                $(this).attr("title", title);
            });
        })
    </script>




<div class="share">
	<div class="bdsharebuttonbox">
	<a href="#" class="bds_more" data-cmd="more"></a>
	<a href="#" class="bds_tsina" data-cmd="tsina" title="分享到新浪微博"></a>
	<a href="#" class="bds_sqq" data-cmd="sqq" title="分享给 QQ 好友"></a>
	<a href="#" class="bds_copy" data-cmd="copy" title="复制网址"></a>
	<a href="#" class="bds_mail" data-cmd="mail" title="通过邮件分享"></a>
	<a href="#" class="bds_weixin" data-cmd="weixin" title="生成文章二维码"></a>
	</div>
	<script>
	window._bd_share_config={
		"common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"0","bdSize":"24"},"share":{}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];
	</script>
</div>







    <style type="text/css">
    #scroll {
      display: none;
    }
    </style>
    <div class="scroll">
    <a href="#" title="返回顶部"><i class="fa fa-arrow-up"></i></a>
    <a href="#comments" title="查看评论"><i class="fa fa-comments-o"></i></a>
    <a href="#footer" title="转到底部"><i class="fa fa-arrow-down"></i></a>
    </div>


  
  
    
    <div  class="post-nav-button">
    <a href="/2016/01/22/2016-01-22-Kafka-Consumer-java/" title="上一篇: Kafka源码分析 Consumer">
    <i class="fa fa-angle-left"></i>
    </a>
    <a href="/2016/01/15/2015-01-15-Kafka-Delay/" title="下一篇: Kafka源码分析 DelayOperation">
    <i class="fa fa-angle-right"></i>
    </a>
    </div>
  



    
        <link rel="stylesheet" href="/fancybox/jquery.fancybox.css" type="text/css">
        <script>
        var yiliaConfig = {
        fancybox: true,
        mathjax: true,
        animate: true,
        isHome: false,
        isPost: true,
        isArchive: false,
        isTag: false,
        isCategory: false,
        open_in_new: false
        }
        </script>
        
</div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
      <div class="footer-left">
        &copy; 2016 任何忧伤,都抵不过世界的美丽
      </div>
        <div class="footer-right">
          <a href="http://hexo.io/" target="_blank" title="快速、简洁且高效的静态博客框架">Hexo</a>  Theme <a href="https://github.com/MOxFIVE/hexo-theme-yelee" target="_blank" title="简而不减双栏 Hexo 博客主题">Yelee</a> by MOxFIVE
        </div>
    </div>
    <div class="visit">
      <span id="busuanzi_container_site_pv" style='display:none'>
        <span id="site-visit" >本站到访数: 
        <span id="busuanzi_value_site_uv"></span>
        </span>
      </span>
      <span id="busuanzi_container_page_pv" style='display:none'>
        <span id="page-visit">, 本页阅读量: 
        <span id="busuanzi_value_page_pv"></span>
        </span>
      </span>
    </div>
  </div>
</footer>
    </div>
    

<script src="http://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js" type="text/javascript"></script>
<script src="/js/main.js" type="text/javascript"></script>

<script>
  var backgroundnum = 5;
  var backgroundimg = "url(/background/bg-x.jpg)".replace(/x/gi, Math.ceil(Math.random() * backgroundnum));

  $("body").css({"background": backgroundimg, "background-attachment": "fixed", "background-size": "cover"});
</script>




<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<div class="scroll" id="scroll">
<a href="#" title="返回顶部"><i class="fa fa-arrow-up"></i></a>
<a href="#footer" title="转到底部"><i class="fa fa-arrow-down"></i></a>
</div>

<script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>
  </div>
</body>
</html>