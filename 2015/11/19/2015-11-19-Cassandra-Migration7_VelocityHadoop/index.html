<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Cassandra数据迁移 分离表 | zqhxuyuan</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="使用Hadoop-sstable读取Cassandra数据">
<meta property="og:type" content="article">
<meta property="og:title" content="Cassandra数据迁移 分离表">
<meta property="og:url" content="http://github.com/zqhxuyuan/2015/11/19/2015-11-19-Cassandra-Migration7_VelocityHadoop/index.html">
<meta property="og:site_name" content="zqhxuyuan">
<meta property="og:description" content="使用Hadoop-sstable读取Cassandra数据">
<meta property="og:image" content="http://img.blog.csdn.net/20151119195500163">
<meta property="og:image" content="http://img.blog.csdn.net/20151119195515238">
<meta property="og:image" content="http://img.blog.csdn.net/20151119195528693">
<meta property="og:image" content="http://img.blog.csdn.net/20151119195541715">
<meta property="og:image" content="http://img.blog.csdn.net/20151119195554022">
<meta property="og:updated_time" content="2015-12-19T13:17:48.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Cassandra数据迁移 分离表">
<meta name="twitter:description" content="使用Hadoop-sstable读取Cassandra数据">
  
    <link rel="alternative" href="/atom.xml" title="zqhxuyuan" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link rel="stylesheet" href="/css/style.css" type="text/css">
  <link rel="stylesheet" href="/font-awesome/css/font-awesome.min.css">
  <link rel="apple-touch-icon" href="/apple-touch-icon.png">
</head>
<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			
			<img lazy-src="https://avatars1.githubusercontent.com/u/1088525?v=3&amp;s=180" class="js-avatar">
			
		</a>

		<hgroup>
		  <h1 class="header-author"><a href="/">任何忧伤,都抵不过世界的美丽</a></h1>
		</hgroup>

		
				


		
			<div id="switch-btn" class="switch-btn">
				<div class="icon">
					<div class="icon-ctn">
						<div class="icon-wrap icon-house" data-idx="0">
							<div class="birdhouse"></div>
							<div class="birdhouse_holes"></div>
						</div>
						<div class="icon-wrap icon-ribbon hide" data-idx="1">
							<div class="ribbon"></div>
						</div>
						
						
						<div class="icon-wrap icon-me hide" data-idx="3">
							<div class="user"></div>
							<div class="shoulder"></div>
						</div>
						
					</div>
					
				</div>
				<div class="tips-box hide">
					<div class="tips-arrow"></div>
					<ul class="tips-inner">
						<li>菜单</li>
						<li>标签</li>
						
						
						<li>关于我</li>
						
					</ul>
				</div>
			</div>
		

		<div id="switch-area" class="switch-area">
			<div class="switch-wrap">
				<section class="switch-part switch-part1">
					<nav class="header-menu">
						<ul>
						
							<li><a href="/">主页</a></li>
				        
							<li><a href="/archives/">归档</a></li>
				        
							<li><a href="/tags/">标签</a></li>
				        
							<li><a href="/about/">关于</a></li>
				        
						</ul>
					</nav>
					<nav class="header-nav">
						<ul class="social">
							
								<li id="新浪微博"><a class="新浪微博" target="_blank" href="http://weibo.com/xuyuantree" title="新浪微博"></a></li>
					        
								<li id="GitHub"><a class="GitHub" target="_blank" href="http://github.com/zqhxuyuan" title="GitHub"></a></li>
					        
						</ul>
					</nav>
				</section>
				
				
				<section class="switch-part switch-part2">
					<div class="widget tagcloud" id="js-tagcloud">
						<a href="/tags/apex/" style="font-size: 10px;">apex</a> <a href="/tags/cassandra/" style="font-size: 20px;">cassandra</a> <a href="/tags/drill/" style="font-size: 18px;">drill</a> <a href="/tags/druid/" style="font-size: 14px;">druid</a> <a href="/tags/elasticsearch/" style="font-size: 10px;">elasticsearch</a> <a href="/tags/geode/" style="font-size: 10px;">geode</a> <a href="/tags/hbase/" style="font-size: 16px;">hbase</a> <a href="/tags/ignite/" style="font-size: 10px;">ignite</a> <a href="/tags/spark/" style="font-size: 14px;">spark</a> <a href="/tags/storm/" style="font-size: 16px;">storm</a> <a href="/tags/timeseries/" style="font-size: 12px;">timeseries</a> <a href="/tags/work/" style="font-size: 12px;">work</a>
					</div>
				</section>
				
				
				

				
				
				<section class="switch-part switch-part3">
				
					<div id="js-aboutme">BIG(DATA)</div>
				</section>
				
			</div>
		</div>
	</header>				
</div>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
  	<div class="overlay">
  		<div class="slider-trigger"></div>
  		<h1 class="header-author js-mobile-header hide"><a href="/" title="回到主页">任何忧伤,都抵不过世界的美丽</a></h1>
  	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<a href="/" class="profilepic">
				<img lazy-src="https://avatars1.githubusercontent.com/u/1088525?v=3&amp;s=180" class="js-avatar">
			</a>
			<hgroup>
			  <h1 class="header-author"><a href="/" title="回到主页">任何忧伤,都抵不过世界的美丽</a></h1>
			</hgroup>
			
			<nav class="header-menu">
				<ul>
				
					<li><a href="/">主页</a></li>
		        
					<li><a href="/archives/">归档</a></li>
		        
					<li><a href="/tags/">标签</a></li>
		        
					<li><a href="/about/">关于</a></li>
		        
		        <div class="clearfix"></div>
				</ul>
			</nav>
			<nav class="header-nav">
						<ul class="social">
							
								<li id="新浪微博"><a class="新浪微博" target="_blank" href="http://weibo.com/xuyuantree" title="新浪微博"></a></li>
					        
								<li id="GitHub"><a class="GitHub" target="_blank" href="http://github.com/zqhxuyuan" title="GitHub"></a></li>
					        
						</ul>
			</nav>
		</header>				
	</div>
</nav>
      <div class="body-wrap"><article id="post-2015-11-19-Cassandra-Migration7_VelocityHadoop" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2015/11/19/2015-11-19-Cassandra-Migration7_VelocityHadoop/" class="article-date">
  	<time datetime="2015-11-18T16:00:00.000Z" itemprop="datePublished">2015-11-19</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Cassandra数据迁移 分离表
    </h1>
  

      </header>
      
      <div class="article-info article-info-post">
        
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/work/">work</a>
	</div>


        
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/cassandra/">cassandra</a></li></ul>
	</div>

        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <p>使用Hadoop-sstable读取Cassandra数据<br><a id="more"></a></p>
<h2 id="hadoop-sstable">hadoop-sstable</h2><h3 id="1-上传hdfs文件">1.上传hdfs文件</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">nohup hadoop fs -put <span class="number">192.168</span><span class="number">.47</span><span class="number">.224</span> forseti_velocity &amp;</span><br><span class="line"></span><br><span class="line">hadoop fs -ls /user/qihuang.zheng/forseti_velocity/<span class="number">192.168</span><span class="number">.47</span><span class="number">.224</span>  | grep Data | wc -l</span><br><span class="line"><span class="number">158</span></span><br><span class="line">ls <span class="number">192.168</span><span class="number">.47</span><span class="number">.224</span> | grep Data | wc -l</span><br><span class="line"><span class="number">397</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>观察网卡的流量在300M-600M之间, 但并没有对线上应用造成影响</p>
<p>使用jps查看进程是否结束, fs -put的进程是FsShell. MR作业的进程是RunJar.  </p>
<p>每个节点上传到HDFS的文件夹约定:<br>大文件为IP,都放在一个文件夹内. 小文件为IP.2, 从原先spark分组的velocity_snapshot,所以有很多小文件夹. </p>
<p>本地文件和HDFS文件的大小比较, 基本是一样的并不会减少或增加(但是HDFS的副本是3个所以实际占用的大小是3倍) </p>
</blockquote>
<h3 id="2-SSTable写到HDFS">2.SSTable写到HDFS</h3><p>读取C*的SSTable,一条记录分成三条,其中一条为空,另外两条是两个RegularColumn的字段名称:  </p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">fenqile</span><span class="pseudo">:fenqile_web</span><span class="pseudo">:smartId</span><span class="pseudo">:11111111111111</span>: ①</span><br><span class="line"><span class="tag">fenqile</span><span class="pseudo">:fenqile_web</span><span class="pseudo">:smartId</span><span class="pseudo">:11111111111111</span><span class="pseudo">:event</span> ②</span><br><span class="line"><span class="tag">fenqile</span><span class="pseudo">:fenqile_web</span><span class="pseudo">:smartId</span><span class="pseudo">:11111111111111</span><span class="pseudo">:sequence_id</span> ③</span><br></pre></td></tr></table></figure>
<p>HDFS中的输出示例: key为attribute, value为partner_code:app_name:type:timestamp:event:eventJSONData  </p>
<figure class="highlight nimrod"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">① <span class="type">KeyValue</span>以制表符分隔</span><br><span class="line">[qihuang.zheng@spark047219 ~]$ hadoop fs -cat /user/qihuang.zheng/forseti_velocity_result/<span class="number">192</span>.<span class="number">168</span>.<span class="number">47</span>.<span class="number">224</span>/part-m-<span class="number">00000</span> | head</span><br><span class="line"><span class="number">111111111111111111</span>  aixuedai:aixuedai:idNumber:<span class="number">111111111111111111</span>:event:<span class="decorator">&#123;....&#125;</span></span><br><span class="line"><span class="number">111111111111111111</span>  qufenqi:qufenqi_web:idNumber:<span class="number">111111111111111111</span>:event:<span class="decorator">&#123;.....&#125;</span></span><br><span class="line"></span><br><span class="line">② <span class="type">KeyValue</span>一起作为<span class="type">Map</span>的<span class="type">Key</span>输出,<span class="type">Map</span>的<span class="type">Value</span>为null(去掉了event字段名称)</span><br><span class="line">[qihuang.zheng@spark047219 ~]$ hadoop fs -cat /user/qihuang.zheng/forseti_velocity_result/<span class="number">192</span>.<span class="number">168</span>.<span class="number">47</span>.<span class="number">224</span>.<span class="number">1</span>/part-m-<span class="number">00000</span> | head</span><br><span class="line"><span class="number">111111111111111111</span>:aixuedai:aixuedai:idNumber:<span class="number">111111111111111111</span>:<span class="decorator">&#123;...&#125;</span></span><br><span class="line"><span class="number">111111111111111111</span>:qufenqi:qufenqi_web:idNumber:<span class="number">111111111111111111</span>:<span class="decorator">&#123;....&#125;</span></span><br><span class="line"></span><br><span class="line">③ 对记录进行过滤,<span class="type">KV</span>制表符分隔并去掉event字段(和原始文件对比,发现输出结果几乎是sstable的两倍):  </span><br><span class="line">[qihuang.zheng@spark047219 ~]$ hadoop fs -du -h /user/qihuang.zheng/forseti_velocity_result</span><br><span class="line"><span class="number">558</span>.<span class="number">9</span> G  /user/qihuang.zheng/forseti_velocity_result/<span class="number">192</span>.<span class="number">168</span>.<span class="number">47</span>.<span class="number">224</span></span><br><span class="line"><span class="number">546</span>.<span class="number">5</span> G  /user/qihuang.zheng/forseti_velocity_result/<span class="number">192</span>.<span class="number">168</span>.<span class="number">47</span>.<span class="number">224</span>.<span class="number">1</span></span><br><span class="line"><span class="number">471</span>.<span class="number">3</span> G  /user/qihuang.zheng/forseti_velocity_result/<span class="number">192</span>.<span class="number">168</span>.<span class="number">47</span>.<span class="number">224</span>.<span class="number">2</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>1.相同的key会有多条记录, 如何在(是否有必要)Mapper任务中过滤输出?<br>2.为了减少数据量,并没有输出sequence_id,可以从eventJSONData中获取<br>3.由于只保存event数据,所以value中的event属性名称其实是可以去掉的:partner_code:app_name:type:timestamp:eventJSONData<br>4.最好key和value分开输出,因为value是以冒号分隔的,如果将key,value一起输出,而key本身可能带有冒号,对后面处理不是很方便.  </p>
</blockquote>
<h3 id="3-除了过滤type字段,_还要过滤event中的字段">3.除了过滤type字段, 还要过滤event中的字段</h3><p>其他一些限制条件: </p>
<ul>
<li>event json 字符串长度为1000/800</li>
<li>partition key 长度为150</li>
<li>timestamp 时间撮在80天之内</li>
</ul>
<p>测试一个数据文件190M. 对Event中的字符串进行去除过滤字段. 选择JSON方式,去除字段的方式比较简单,而且速度快.    </p>
<table>
<thead>
<tr>
<th>FilterWay</th>
<th>Cost</th>
<th>DataSize</th>
</tr>
</thead>
<tbody>
<tr>
<td>JSON</td>
<td>143s,616s,110s,311s</td>
<td>189.7M</td>
</tr>
<tr>
<td>REG</td>
<td>269s</td>
<td>190M</td>
</tr>
<tr>
<td>NO</td>
<td>435s</td>
<td>192.8M</td>
</tr>
</tbody>
</table>
<blockquote>
<p>奇怪的是用JSON方式运行,有时候很快,有时候又很慢!  </p>
</blockquote>
<table>
<thead>
<tr>
<th>Input</th>
<th>Type</th>
<th>Files/Maps</th>
<th>OutputSize</th>
<th>Cost</th>
<th>Tips</th>
</tr>
</thead>
<tbody>
<tr>
<td>192.168.47.224</td>
<td>大文件&gt;160M</td>
<td>397</td>
<td>558G</td>
<td>16813s</td>
<td>4.6h,280min,平均每个任务不到一分钟,输出key为partitionKey,value为其他字段,\t分隔</td>
</tr>
<tr>
<td>192.168.47.224</td>
<td>大文件&gt;160M</td>
<td>397</td>
<td>546G</td>
<td>21736s</td>
<td>6h,362min, 输出key为整条记录,value为null,去掉event字段名称</td>
</tr>
<tr>
<td>192.168.47.224</td>
<td>大文件&gt;160M</td>
<td>397</td>
<td>471G</td>
<td>20184s</td>
<td>7.5h, key,value分隔,过滤不必要的数据(过滤type以及event字符串里的字段)</td>
</tr>
</tbody>
</table>
<blockquote>
<p>有些任务运行时间很长(超过4个小时), 是因为输出的文件也很大(将近90G), 实际上本身SSTable文件就很大了.<br>HDFS的输出和原始的SSTable相比,还是要大很多,因为SSTable是紧凑的,而HDFS上的是纯文本格式.<br>不过后续可以考虑转换为Parquet文件. Spark对读取Parquet文件也有优势.但是目前因为是全部数据,貌似优势也体现不出来.<br>如果测试同一个输入文件夹多次输出,第二次不需要重建索引,而且输出文件夹也要变化,可以直接在终端中执行,不要用上面的脚本.  </p>
</blockquote>
<p><img src="http://img.blog.csdn.net/20151119195500163" alt="mr_times"></p>
<h3 id="4-HadoopMR作业">4.HadoopMR作业</h3><p>先创建索引,再输出(hadoop作业和spark作业都在219上运行): <code>nohup sh velocity_hadoop.sh 192.168.47.224.2 &amp;</code><br><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="shebang">#!/bin/sh</span></span><br><span class="line">input=<span class="variable">$1</span></span><br><span class="line"><span class="comment">#hadoop jar hadoop-sstable-2.0.0.jar com.fullcontact.sstable.index.SSTableIndexIndexer /user/qihuang.zheng/forseti_velocity/$input</span></span><br><span class="line">startT=$(date +%s)  </span><br><span class="line">hadoop jar hadoop-sstable-<span class="number">2.0</span>.<span class="number">0</span>.jar com.fullcontact.sstable.velocity.VelocityReadJobTest \</span><br><span class="line">    -libjars guava-<span class="number">16.0</span>.<span class="number">1</span>.jar \</span><br><span class="line">    -D mapreduce.job.user.classpath.first=<span class="literal">true</span> \</span><br><span class="line">    -D hadoop.sstable.cql=<span class="string">"CREATE TABLE velocity (attribute text,partner_code text,app_name text,type text,&amp;timestamp&amp; bigint,event text,sequence_id text,PRIMARY KEY ((attribute), partner_code, app_name, type, &amp;timestamp&amp;)) WITH bloom_filter_fp_chance=0.100000 AND caching='ALL' AND comment='' AND dclocal_read_repair_chance=0.000000 AND gc_grace_seconds=0 AND index_interval=128 AND read_repair_chance=0.100000 AND replicate_on_write='true' AND populate_io_cache_on_flush='false' AND default_time_to_live=0 AND speculative_retry='99.0PERCENTILE' AND memtable_flush_period_in_ms=0 AND compaction=&#123;'unchecked_tombstone_compaction': 'true', 'tombstone_threshold': '0.1', 'class': 'LeveledCompactionStrategy'&#125; AND compression=&#123;'sstable_compression': 'LZ4Compressor'&#125;"</span> \</span><br><span class="line">    -D mapred.task.timeout=<span class="number">21600000</span> \</span><br><span class="line">    -D mapred.map.tasks.speculative.execution=<span class="literal">false</span> \</span><br><span class="line">    -D mapred.job.reuse.jvm.num.tasks=<span class="number">1</span> \</span><br><span class="line">    -D io.sort.mb=<span class="number">1000</span> \</span><br><span class="line">    -D io.sort.factor=<span class="number">100</span> \</span><br><span class="line">    -D hadoop.sstable.split.mb=<span class="number">1000</span> \</span><br><span class="line">    -D mapred.reduce.tasks=<span class="number">0</span> \</span><br><span class="line">    -D mapred.child.java.opts=<span class="string">"-Xms6G -Xmx6G -XX:MaxPermSize=256m"</span> \</span><br><span class="line">    -D hadoop.sstable.keyspace=<span class="string">"forseti"</span> \</span><br><span class="line">    -D hadoop.sstable.column.family.name=<span class="string">"velocity"</span> \</span><br><span class="line">    -D hadoop.sstable.velocity.pklen=<span class="number">150</span> \</span><br><span class="line">    -D hadoop.sstable.velocity.eventlen=<span class="number">1000</span> \</span><br><span class="line">    -D hadoop.sstable.velocity.ttl=<span class="number">80</span> \</span><br><span class="line">    -D hadoop.sstable.velocity.excludes.type=<span class="string">"postingContent,postingTitle,smsContent,msgContent,searchContent,extContent,referCust,eventOccurTime,userAgentCust"</span> \</span><br><span class="line">    -D hadoop.sstable.velocity.excludes.fields=<span class="string">"postingContent,postingTitle,smsContent,msgContent,searchContent,extContent,items"</span> \</span><br><span class="line">    -D hadoop.sstable.velocity.excludes.fields.way=<span class="string">"JSON"</span> \</span><br><span class="line">    /user/qihuang.zheng/forseti_velocity/<span class="variable">$input</span> /user/qihuang.zheng/forseti_velocity_result/<span class="variable">$input</span></span><br><span class="line">endT=$(date +%s)  </span><br><span class="line">timeT=$(( <span class="variable">$endT</span> - <span class="variable">$startT</span> ))  </span><br><span class="line"><span class="built_in">echo</span> <span class="string">"velocity_hadoop: input: <span class="variable">$input</span>; output: <span class="variable">$output</span>; cost: <span class="variable">$timeT</span>."</span></span><br></pre></td></tr></table></figure></p>
<hr>
<h2 id="Spark读取HDFS写入到Cassandra">Spark读取HDFS写入到Cassandra</h2><p>以Hadoop作业的输出作为Spark作业的输入(1.4.1版本) <code>nohup sh velocity_cassandra.sh 192.168.47.224_2 &amp;</code>  </p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="shebang">#!/bin/sh</span></span><br><span class="line">input=<span class="variable">$1</span></span><br><span class="line">startS=$(date +%s)  </span><br><span class="line">/usr/install/spark-<span class="number">1.4</span>.<span class="number">1</span>-bin-hadoop2.<span class="number">4</span>/bin/spark-submit \</span><br><span class="line">    --master spark://<span class="number">192.168</span>.<span class="number">47.209</span>:<span class="number">7077</span> \</span><br><span class="line">    --executor-memory <span class="number">12</span>g --total-executor-cores <span class="number">45</span> --driver-memory <span class="number">10</span>g \</span><br><span class="line">    --jars spark-cassandra-connector-assembly-<span class="number">1.4</span>.<span class="number">0</span>-SNAPSHOT.jar \</span><br><span class="line">    --conf spark.cassandra.connection.host=<span class="number">192.168</span>.<span class="number">47.219</span> \</span><br><span class="line">    --class cn.fraudmetrix.cassandra.VelocityHDFS \</span><br><span class="line">    --properties-file spark-defaults_backup.conf \</span><br><span class="line">    spark-app-<span class="number">1.0</span>-SNAPSHOT.jar /user/qihuang.zheng/forseti_velocity_result/<span class="variable">$input</span></span><br><span class="line">endS=$(date +%s)  </span><br><span class="line">timeS=$(( <span class="variable">$endS</span> - <span class="variable">$startS</span> ))  </span><br><span class="line"><span class="built_in">echo</span> <span class="string">"velocity_cassandra: input: <span class="variable">$input</span>; cost: <span class="variable">$timeS</span>."</span></span><br></pre></td></tr></table></figure>
<p>1.5.2版本的Spark: <code>nohup sh velocity_cassandra_152.sh 192.168.47.224_2 &amp;</code>  </p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="shebang">#!/bin/sh</span></span><br><span class="line">input=<span class="variable">$1</span></span><br><span class="line">startS=$(date +%s)</span><br><span class="line">/usr/install/spark-<span class="number">1.5</span>.<span class="number">2</span>-bin-hadoop2.<span class="number">4</span>/bin/spark-submit \</span><br><span class="line">    --master spark://<span class="number">192.168</span>.<span class="number">47.213</span>:<span class="number">7077</span> \</span><br><span class="line">    --executor-memory <span class="number">15</span>g --total-executor-cores <span class="number">125</span> --driver-memory <span class="number">10</span>g --executor-cores <span class="number">5</span> \</span><br><span class="line">    --jars spark-cassandra-connector-java-assembly-<span class="number">1.5</span>.<span class="number">0</span>-M2-SNAPSHOT.jar \</span><br><span class="line">    --conf spark.cassandra.connection.host=<span class="number">192.168</span>.<span class="number">47.219</span> \</span><br><span class="line">    --class cn.fraudmetrix.cassandra.VelocityHDFS \</span><br><span class="line">    --properties-file spark-defaults_backup.conf \</span><br><span class="line">    spark-app-<span class="number">1.1</span>-SNAPSHOT.jar /user/qihuang.zheng/forseti_velocity_result/<span class="variable">$input</span></span><br><span class="line">endS=$(date +%s)</span><br><span class="line">timeS=$(( <span class="variable">$endS</span> - <span class="variable">$startS</span> ))</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"velocity_cassandra: input: <span class="variable">$input</span>; cost: <span class="variable">$timeS</span>."</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>在线上运行时, 直接修改<code>spark.cassandra.connection.host=192.168.47.226</code>  </p>
</blockquote>
<h3 id="读取HDFS大文件夹(cache比例很低)">读取HDFS大文件夹(cache比例很低)</h3><p>forseti_velocity_result/192.168.47.224下471G全量数据, 12个节点, executor-memory=12G. 在1.4.1中一个Worker只有一个executor. 缓存只有4%, 40G.   </p>
<p><img src="http://img.blog.csdn.net/20151119195515238" alt="cache_4"></p>
<p>虽然executor-memory的内存为12G,但是因为设置了<code>spark.storage.memoryFraction 0.4</code>, 所以实际能缓存的只有12*0.4=4G左右. 12个节点就是48G.<br>所以我们看到Storage中的Cache大小只有40G, 而下图也显示每个executor也都没有剩下多少内存了. 所以一种提高Cache的方式很显然是增加executor的内存大小.   </p>
<p><img src="http://img.blog.csdn.net/20151119195528693" alt="cache_mem"></p>
<h3 id="增大Cache的比重(1-5-2)+分批处理">增大Cache的比重(1.5.2)+分批处理</h3><ul>
<li>使用Spark-1.5.2可以启动多个Executors. 假设total-cores=150,executor-cores=5,就有150/5=30个executors,再加上一个driver=31.  </li>
<li>增大executor-memory为15G,并去掉memoryFraction=0.4,默认是0.6, 所以每个executor能Cache的容量为15*0.6=8G左右.  </li>
<li>RDD缓存使用StorageLevel.MEMORY_AND_DISK,而不是直接rdd.cache(这个默认是Memory,因此后续的任务会存在Any的).  </li>
<li>分批测试,不要测试全量数据.  </li>
</ul>
<p><img src="http://img.blog.csdn.net/20151119195541715" alt="cache_disk"></p>
<p>后续的runJob, NODE_LOCAL级别来自network, 而PROCESS_LOCAL可能是memory或者disk.  </p>
<p><img src="http://img.blog.csdn.net/20151119195554022" alt="cache_from"></p>
<p>将原始417G的分成多个小文件夹处理, 这样一次Cache的量不至于太多.  </p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[qihuang.zheng@spark047219 ~]$ hadoop fs -du -h /user/qihuang.zheng/forseti_velocity_result/</span><br><span class="line"><span class="number">471.3</span> G  /user/qihuang.zheng/forseti_velocity_result/<span class="number">192.168</span><span class="number">.47</span><span class="number">.224</span></span><br><span class="line"></span><br><span class="line">[qihuang.zheng@spark047219 ~]$ hadoop fs -du -h forseti_velocity_result</span><br><span class="line"><span class="number">0</span>        forseti_velocity_result/<span class="number">192.168</span><span class="number">.47</span><span class="number">.224</span></span><br><span class="line"><span class="number">258.6</span> G  forseti_velocity_result/<span class="number">192.168</span><span class="number">.47</span><span class="number">.224</span>_1</span><br><span class="line"><span class="number">212.7</span> G  forseti_velocity_result/<span class="number">192.168</span><span class="number">.47</span><span class="number">.224</span>_2</span><br><span class="line"></span><br><span class="line">[qihuang.zheng@spark047219 ~]$ hadoop fs -ls forseti_velocity_result/<span class="number">192.168</span><span class="number">.47</span><span class="number">.224</span>_2 | wc -l</span><br><span class="line"><span class="number">101</span></span><br></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th>nodes</th>
<th>executor-memory</th>
<th>executor-cores</th>
<th>total-cores</th>
<th>executors</th>
<th>total-memory</th>
<th>input-size</th>
<th>fraction-cached</th>
<th>cached-partitions</th>
<th>cached-memory</th>
<th>cached-disk</th>
</tr>
</thead>
<tbody>
<tr>
<td>6</td>
<td>15g</td>
<td>5</td>
<td>150</td>
<td>30</td>
<td><code>30*15*0.5=225G</code></td>
<td>212.7G</td>
<td>100%(0.6)</td>
<td>1741</td>
<td>210.2G</td>
<td>44.2G</td>
</tr>
<tr>
<td>11</td>
<td>15g</td>
<td>5</td>
<td>125</td>
<td>25</td>
<td><code>25*15*0.2=75G</code></td>
<td>258.6G</td>
<td>100%(0.3)</td>
<td>2185</td>
<td>84.6G</td>
<td>272.5G</td>
</tr>
</tbody>
</table>
<blockquote>
<p>如果不Cache,读取HDFS后,直接写入: 11Nodes, 212.7G, 4h+5.7h+6.6h=16.3h 看起来和缓存的时间差不多.  </p>
</blockquote>
<h3 id="Verify_Data">Verify Data</h3><figure class="highlight oxygene"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> velocity_app <span class="keyword">where</span> attribute=<span class="string">'111111111111111111'</span> <span class="keyword">and</span> partner_code=<span class="string">'aixuedai'</span> <span class="keyword">and</span> app_name=<span class="string">'aixuedai'</span> <span class="keyword">and</span> <span class="keyword">type</span>=<span class="string">'idNumber'</span>;</span><br><span class="line"><span class="keyword">select</span> timestamp,ttl(<span class="keyword">event</span>) <span class="keyword">from</span> velocity_app <span class="keyword">where</span> attribute=<span class="string">'111111111111111111'</span> <span class="keyword">and</span> partner_code=<span class="string">'aixuedai'</span> <span class="keyword">and</span> app_name=<span class="string">'aixuedai'</span> <span class="keyword">and</span> <span class="keyword">type</span>=<span class="string">'idNumber'</span>;</span><br><span class="line"></span><br><span class="line">cqlsh:forseti&gt; <span class="keyword">select</span> * <span class="keyword">from</span> velocity_app <span class="keyword">where</span> attribute=<span class="string">'111111111111111111'</span> <span class="keyword">and</span> partner_code=<span class="string">'aixuedai'</span> <span class="keyword">and</span> app_name=<span class="string">'aixuedai'</span> <span class="keyword">and</span> <span class="keyword">type</span>=<span class="string">'idNumber'</span>;</span><br><span class="line"></span><br><span class="line"> attribute          | partner_code | app_name | <span class="keyword">type</span>     | sequence_id            | <span class="keyword">event</span>       | timestamp</span><br><span class="line">--------------------+--------------+----------+----------+------------------------+-------------+---------------</span><br><span class="line"> <span class="number">111111111111111111</span> |     aixuedai | aixuedai | idNumber | <span class="number">1111111111111</span>-<span class="number">11111111</span> | ........... | <span class="number">1111111111</span></span><br><span class="line"></span><br><span class="line">cqlsh:forseti&gt; <span class="keyword">select</span> timestamp,ttl(<span class="keyword">event</span>) <span class="keyword">from</span> velocity_app <span class="keyword">where</span> attribute=<span class="string">'111111111111111111'</span> <span class="keyword">and</span> partner_code=<span class="string">'aixuedai'</span> <span class="keyword">and</span> app_name=<span class="string">'aixuedai'</span> <span class="keyword">and</span> <span class="keyword">type</span>=<span class="string">'idNumber'</span>;</span><br><span class="line"></span><br><span class="line"> timestamp     | ttl(<span class="keyword">event</span>)</span><br><span class="line">---------------+------------</span><br><span class="line"> <span class="number">1446946666300</span> |    <span class="number">6622388</span></span><br></pre></td></tr></table></figure>
<h2 id="CassandraOutputFormat">CassandraOutputFormat</h2><p>使用SSTableInputFormat读取HDFS上的SSTable, 可以直接利用Cassandra的BulkOutputFormat写到Cassandra中. 而不是先存成HDFS,再用Spark来处理!  </p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar hadoop-sstable-<span class="number">2.0</span>.<span class="number">0</span>.jar com.fullcontact.sstable.velocity.VelocityRead2Write \</span><br><span class="line">    -libjars guava-<span class="number">16.0</span>.<span class="number">1</span>.jar \</span><br><span class="line">    -D mapreduce.job.user.classpath.first=<span class="literal">true</span> \</span><br><span class="line">    -D hadoop.sstable.cql=<span class="string">"CREATE TABLE velocity (attribute text,partner_code text,app_name text,type text,&amp;timestamp&amp; bigint,event text,sequence_id text,PRIMARY KEY ((attribute), partner_code, app_name, type, &amp;timestamp&amp;)) WITH bloom_filter_fp_chance=0.100000 AND caching='ALL' AND comment='' AND dclocal_read_repair_chance=0.000000 AND gc_grace_seconds=0 AND index_interval=128 AND read_repair_chance=0.100000 AND replicate_on_write='true' AND populate_io_cache_on_flush='false' AND default_time_to_live=0 AND speculative_retry='99.0PERCENTILE' AND memtable_flush_period_in_ms=0 AND compaction=&#123;'unchecked_tombstone_compaction': 'true', 'tombstone_threshold': '0.1', 'class': 'LeveledCompactionStrategy'&#125; AND compression=&#123;'sstable_compression': 'LZ4Compressor'&#125;"</span> \</span><br><span class="line">    -D mapred.task.timeout=<span class="number">21600000</span> \</span><br><span class="line">    -D mapred.map.tasks.speculative.execution=<span class="literal">false</span> \</span><br><span class="line">    -D mapred.job.reuse.jvm.num.tasks=<span class="number">1</span> \</span><br><span class="line">    -D io.sort.mb=<span class="number">1000</span> \</span><br><span class="line">    -D io.sort.factor=<span class="number">100</span> \</span><br><span class="line">    -D hadoop.sstable.split.mb=<span class="number">1000</span> \</span><br><span class="line">    -D mapred.reduce.tasks=<span class="number">0</span> \</span><br><span class="line">    -D mapred.child.java.opts=<span class="string">"-Xms6G -Xmx6G -XX:MaxPermSize=256m"</span> \</span><br><span class="line">    -D hadoop.sstable.keyspace=<span class="string">"forseti"</span> \</span><br><span class="line">    -D hadoop.sstable.column.family.name=<span class="string">"velocity"</span> \</span><br><span class="line">    -D hadoop.sstable.velocity.pklen=<span class="number">150</span> \</span><br><span class="line">    -D hadoop.sstable.velocity.eventlen=<span class="number">1000</span> \</span><br><span class="line">    -D hadoop.sstable.velocity.ttl=<span class="number">80</span> \</span><br><span class="line">    -D hadoop.sstable.velocity.excludes.type=<span class="string">"postingContent,postingTitle,smsContent,msgContent,searchContent,extContent,referCust,eventOccurTime,userAgentCust"</span> \</span><br><span class="line">    -D hadoop.sstable.velocity.excludes.fields=<span class="string">"postingContent,postingTitle,smsContent,msgContent,searchContent,extContent,items"</span> \</span><br><span class="line">    -D hadoop.sstable.velocity.excludes.fields.way=<span class="string">"JSON"</span> \</span><br><span class="line">    /user/qihuang.zheng/forseti_velocity/<span class="built_in">test</span></span><br></pre></td></tr></table></figure>

      
    </div>
    
  </div>
  
    
<div class="copyright">
  <p><span>本文标题:</span><a href="/2015/11/19/2015-11-19-Cassandra-Migration7_VelocityHadoop/">Cassandra数据迁移 分离表</a></p>
  <p><span>文章作者:</span><a href="/" title="访问 任何忧伤,都抵不过世界的美丽 的个人博客">任何忧伤,都抵不过世界的美丽</a></p>
  <p><span>发布时间:</span>2015年11月19日 - 00时00分</p>
  <p><span>最后更新:</span>2015年12月19日 - 21时17分</p>
  <p>
    <span>原始链接:</span><a href="/2015/11/19/2015-11-19-Cassandra-Migration7_VelocityHadoop/" title="Cassandra数据迁移 分离表">http://github.com/zqhxuyuan/2015/11/19/2015-11-19-Cassandra-Migration7_VelocityHadoop/</a>
    <span class="btn" data-clipboard-text="原文: http://github.com/zqhxuyuan/2015/11/19/2015-11-19-Cassandra-Migration7_VelocityHadoop/　　作者: 任何忧伤,都抵不过世界的美丽" title="点击复制文章链接">
        <i class="fa fa-clipboard"></i>
    </span>
  </p>
  <p><span>许可协议:</span><i class="fa fa-creative-commons"></i> <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/3.0/cn/" title="中国大陆 (CC BY-NC-SA 3.0 CN)">"署名-非商用-相同方式共享 3.0"</a> 转载请保留原文链接及作者。</p>
  <script src="/js/clipboard.min.js"></script>
  <script> var clipboard = new Clipboard('.btn'); </script>
</div>
<style type="text/css">
  .copyright p .btn {
    margin-left: 1em;
  }
  .copyright:hover p .btn::after {
    content: "复制"
  }
  .copyright p .btn:hover {
      color: gray;
      cursor: pointer;
    };
</style>



<nav id="article-nav">
  
    <div id="article-nav-newer" class="article-nav-title">
      <a href="/2015/11/24/2015-11-24-StreamCQL-task/">
        StreamCQL源码阅读(1) 提交任务
      </a>
    </div>
  
  
    <div id="article-nav-older" class="article-nav-title">
      <a href="/2015/11/18/2015-11-18-Hadoop-SSTable/">
        Cassandra Migration Tool(hadoop-sstable)
      </a>
    </div>
  
</nav>

  
</article>

<!-- 默认显示文章目录，在文章---前输入toc: false关闭目录 -->
<!-- Show TOC and tocButton in default, Hide TOC via putting "toc: false" before "---" at [post].md -->
<div id="toc" class="toc-article">
<strong class="toc-title">文章目录</strong>
<ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#hadoop-sstable"><span class="toc-number">1.</span> <span class="toc-text">hadoop-sstable</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-上传hdfs文件"><span class="toc-number">1.1.</span> <span class="toc-text">1.上传hdfs文件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-SSTable写到HDFS"><span class="toc-number">1.2.</span> <span class="toc-text">2.SSTable写到HDFS</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-除了过滤type字段,_还要过滤event中的字段"><span class="toc-number">1.3.</span> <span class="toc-text">3.除了过滤type字段, 还要过滤event中的字段</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-HadoopMR作业"><span class="toc-number">1.4.</span> <span class="toc-text">4.HadoopMR作业</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Spark读取HDFS写入到Cassandra"><span class="toc-number">2.</span> <span class="toc-text">Spark读取HDFS写入到Cassandra</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#读取HDFS大文件夹(cache比例很低)"><span class="toc-number">2.1.</span> <span class="toc-text">读取HDFS大文件夹(cache比例很低)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#增大Cache的比重(1-5-2)+分批处理"><span class="toc-number">2.2.</span> <span class="toc-text">增大Cache的比重(1.5.2)+分批处理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Verify_Data"><span class="toc-number">2.3.</span> <span class="toc-text">Verify Data</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#CassandraOutputFormat"><span class="toc-number">3.</span> <span class="toc-text">CassandraOutputFormat</span></a></li></ol>
</div>
<style type="text/css">
  .left-col .switch-btn {
    display: none;
  }
  .left-col .switch-area {
    display: none;
  }
</style>

<input type="button" id="tocButton" value="隐藏目录"  title="点击按钮隐藏或者显示文章目录">
<script type="text/javascript">
  var toc_button= document.getElementById("tocButton");
  var toc_div= document.getElementById("toc");
  /* Show or hide toc when click on tocButton.
  通过点击设置的按钮显示或者隐藏文章目录.*/
  toc_button.onclick=function(){
  if(toc_div.style.display=="none"){
  toc_div.style.display="block";
  toc_button.value="隐藏目录";
  document.getElementById("switch-btn").style.display="none";
  document.getElementById("switch-area").style.display="none";
  }
  else{
  toc_div.style.display="none";
  toc_button.value="显示目录";
  document.getElementById("switch-btn").style.display="block";
  document.getElementById("switch-area").style.display="block";
  }
  }
</script>


<div class="share">
	<div class="bdsharebuttonbox">
	<a href="#" class="bds_more" data-cmd="more"></a>
	<a href="#" class="bds_tsina" data-cmd="tsina" title="分享到新浪微博"></a>
	<a href="#" class="bds_sqq" data-cmd="sqq" title="分享给 QQ 好友"></a>
	<a href="#" class="bds_copy" data-cmd="copy" title="复制网址"></a>
	<a href="#" class="bds_mail" data-cmd="mail" title="通过邮件分享"></a>
	<a href="#" class="bds_weixin" data-cmd="weixin" title="生成文章二维码"></a>
	</div>
	<script>
	window._bd_share_config={
		"common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"0","bdSize":"24"},"share":{}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];
	</script>
</div>







    <style type="text/css">
    #scroll {
      display: none;
    }
    </style>
    <div class="scroll">
    <a href="#" title="返回顶部"><i class="fa fa-arrow-up"></i></a>
    <a href="#comments" title="查看评论"><i class="fa fa-comments-o"></i></a>
    <a href="#footer" title="转到底部"><i class="fa fa-arrow-down"></i></a>
    </div>


  
  
    
    <div  class="post-nav-button">
    <a href="/2015/11/24/2015-11-24-StreamCQL-task/" title="上一篇: StreamCQL源码阅读(1) 提交任务">
    <i class="fa fa-angle-left"></i>
    </a>
    <a href="/2015/11/18/2015-11-18-Hadoop-SSTable/" title="下一篇: Cassandra Migration Tool(hadoop-sstable)">
    <i class="fa fa-angle-right"></i>
    </a>
    </div>
  



    
        <link rel="stylesheet" href="/fancybox/jquery.fancybox.css" type="text/css">
        <script>
        var yiliaConfig = {
        fancybox: true,
        mathjax: true,
        animate: true,
        isHome: false,
        isPost: true,
        isArchive: false,
        isTag: false,
        isCategory: false,
        open_in_new: false
        }
        </script>
        
</div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
      <div class="footer-left">
        &copy; 2015 任何忧伤,都抵不过世界的美丽
      </div>
        <div class="footer-right">
          <a href="http://hexo.io/" target="_blank" title="快速、简洁且高效的静态博客框架">Hexo</a>  Theme <a href="https://github.com/MOxFIVE/hexo-theme-yelee" target="_blank" title="简而不减双栏 Hexo 博客主题">Yelee</a> by MOxFIVE
        </div>
    </div>
    <div class="visit">
      <span id="busuanzi_container_site_pv" style='display:none'>
        <span id="site-visit" >本站到访数: 
        <span id="busuanzi_value_site_uv"></span>
        </span>
      </span>
      <span id="busuanzi_container_page_pv" style='display:none'>
        <span id="page-visit">, 本页阅读量: 
        <span id="busuanzi_value_page_pv"></span>
        </span>
      </span>
    </div>
  </div>
</footer>
    </div>
    

<script src="http://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js" type="text/javascript"></script>
<script src="/js/main.js" type="text/javascript"></script>

<script>
  var backgroundnum = 5;
  var backgroundimg = "url(/background/bg-x.jpg)".replace(/x/gi, Math.ceil(Math.random() * backgroundnum));

  $("body").css({"background": backgroundimg, "background-attachment": "fixed", "background-size": "cover"});
</script>




<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<div class="scroll" id="scroll">
<a href="#" title="返回顶部"><i class="fa fa-arrow-up"></i></a>
<a href="#footer" title="转到底部"><i class="fa fa-arrow-down"></i></a>
</div>

<script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>
  </div>
</body>
</html>