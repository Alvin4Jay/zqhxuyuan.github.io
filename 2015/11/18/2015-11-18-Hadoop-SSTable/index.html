<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Cassandra Migration Tool(hadoop-sstable) | zqhxuyuan</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Cassandra BulkLoad 批量导数据工具(2)">
<meta property="og:type" content="article">
<meta property="og:title" content="Cassandra Migration Tool(hadoop-sstable)">
<meta property="og:url" content="http://github.com/zqhxuyuan/2015/11/18/2015-11-18-Hadoop-SSTable/index.html">
<meta property="og:site_name" content="zqhxuyuan">
<meta property="og:description" content="Cassandra BulkLoad 批量导数据工具(2)">
<meta property="og:image" content="http://img.blog.csdn.net/20151110134149469">
<meta property="og:image" content="http://img.blog.csdn.net/20151110094117060">
<meta property="og:updated_time" content="2015-12-19T13:17:42.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Cassandra Migration Tool(hadoop-sstable)">
<meta name="twitter:description" content="Cassandra BulkLoad 批量导数据工具(2)">
  
    <link rel="alternative" href="/atom.xml" title="zqhxuyuan" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link rel="stylesheet" href="/css/style.css" type="text/css">
  <link rel="stylesheet" href="/font-awesome/css/font-awesome.min.css">
  <link rel="apple-touch-icon" href="/apple-touch-icon.png">
</head>
<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			
			<img lazy-src="https://avatars1.githubusercontent.com/u/1088525?v=3&amp;s=180" class="js-avatar">
			
		</a>

		<hgroup>
		  <h1 class="header-author"><a href="/">任何忧伤,都抵不过世界的美丽</a></h1>
		</hgroup>

		
				


		
			<div id="switch-btn" class="switch-btn">
				<div class="icon">
					<div class="icon-ctn">
						<div class="icon-wrap icon-house" data-idx="0">
							<div class="birdhouse"></div>
							<div class="birdhouse_holes"></div>
						</div>
						<div class="icon-wrap icon-ribbon hide" data-idx="1">
							<div class="ribbon"></div>
						</div>
						
						
						<div class="icon-wrap icon-me hide" data-idx="3">
							<div class="user"></div>
							<div class="shoulder"></div>
						</div>
						
					</div>
					
				</div>
				<div class="tips-box hide">
					<div class="tips-arrow"></div>
					<ul class="tips-inner">
						<li>菜单</li>
						<li>标签</li>
						
						
						<li>关于我</li>
						
					</ul>
				</div>
			</div>
		

		<div id="switch-area" class="switch-area">
			<div class="switch-wrap">
				<section class="switch-part switch-part1">
					<nav class="header-menu">
						<ul>
						
							<li><a href="/">主页</a></li>
				        
							<li><a href="/archives/">归档</a></li>
				        
							<li><a href="/tags/">标签</a></li>
				        
							<li><a href="/about/">关于</a></li>
				        
						</ul>
					</nav>
					<nav class="header-nav">
						<ul class="social">
							
								<li id="新浪微博"><a class="新浪微博" target="_blank" href="http://weibo.com/xuyuantree" title="新浪微博"></a></li>
					        
								<li id="GitHub"><a class="GitHub" target="_blank" href="http://github.com/zqhxuyuan" title="GitHub"></a></li>
					        
						</ul>
					</nav>
				</section>
				
				
				<section class="switch-part switch-part2">
					<div class="widget tagcloud" id="js-tagcloud">
						<a href="/tags/apex/" style="font-size: 10px;">apex</a> <a href="/tags/cassandra/" style="font-size: 20px;">cassandra</a> <a href="/tags/drill/" style="font-size: 18px;">drill</a> <a href="/tags/druid/" style="font-size: 14px;">druid</a> <a href="/tags/elasticsearch/" style="font-size: 10px;">elasticsearch</a> <a href="/tags/geode/" style="font-size: 10px;">geode</a> <a href="/tags/hbase/" style="font-size: 16px;">hbase</a> <a href="/tags/ignite/" style="font-size: 10px;">ignite</a> <a href="/tags/spark/" style="font-size: 14px;">spark</a> <a href="/tags/storm/" style="font-size: 16px;">storm</a> <a href="/tags/timeseries/" style="font-size: 12px;">timeseries</a> <a href="/tags/work/" style="font-size: 12px;">work</a>
					</div>
				</section>
				
				
				

				
				
				<section class="switch-part switch-part3">
				
					<div id="js-aboutme">BIG(DATA)</div>
				</section>
				
			</div>
		</div>
	</header>				
</div>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
  	<div class="overlay">
  		<div class="slider-trigger"></div>
  		<h1 class="header-author js-mobile-header hide"><a href="/" title="回到主页">任何忧伤,都抵不过世界的美丽</a></h1>
  	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<a href="/" class="profilepic">
				<img lazy-src="https://avatars1.githubusercontent.com/u/1088525?v=3&amp;s=180" class="js-avatar">
			</a>
			<hgroup>
			  <h1 class="header-author"><a href="/" title="回到主页">任何忧伤,都抵不过世界的美丽</a></h1>
			</hgroup>
			
			<nav class="header-menu">
				<ul>
				
					<li><a href="/">主页</a></li>
		        
					<li><a href="/archives/">归档</a></li>
		        
					<li><a href="/tags/">标签</a></li>
		        
					<li><a href="/about/">关于</a></li>
		        
		        <div class="clearfix"></div>
				</ul>
			</nav>
			<nav class="header-nav">
						<ul class="social">
							
								<li id="新浪微博"><a class="新浪微博" target="_blank" href="http://weibo.com/xuyuantree" title="新浪微博"></a></li>
					        
								<li id="GitHub"><a class="GitHub" target="_blank" href="http://github.com/zqhxuyuan" title="GitHub"></a></li>
					        
						</ul>
			</nav>
		</header>				
	</div>
</nav>
      <div class="body-wrap"><article id="post-2015-11-18-Hadoop-SSTable" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2015/11/18/2015-11-18-Hadoop-SSTable/" class="article-date">
  	<time datetime="2015-11-17T16:00:00.000Z" itemprop="datePublished">2015-11-18</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Cassandra Migration Tool(hadoop-sstable)
    </h1>
  

      </header>
      
      <div class="article-info article-info-post">
        
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/bigdata/">bigdata</a>
	</div>


        
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/cassandra/">cassandra</a></li></ul>
	</div>

        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <p>Cassandra BulkLoad 批量导数据工具(2)</p>
<a id="more"></a>
<h2 id="hadoop-sstable">hadoop-sstable</h2><p><a href="https://github.com/fullcontact/hadoop-sstable">https://github.com/fullcontact/hadoop-sstable</a>  </p>
<blockquote>
<p>读取HDFS上的SSTable文件, 输出为HDFS上的json.  </p>
</blockquote>
<p>编译项目, 生成jar包.    </p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">➜  hadoop-sstable git:(cassandra-<span class="number">2.0</span>.x) ./gradlew build</span><br><span class="line">➜  hadoop-sstable git:(cassandra-<span class="number">2.0</span>.x) ll sstable-core/build/libs</span><br><span class="line">-rw-r--r--  <span class="number">1</span> zhengqh  staff    <span class="number">90</span>K <span class="number">11</span>  <span class="number">7</span> <span class="number">10</span>:<span class="number">06</span> hadoop-sstable-<span class="number">0.1</span><span class="number">.4</span>.jar</span><br></pre></td></tr></table></figure>
<p>创建索引文件:  </p>
<figure class="highlight haml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">1.如果报错权限不足, 修改hdfs的权限</span><br><span class="line">sudo chmod 777 -R /home/admin/hadoop/data/tmp</span><br><span class="line"></span><br><span class="line">2.libjars用脚本自动生成,逗号分隔, 还是报错找不到cassandra的ByteBufferUtil, 这个类其实在cassandra-all-2.0.15.jar中. 而Cassandra的lib下并没有cassandra-all-2.0.15.jar.    </span><br><span class="line">CASS_PATH=`ls /usr/install/cassandra/lib/*.jar | awk '&#123;print $0&#125;' | tr '\n' ',' |sed 's/,$//'`</span><br><span class="line"><span class="comment"></span><br><span class="line">/usr/install/hadoop/bin/hadoop jar hadoop-sstable-2.0.0.jar com.fullcontact.sstable.index.SSTableIndexIndexer \</span></span><br><span class="line"><span class="comment">/user/qihuang.zheng/velocity_backup_1107/226_1105/0/forseti/velocity \</span></span><br><span class="line">-<span class="ruby">libjars <span class="variable">$CASS_PATH</span></span><br><span class="line"></span></span><br><span class="line">3.把上面的CASS_PATH手动添加到-libjars也不行.  </span><br><span class="line"><span class="comment">/usr/install/hadoop/bin/hadoop jar hadoop-sstable-2.0.0.jar com.fullcontact.sstable.index.SSTableIndexIndexer \</span></span><br><span class="line"><span class="comment">/user/qihuang.zheng/velocity_backup_1107/226_1105/0/forseti/velocity \</span></span><br><span class="line">-<span class="ruby">libjars /usr/install/cassandra/lib/antlr-<span class="number">3.2</span>.jar,<span class="regexp">/usr/install</span><span class="regexp">/cassandra/lib</span><span class="regexp">/apache-cassandra-2.0.15.jar,/usr</span><span class="regexp">/install/cassandra</span><span class="regexp">/lib/apache</span>-cassandra-clientutil-<span class="number">2.0</span>.<span class="number">15</span>.jar,<span class="regexp">/usr/install</span><span class="regexp">/cassandra/lib</span><span class="regexp">/apache-cassandra-thrift-2.0.15.jar,/usr</span><span class="regexp">/install/cassandra</span><span class="regexp">/lib/commons</span>-cli-<span class="number">1.1</span>.jar,<span class="regexp">/usr/install</span><span class="regexp">/cassandra/lib</span><span class="regexp">/commons-codec-1.2.jar,/usr</span><span class="regexp">/install/cassandra</span><span class="regexp">/lib/commons</span>-lang3-<span class="number">3.1</span>.jar,<span class="regexp">/usr/install</span><span class="regexp">/cassandra/lib</span><span class="regexp">/compress-lzf-0.8.4.jar,/usr</span><span class="regexp">/install/cassandra</span><span class="regexp">/lib/concurrentlinkedhashmap</span>-lru-<span class="number">1.3</span>.jar,<span class="regexp">/usr/install</span><span class="regexp">/cassandra/lib</span><span class="regexp">/disruptor-3.0.1.jar,/usr</span><span class="regexp">/install/cassandra</span><span class="regexp">/lib/guava</span>-<span class="number">15.0</span>.jar,<span class="regexp">/usr/install</span><span class="regexp">/cassandra/lib</span><span class="regexp">/high-scale-lib-1.1.2.jar,/usr</span><span class="regexp">/install/cassandra</span><span class="regexp">/lib/jackson</span>-core-asl-<span class="number">1.9</span>.<span class="number">2</span>.jar,<span class="regexp">/usr/install</span><span class="regexp">/cassandra/lib</span><span class="regexp">/jackson-mapper-asl-1.9.2.jar,/usr</span><span class="regexp">/install/cassandra</span><span class="regexp">/lib/jamm</span>-<span class="number">0</span>.<span class="number">2.5</span>.jar,<span class="regexp">/usr/install</span><span class="regexp">/cassandra/lib</span><span class="regexp">/jbcrypt-0.3m.jar,/usr</span><span class="regexp">/install/cassandra</span><span class="regexp">/lib/jline</span>-<span class="number">1.0</span>.jar,<span class="regexp">/usr/install</span><span class="regexp">/cassandra/lib</span><span class="regexp">/json-simple-1.1.jar,/usr</span><span class="regexp">/install/cassandra</span><span class="regexp">/lib/libthrift</span>-<span class="number">0</span>.<span class="number">9.1</span>.jar,<span class="regexp">/usr/install</span><span class="regexp">/cassandra/lib</span><span class="regexp">/log4j-1.2.16.jar,/usr</span><span class="regexp">/install/cassandra</span><span class="regexp">/lib/lz</span>4-<span class="number">1.2</span>.<span class="number">0</span>.jar,<span class="regexp">/usr/install</span><span class="regexp">/cassandra/lib</span><span class="regexp">/metrics-core-2.2.0.jar,/usr</span><span class="regexp">/install/cassandra</span><span class="regexp">/lib/netty</span>-<span class="number">3.6</span>.<span class="number">6</span>.<span class="constant">Final</span>.jar,<span class="regexp">/usr/install</span><span class="regexp">/cassandra/lib</span><span class="regexp">/reporter-config-2.1.0.jar,/usr</span><span class="regexp">/install/cassandra</span><span class="regexp">/lib/servlet</span>-api-<span class="number">2.5</span>-<span class="number">20081211</span>.jar,<span class="regexp">/usr/install</span><span class="regexp">/cassandra/lib</span><span class="regexp">/slf4j-api-1.7.2.jar,/usr</span><span class="regexp">/install/cassandra</span><span class="regexp">/lib/slf</span>4j-log4j12-<span class="number">1.7</span>.<span class="number">2</span>.jar,<span class="regexp">/usr/install</span><span class="regexp">/cassandra/lib</span><span class="regexp">/snakeyaml-1.11.jar,/usr</span><span class="regexp">/install/cassandra</span><span class="regexp">/lib/snappy</span>-java-<span class="number">1.0</span>.<span class="number">5</span>.jar,<span class="regexp">/usr/install</span><span class="regexp">/cassandra/lib</span><span class="regexp">/snaptree-0.1.jar,/usr</span><span class="regexp">/install/cassandra</span><span class="regexp">/lib/super</span>-csv-<span class="number">2.1</span>.<span class="number">0</span>.jar,<span class="regexp">/usr/install</span><span class="regexp">/cassandra/lib</span><span class="regexp">/thrift-server-0.3.7.jar</span><br><span class="line"></span></span></span><br><span class="line">4.下载cassandra-all-2.0.15.jar, 使用libjars会提示hdfs:/user/qihuang.zheng下不存在cassandra-all-2.0.15.jar</span><br><span class="line">export HADOOP_CLASSPATH=/usr/install/cassandra/lib/*:cassandra-all-2.0.15.jar:$HADOOP_CLASSPATH</span><br><span class="line"><span class="comment">/usr/install/hadoop/bin/hadoop jar hadoop-sstable-2.0.0.jar com.fullcontact.sstable.index.SSTableIndexIndexer \</span></span><br><span class="line"><span class="comment">/user/qihuang.zheng/velocity_backup_1107/226_1105/0/forseti/velocity \</span></span><br><span class="line">-<span class="ruby"><span class="regexp">libjars cassandra-all-2.0.15.jar</span><br><span class="line"></span></span></span><br><span class="line">5.正确的做法: 先设置Cassandra的jar包到HADOOP_CLASSPATH中.   </span><br><span class="line">export HADOOP_CLASSPATH=/usr/install/cassandra/lib/*:cassandra-all-2.0.15.jar:$HADOOP_CLASSPATH</span><br><span class="line"></span><br><span class="line">或者在build hadoop-sstable项目的时候直接把cassandra编译到fatjar里. --&gt;</span><br><span class="line"></span><br><span class="line">测试生成一个文件夹的索引文件:  </span><br><span class="line"><span class="comment">/usr/install/hadoop/bin/hadoop jar hadoop-sstable-2.0.0.jar com.fullcontact.sstable.index.SSTableIndexIndexer \</span></span><br><span class="line"><span class="comment">/user/qihuang.zheng/velocity_backup_1107/226_1105/1/forseti/velocity</span></span><br><span class="line"></span><br><span class="line">15/11/07 15:25:44 INFO index.SSTableIndexIndexer: SSTable Indexing directory /user/qihuang.zheng/velocity_backup_1107/226_1105/1/forseti/velocity</span><br><span class="line">15/11/07 15:25:44 INFO index.SSTableIndexIndexer: Indexing SSTABLE Indexing file hdfs://tdhdfs/user/qihuang.zheng/velocity_backup_1107/226_1105/1/forseti/velocity/forseti-velocity-jb-102234-Index.db, size 0.01 GB...</span><br><span class="line">15/11/07 15:25:45 INFO index.SSTableIndexIndexer: Completed SSTABLE Indexing in 1.16 seconds (8.12 MB/s).  Index size is 0.02 KB.</span><br><span class="line"></span><br><span class="line">可以看到生成了Index文件:  </span><br><span class="line"><span class="comment">/usr/install/hadoop/bin/hadoop fs -ls /user/qihuang.zheng/velocity_backup_1107/226_1105/1/forseti/velocity/forseti-velocity-jb-102234*</span></span><br><span class="line">-<span class="ruby"><span class="regexp">rw-r--r--   3 qihuang.zheng supergroup      87211 2015-11-07 10:02 /user</span><span class="regexp">/qihuang.zheng/velocity</span>_backup_1107/<span class="number">226_1105</span>/<span class="number">1</span>/forseti/velocity/forseti-velocity-jb-<span class="number">102234</span>-<span class="constant">CompressionInfo</span>.db</span><br><span class="line"></span>-<span class="ruby">rw-r--r--   <span class="number">3</span> qihuang.zheng supergroup  <span class="number">172873282</span> <span class="number">2015</span>-<span class="number">11</span>-<span class="number">07</span> <span class="number">10</span><span class="symbol">:</span><span class="number">02</span> /user/qihuang.zheng/velocity_backup_1107/<span class="number">226_1105</span>/<span class="number">1</span>/forseti/velocity/forseti-velocity-jb-<span class="number">102234</span>-<span class="constant">Data</span>.db</span><br><span class="line"></span>-<span class="ruby">rw-r--r--   <span class="number">3</span> qihuang.zheng supergroup      <span class="number">51960</span> <span class="number">2015</span>-<span class="number">11</span>-<span class="number">07</span> <span class="number">10</span><span class="symbol">:</span><span class="number">02</span> /user/qihuang.zheng/velocity_backup_1107/<span class="number">226_1105</span>/<span class="number">1</span>/forseti/velocity/forseti-velocity-jb-<span class="number">102234</span>-<span class="constant">Filter</span>.db</span><br><span class="line"></span>-<span class="ruby">rw-r--r--   <span class="number">3</span> qihuang.zheng supergroup    <span class="number">8747545</span> <span class="number">2015</span>-<span class="number">11</span>-<span class="number">07</span> <span class="number">10</span><span class="symbol">:</span><span class="number">02</span> /user/qihuang.zheng/velocity_backup_1107/<span class="number">226_1105</span>/<span class="number">1</span>/forseti/velocity/forseti-velocity-jb-<span class="number">102234</span>-<span class="constant">Index</span>.db</span><br><span class="line"></span>-<span class="ruby">rw-r--r--   <span class="number">3</span> qihuang.zheng supergroup         <span class="number">16</span> <span class="number">2015</span>-<span class="number">11</span>-<span class="number">07</span> <span class="number">15</span><span class="symbol">:</span><span class="number">25</span> /user/qihuang.zheng/velocity_backup_1107/<span class="number">226_1105</span>/<span class="number">1</span>/forseti/velocity/forseti-velocity-jb-<span class="number">102234</span>-<span class="constant">Index</span>.db.<span class="constant">Index</span></span><br><span class="line"></span>-<span class="ruby">rw-r--r--   <span class="number">3</span> qihuang.zheng supergroup       <span class="number">6127</span> <span class="number">2015</span>-<span class="number">11</span>-<span class="number">07</span> <span class="number">10</span><span class="symbol">:</span><span class="number">02</span> /user/qihuang.zheng/velocity_backup_1107/<span class="number">226_1105</span>/<span class="number">1</span>/forseti/velocity/forseti-velocity-jb-<span class="number">102234</span>-<span class="constant">Statistics</span>.db</span><br><span class="line"></span>-<span class="ruby">rw-r--r--   <span class="number">3</span> qihuang.zheng supergroup         <span class="number">79</span> <span class="number">2015</span>-<span class="number">11</span>-<span class="number">07</span> <span class="number">10</span><span class="symbol">:</span><span class="number">02</span> /user/qihuang.zheng/velocity_backup_1107/<span class="number">226_1105</span>/<span class="number">1</span>/forseti/velocity/forseti-velocity-jb-<span class="number">102234</span>-<span class="constant">TOC</span>.txt</span><br><span class="line"></span></span><br><span class="line">查看生成的Index文件, 因为是SequenceFile, 所以看到的是乱码</span><br><span class="line"><span class="comment">/usr/install/hadoop/bin/hadoop fs -cat /user/qihuang.zheng/velocity_backup_1107/226_1105/1/forseti/velocity/forseti-velocity-jb-102234-Index.db.Index</span></span><br><span class="line"></span><br><span class="line">6.所有文件夹, 支持递归</span><br><span class="line"><span class="comment">/usr/install/hadoop/bin/hadoop jar hadoop-sstable-2.0.0.jar com.fullcontact.sstable.index.SSTableIndexIndexer \</span></span><br><span class="line"><span class="comment">/user/qihuang.zheng/velocity_backup_1107/226_1105</span></span><br></pre></td></tr></table></figure>
<p>转换SSTable文件为JSON:  </p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">/usr/install/hadoop/bin/hadoop jar hadoop-sstable-<span class="number">2.0</span>.<span class="number">0</span><span class="class">.jar</span> com<span class="class">.fullcontact</span><span class="class">.sstable</span><span class="class">.example</span><span class="class">.SimpleExample</span> \</span><br><span class="line">    -D hadoop<span class="class">.sstable</span><span class="class">.cql</span>=<span class="string">"CREATE TABLE velocity (attribute text,partner_code text,app_name text,type text,"</span>timestamp<span class="string">" bigint,event text,sequence_id text,PRIMARY KEY ((attribute), partner_code, app_name, type, "</span>timestamp<span class="string">")) WITH compression=&#123;'sstable_compression': 'LZ4Compressor'&#125;"</span> \</span><br><span class="line">    -D mapred<span class="class">.task</span><span class="class">.timeout</span>=<span class="number">21600000</span> \</span><br><span class="line">    -D mapred<span class="class">.map</span><span class="class">.tasks</span><span class="class">.speculative</span><span class="class">.execution</span>=false \</span><br><span class="line">    -D mapred<span class="class">.job</span><span class="class">.reuse</span><span class="class">.jvm</span><span class="class">.num</span><span class="class">.tasks</span>=<span class="number">1</span> \</span><br><span class="line">    -D io<span class="class">.sort</span><span class="class">.mb</span>=<span class="number">1000</span> \</span><br><span class="line">    -D io<span class="class">.sort</span><span class="class">.factor</span>=<span class="number">100</span> \</span><br><span class="line">    -D mapred<span class="class">.reduce</span><span class="class">.tasks</span>=<span class="number">512</span> \</span><br><span class="line">    -D hadoop<span class="class">.sstable</span><span class="class">.split</span><span class="class">.mb</span>=<span class="number">1024</span> \</span><br><span class="line">    -D mapred<span class="class">.child</span><span class="class">.java</span><span class="class">.opts</span>=<span class="string">"-Xmx2G -XX:MaxPermSize=256m"</span> \</span><br><span class="line">    /user/qihuang.zheng/velocity_backup_1107/<span class="number">226</span>_1105/<span class="number">1</span>/forseti/velocity /user/qihuang.zheng/velocity_test</span><br></pre></td></tr></table></figure>
<blockquote>
<p>F**k, 发现hadoop.ssable.cql中的timestamp本身有双引号! 改成单引号, 但是单引号本身在建表时就不支持! 用转义字符…  </p>
</blockquote>
<h3 id="Shell$ExitCodeException">Shell$ExitCodeException</h3><p><a href="http://stackoverflow.com/questions/22579943/yarn-mapreduce-job-issue-am-container-launch-error-in-hadoop-2-3-0" target="_blank" rel="external">http://stackoverflow.com/questions/22579943/yarn-mapreduce-job-issue-am-container-launch-error-in-hadoop-2-3-0</a><br>之前在跑example的wordcount时遇到这个问题, 后来在<code>hadoop-env.sh, mapred-env.sh, yarn-env.sh</code>中都添加export..就可以了, 但是这里的example却没有问题.  </p>
<figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">15</span><span class="regexp">/11/</span><span class="number">07</span> <span class="number">17</span>:<span class="number">28</span>:<span class="number">51</span> INFO mapreduce.<span class="string">Job:</span> Running <span class="string">job:</span> job_1446657831952_0012</span><br><span class="line"><span class="number">15</span><span class="regexp">/11/</span><span class="number">07</span> <span class="number">17</span>:<span class="number">29</span>:<span class="number">01</span> INFO mapreduce.<span class="string">Job:</span> Job job_1446657831952_0012 running <span class="keyword">in</span> uber <span class="string">mode :</span> <span class="literal">false</span></span><br><span class="line"><span class="number">15</span><span class="regexp">/11/</span><span class="number">07</span> <span class="number">17</span>:<span class="number">29</span>:<span class="number">01</span> INFO mapreduce.<span class="string">Job:</span>  map <span class="number">0</span>% reduce <span class="number">0</span>%</span><br><span class="line"><span class="number">15</span><span class="regexp">/11/</span><span class="number">07</span> <span class="number">17</span>:<span class="number">29</span>:<span class="number">01</span> INFO mapreduce.<span class="string">Job:</span> Job job_1446657831952_0012 failed with state FAILED due <span class="string">to:</span> Application application_1446657831952_0012 failed <span class="number">2</span> times due to AM Container <span class="keyword">for</span> appattempt_1446657831952_0012_000002 exited with  <span class="string">exitCode:</span> <span class="number">1</span> due <span class="string">to:</span> </span><br><span class="line">Exception from container-<span class="string">launch:</span> org.apache.hadoop.util.<span class="string">Shell$ExitCodeException:</span></span><br><span class="line">org.apache.hadoop.util.<span class="string">Shell$ExitCodeException:</span></span><br><span class="line">    at org.apache.hadoop.util.Shell.runCommand(Shell.<span class="string">java:</span><span class="number">505</span>)</span><br><span class="line">    at org.apache.hadoop.util.Shell.run(Shell.<span class="string">java:</span><span class="number">418</span>)</span><br><span class="line">    at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.<span class="string">java:</span><span class="number">650</span>)</span><br><span class="line">    at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.<span class="string">java:</span><span class="number">195</span>)</span><br><span class="line">    at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.<span class="string">java:</span><span class="number">300</span>)</span><br><span class="line">    at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.<span class="string">java:</span><span class="number">81</span>)</span><br><span class="line">    at java.util.concurrent.FutureTask.run(FutureTask.<span class="string">java:</span><span class="number">262</span>)</span><br><span class="line">    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.<span class="string">java:</span><span class="number">1145</span>)</span><br><span class="line">    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.<span class="string">java:</span><span class="number">615</span>)</span><br><span class="line">    at java.lang.Thread.run(Thread.<span class="string">java:</span><span class="number">744</span>)</span><br><span class="line">Container exited with a non-zero exit code <span class="number">1</span></span><br><span class="line">.Failing <span class="keyword">this</span> attempt.. Failing the application.</span><br><span class="line"><span class="number">15</span><span class="regexp">/11/</span><span class="number">07</span> <span class="number">17</span>:<span class="number">29</span>:<span class="number">01</span> INFO mapreduce.<span class="string">Job:</span> <span class="string">Counters:</span> <span class="number">0</span></span><br><span class="line"><span class="number">15</span><span class="regexp">/11/</span><span class="number">07</span> <span class="number">17</span>:<span class="number">29</span>:<span class="number">01</span> INFO example.<span class="string">SimpleExample:</span> Total <span class="string">runtime:</span> <span class="number">21</span>s</span><br><span class="line">  </span><br><span class="line"><span class="regexp">/usr/</span>install<span class="regexp">/hadoop/</span>bin<span class="regexp">/hadoop jar /</span>usr<span class="regexp">/install/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/mapreduce/</span>hadoop-mapreduce-examples-<span class="number">2.4</span><span class="number">.1</span>.jar wordcount <span class="regexp">/user/</span>qihuang.zheng<span class="regexp">/test3 /</span>user<span class="regexp">/qihuang.zheng/</span>test4</span><br><span class="line"><span class="regexp">/usr/</span>install<span class="regexp">/hadoop/</span>bin<span class="regexp">/hadoop jar /</span>usr<span class="regexp">/install/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/mapreduce/</span>hadoop-mapreduce-examples-<span class="number">2.4</span><span class="number">.1</span>.jar pi <span class="number">10</span> <span class="number">100</span></span><br><span class="line"><span class="regexp">/usr/</span>install<span class="regexp">/hadoop/</span>bin<span class="regexp">/hadoop jar /</span>usr<span class="regexp">/install/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>hadoop-yarn-applications-distributedshell-<span class="number">2.4</span><span class="number">.1</span>.jar  \</span><br><span class="line">--jar <span class="regexp">/usr/</span>install<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>yarn/hadoop-yarn-applications-distributedshell-<span class="number">2.4</span><span class="number">.1</span>.jar  \</span><br><span class="line">org.apache.hadoop.yarn.applications.distributedshell.Client  \</span><br><span class="line">-shell_command ls -shell_args <span class="string">'/tmp'</span> -num_containers <span class="number">3</span> -container_memory <span class="number">1024</span></span><br><span class="line"></span><br><span class="line">export HADOOP_HOME=<span class="regexp">/usr/</span>install/hadoop</span><br><span class="line">export YARN_HOME=$&#123;HADOOP_HOME&#125;</span><br><span class="line">export HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;</span><br><span class="line">export HADOOP_COMMON_HOME=$&#123;HADOOP_HOME&#125;</span><br><span class="line">export HADOOP_HDFS_HOME=$&#123;HADOOP_HOME&#125;</span><br><span class="line">export HADOOP_YARN_HOME=$&#123;HADOOP_HOME&#125;</span><br><span class="line">export HADOOP_CONF_DIR=$&#123;HADOOP_HOME&#125;<span class="regexp">/etc/</span>hadoop</span><br><span class="line">export HDFS_CONF_DIR=$&#123;HADOOP_HOME&#125;<span class="regexp">/etc/</span>hadoop</span><br><span class="line">export YARN_CONF_DIR=$&#123;HADOOP_HOME&#125;<span class="regexp">/etc/</span>hadoop</span><br><span class="line"></span><br><span class="line">export CLASSPATH=<span class="string">"$CLASSPATH:$HADOOP_CONF_DIR:$HADOOP_COMMON_HOME/share/hadoop/common/*:$HADOOP_COMMON_HOME/share/hadoop/common/lib/*:$HADOOP_HDFS_HOME/share/hadoop/hdfs/*:$HADOOP_HDFS_HOME/share/hadoop/hdfs/lib/*:$HADOOP_YARN_HOME/share/hadoop/yarn/*:$HADOOP_YARN_HOME/share/hadoop/yarn/lib/*:$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/*:$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/*"</span></span><br><span class="line">这里加载的jar包包括了share/hadoop下的common,hdfs,yarn,mapreduce,以及各自下面的lib.</span><br></pre></td></tr></table></figure>
<h3 id="yarn_log查看日志:_找不到cassandra-all的jar包">yarn log查看日志: 找不到cassandra-all的jar包</h3><p>实际的报错是怎么发生的呢? 因为任何的错误只要执行失败, 在最后都会报上面的Exist异常(是吗?).<br>默认的日志级别在/usr/install/hadoop/etc/hadoop/log4j.properties的<code>INFO,console</code>.<br>可以修改为DEBUG: <code>export HADOOP_ROOT_LOGGER=&quot;DEBUG,console&quot;</code>, 这样不需要重启即可.    </p>
<p>重新运行之前的hadoop jar命令, 打印在控制台的日志如下:  </p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">15</span>/<span class="number">11</span>/<span class="number">07</span> <span class="number">17</span>:<span class="number">43</span>:<span class="number">43</span> DEBUG ipc.ProtobufRpcEngine: Call: getListing took <span class="number">5</span>ms</span><br><span class="line"><span class="number">15</span>/<span class="number">11</span>/<span class="number">07</span> <span class="number">17</span>:<span class="number">43</span>:<span class="number">43</span> DEBUG input.FileInputFormat: Time taken to get FileStatuses: <span class="number">136</span></span><br><span class="line"><span class="number">15</span>/<span class="number">11</span>/<span class="number">07</span> <span class="number">17</span>:<span class="number">43</span>:<span class="number">43</span> INFO input.FileInputFormat: Total input paths to process : <span class="number">70</span></span><br><span class="line"><span class="number">15</span>/<span class="number">11</span>/<span class="number">07</span> <span class="number">17</span>:<span class="number">43</span>:<span class="number">43</span> DEBUG mapreduce.SSTableInputFormat: Initial file <span class="built_in">list</span>: <span class="number">70</span> [LocatedFileStatus&#123;path=hdfs:<span class="comment">//tdhdfs/user/qihuang.zheng/velocity_backup_1107/226_1105/1/forseti/velocity/forseti-velocity-jb-102234-CompressionInfo.db; isDirectory=false; length=87211; replication=3; blocksize=134217728; modification_time=1446861739953; access_time=1446861739918; owner=qihuang.zheng; group=supergroup; permission=rw-r--r--; isSymlink=false&#125;,</span></span><br><span class="line"><span class="number">15</span>/<span class="number">11</span>/<span class="number">07</span> <span class="number">17</span>:<span class="number">43</span>:<span class="number">43</span> DEBUG mapreduce.SSTableInputFormat: Removing non-sstable file: hdfs:<span class="comment">//tdhdfs/user/qihuang.zheng/velocity_backup_1107/226_1105/1/forseti/velocity/forseti-velocity-jb-102234-CompressionInfo.db</span></span><br><span class="line"><span class="number">15</span>/<span class="number">11</span>/<span class="number">07</span> <span class="number">17</span>:<span class="number">43</span>:<span class="number">43</span> DEBUG mapreduce.SSTableInputFormat: Reading index file <span class="keyword">for</span> sstable file: hdfs:<span class="comment">//tdhdfs/user/qihuang.zheng/velocity_backup_1107/226_1105/1/forseti/velocity/forseti-velocity-jb-102234-Data.db</span></span><br><span class="line"><span class="number">15</span>/<span class="number">11</span>/<span class="number">07</span> <span class="number">17</span>:<span class="number">43</span>:<span class="number">43</span> DEBUG mapreduce.SSTableInputFormat: Reading index file: hdfs:<span class="comment">//tdhdfs/user/qihuang.zheng/velocity_backup_1107/226_1105/1/forseti/velocity/forseti-velocity-jb-102234-Index.db</span></span><br><span class="line"><span class="number">15</span>/<span class="number">11</span>/<span class="number">07</span> <span class="number">17</span>:<span class="number">43</span>:<span class="number">43</span> DEBUG mapreduce.SSTableInputFormat: Final file <span class="built_in">list</span>: <span class="number">10</span> [LocatedFileStatus&#123;path=hdfs:<span class="comment">//tdhdfs/user/qihuang.zheng/velocity_backup_1107/226_1105/1/forseti/velocity/forseti-velocity-jb-102234-Data.db; isDirectory=false; length=172873282; replication=3; blocksize=134217728;</span></span><br><span class="line"><span class="number">15</span>/<span class="number">11</span>/<span class="number">07</span> <span class="number">17</span>:<span class="number">43</span>:<span class="number">43</span> DEBUG mapreduce.SSTableInputFormat: Splits calculated: <span class="number">10</span> [SSTableSplit&#123;dataStart=<span class="number">0</span>, dataEnd=<span class="number">0</span>, idxStart=<span class="number">0</span>, length=<span class="number">8472466</span>, idxEnd=<span class="number">8472466</span>, dataFile=hdfs:<span class="comment">//tdhdfs/user/qihuang.zheng/velocity_backup_1107/226_1105/1/forseti/velocity/forseti-velocity-jb-102234-Data.db,</span></span><br></pre></td></tr></table></figure>
<p>如果去掉参数<code>-D hadoop.sstable.cql</code>, 也没有打印出日志<code>Failed CQL create statement empty</code>.<br>说明Mapper都没有执行(因为map有执行的话没指定cql一定会报异常), 尽管我们前面看到SSTableInputFormat的输入都很正常.<br>因为Mapper没有执行, 所有我们看到map 0% reduce 0%中map都没有跑, 最后就报异常了. 为什么mapper没有被调用??   </p>
<p><a href="http://zh.hortonworks.com/community/forums/topic/hadoop-2-0-remote-job-client-fails-with-shell-exit-code-exception/" target="_blank" rel="external">http://zh.hortonworks.com/community/forums/topic/hadoop-2-0-remote-job-client-fails-with-shell-exit-code-exception/</a>提到查看日志的方式:  </p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">/usr/install/hadoop/bin/yarn logs -applicationId application_1446657831952_0020</span><br><span class="line"></span><br><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">08</span> <span class="number">13</span>:<span class="number">28</span>:<span class="number">25</span>,<span class="number">780</span> FATAL [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Error starting MRAppMaster</span><br><span class="line">java.lang.NoClassDefFoundError: org/apache/cassandra/exceptions/RequestValidationException</span><br><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">08</span> <span class="number">13</span>:<span class="number">28</span>:<span class="number">25</span>,<span class="number">782</span> INFO [main] org.apache.hadoop.util.ExitUtil: Exiting with status <span class="number">1</span></span><br></pre></td></tr></table></figure>
<p>没有找到RequestValidationException, 这个类是在cassandra-all-2.0.15.jar中, 虽然前面设置到了HADOOP_CLASSPATH, 但是貌似仍然没能获取到cassandra的jar包:  </p>
<figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="regexp">/usr/i</span>nstall<span class="regexp">/hadoop/</span>bin<span class="regexp">/hadoop fs -put cassandra-all-2.0.15.jar /u</span>ser<span class="regexp">/qihuang.zheng</span></span><br></pre></td></tr></table></figure>
<p>将cassandra-all-2.0.15.jar上次到hdfs的用户目录下, 并指定-libjars运行:  </p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">/usr/install/hadoop/bin/hadoop jar hadoop-sstable-<span class="number">2.0</span>.<span class="number">0</span><span class="class">.jar</span> com<span class="class">.fullcontact</span><span class="class">.sstable</span><span class="class">.example</span><span class="class">.SimpleExample</span> \</span><br><span class="line">    -libjars cassandra-all-<span class="number">2.0</span>.<span class="number">15</span><span class="class">.jar</span> \</span><br><span class="line">    -D hadoop<span class="class">.sstable</span><span class="class">.cql</span>=<span class="string">"CREATE TABLE velocity (attribute text,partner_code text,app_name text,type text,\"timestamp\" bigint,event text,sequence_id text,PRIMARY KEY ((attribute), partner_code, app_name, type, \"timestamp\")) WITH compression=&#123;'sstable_compression': 'LZ4Compressor'&#125;"</span> \</span><br><span class="line">    -D mapred<span class="class">.task</span><span class="class">.timeout</span>=<span class="number">21600000</span> \</span><br><span class="line">    -D mapred<span class="class">.map</span><span class="class">.tasks</span><span class="class">.speculative</span><span class="class">.execution</span>=false \</span><br><span class="line">    -D mapred<span class="class">.job</span><span class="class">.reuse</span><span class="class">.jvm</span><span class="class">.num</span><span class="class">.tasks</span>=<span class="number">1</span> \</span><br><span class="line">    -D io<span class="class">.sort</span><span class="class">.mb</span>=<span class="number">1000</span> \</span><br><span class="line">    -D io<span class="class">.sort</span><span class="class">.factor</span>=<span class="number">100</span> \</span><br><span class="line">    -D mapred<span class="class">.reduce</span><span class="class">.tasks</span>=<span class="number">512</span> \</span><br><span class="line">    -D hadoop<span class="class">.sstable</span><span class="class">.split</span><span class="class">.mb</span>=<span class="number">1024</span> \</span><br><span class="line">    -D mapred<span class="class">.child</span><span class="class">.java</span><span class="class">.opts</span>=<span class="string">"-Xmx2G -XX:MaxPermSize=256m"</span> \</span><br><span class="line">    -D hadoop<span class="class">.sstable</span><span class="class">.keyspace</span>=<span class="string">"forseti"</span> \</span><br><span class="line">    -D hadoop<span class="class">.sstable</span><span class="class">.column</span><span class="class">.family</span><span class="class">.name</span>=<span class="string">"velocity"</span> \</span><br><span class="line">    /user/qihuang.zheng/velocity_backup_1107/<span class="number">226</span>_1105/<span class="number">1</span>/forseti/velocity /user/qihuang.zheng/velocity_test</span><br></pre></td></tr></table></figure>
<blockquote>
<p>这里的libjars实际上是本地的, 在当前用户目录下存在cassandra-all-2.0.15.jar, 为了保险起见也将它放到了HDFS的home目录下.  </p>
</blockquote>
<h3 id="cassandra/lib下的jar包">cassandra/lib下的jar包</h3><p>继续运行, 会在命令行报错没有找到supercsv(不再是Shell退出的异常了), 这个类是cassandra的lib: super-csv-2.1.0.jar下.<br>所以虽然前面指定的HADOOP_CLASSPATH包含了/usr/install/cassandra/lib下的所有jar包. 但貌似没起作用!  </p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">15</span>/<span class="number">11</span>/<span class="number">08</span> <span class="number">15</span>:<span class="number">11</span>:<span class="number">39</span> INFO mapreduce<span class="class">.Job</span>: Task Id : attempt_1446657831952_0020_m_000001_0, Status : FAILED</span><br><span class="line">Error: java<span class="class">.lang</span><span class="class">.ClassNotFoundException</span>: org<span class="class">.supercsv</span><span class="class">.prefs</span><span class="class">.CsvPreference</span><span class="variable">$Builder</span></span><br></pre></td></tr></table></figure>
<p>那么是不是要把cassandra/lib下的所有jar包都加到-libjars下面呢? 还有这里的libjars指定的是本地的, 还是HDFS的?   </p>
<figure class="highlight crystal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">/usr/install/hadoop/bin/hadoop fs -mkdir cassandra-<span class="number">2.0</span>.<span class="number">15</span></span><br><span class="line">/usr/install/hadoop/bin/hadoop fs -put /usr/install/cassandra/<span class="class"><span class="keyword">lib</span>/*.<span class="title">jar</span> <span class="title">cassandra</span>-2.0.15</span></span><br><span class="line">/usr/install/hadoop/bin/hadoop fs -put cassandra-all-<span class="number">2.0</span>.<span class="number">15</span>.jar cassandra-<span class="number">2.0</span>.<span class="number">15</span></span><br><span class="line"></span><br><span class="line"><span class="constant">CLASSPATH</span>的分隔符是冒号:  </span><br><span class="line">ls /usr/install/cassandra/<span class="class"><span class="keyword">lib</span>/*.<span class="title">jar</span> | <span class="title">awk</span> '&#123;<span class="title">print</span> $0&#125;' | <span class="title">tr</span> '\<span class="title">n</span>' ':' |<span class="title">sed</span> '<span class="title">s</span>/:$//'</span></span><br><span class="line">export <span class="constant">HADOOP_CLASSPATH</span>=cassandra-all-<span class="number">2.0</span>.<span class="number">15</span>.<span class="symbol">jar:</span>/usr/install/cassandra/<span class="class"><span class="keyword">lib</span>/<span class="title">antlr</span>-3.2.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">install</span>/<span class="title">cassandra</span>......</span></span><br><span class="line"></span><br><span class="line">libjars则是逗号分隔符(本地和<span class="constant">HDFS</span>):  </span><br><span class="line">ls /usr/install/cassandra/<span class="class"><span class="keyword">lib</span>/*.<span class="title">jar</span> | <span class="title">awk</span> '&#123;<span class="title">print</span> $0&#125;' | <span class="title">tr</span> '\<span class="title">n</span>' ',' |<span class="title">sed</span> '<span class="title">s</span>/,$//'</span></span><br><span class="line">/usr/install/hadoop/bin/hadoop fs -ls cassandra-<span class="number">2.0</span>.<span class="number">15</span> | awk <span class="string">'&#123;print $8&#125;'</span> | tr <span class="string">'\n'</span> <span class="string">','</span> |sed <span class="string">'s/,$//'</span></span><br><span class="line"></span><br><span class="line">用本地的jar包:  </span><br><span class="line"><span class="regexp">/usr/install</span><span class="regexp">/hadoop/bin</span><span class="regexp">/hadoop jar hadoop-sstable-2.0.0.jar com.fullcontact.sstable.example.SimpleExample \</span><br><span class="line">    -libjars cassandra-all-2.0.15.jar,/usr</span><span class="regexp">/install/cassandra</span><span class="regexp">/lib/antlr</span>-<span class="number">3.2</span>.jar,<span class="regexp">/usr/install</span><span class="regexp">/cassandra/lib</span><span class="regexp">/apache-cassandra-2.0.15.jar,/usr</span>........</span><br><span class="line">    -<span class="constant">D</span> hadoop.sstable.cql=<span class="string">"CREATE TABLE velocity (attribute text,partner_code text,app_name text,type text,\"timestamp\" bigint,event text,sequence_id text,PRIMARY KEY ((attribute), partner_code, app_name, type, \"timestamp\")) WITH compression=&#123;'sstable_compression': 'LZ4Compressor'&#125;"</span> \</span><br><span class="line">    -<span class="constant">D</span> mapred.task.timeout=<span class="number">21600000</span> \</span><br><span class="line">    -<span class="constant">D</span> mapred.map.tasks.speculative.execution=<span class="literal">false</span> \</span><br><span class="line">    -<span class="constant">D</span> mapred.job.reuse.jvm.num.tasks=<span class="number">1</span> \</span><br><span class="line">    -<span class="constant">D</span> io.sort.mb=<span class="number">1000</span> \</span><br><span class="line">    -<span class="constant">D</span> io.sort.factor=<span class="number">100</span> \</span><br><span class="line">    -<span class="constant">D</span> mapred.reduce.tasks=<span class="number">512</span> \</span><br><span class="line">    -<span class="constant">D</span> hadoop.sstable.split.mb=<span class="number">1024</span> \</span><br><span class="line">    -<span class="constant">D</span> mapred.child.java.opts=<span class="string">"-Xmx4G -XX:MaxPermSize=512m"</span> \</span><br><span class="line">    -<span class="constant">D</span> hadoop.sstable.keyspace=<span class="string">"forseti"</span> \</span><br><span class="line">    -<span class="constant">D</span> hadoop.sstable.column.family.name=<span class="string">"velocity"</span> \</span><br><span class="line">    /user/qihuang.zheng/velocity_backup_1107/<span class="number">226_1105</span>/<span class="number">1</span>/forseti/velocity /user/qihuang.zheng/velocity_test13</span><br></pre></td></tr></table></figure>
<p>注意jar包以逗号分隔,而不是冒号分隔,否则会报错说jar包不存在, 不存在不是指在HDFS中不存在, 而是路径有问题, 不被-libjars认识.    </p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Exception <span class="keyword">in</span> thread <span class="string">"main"</span> java<span class="class">.io</span><span class="class">.FileNotFoundException</span>: File cassandra-<span class="number">2.0</span>.<span class="number">15</span>/antlr-<span class="number">3.2</span><span class="class">.jar</span>: ...<span class="class">.does</span> not exist.</span><br></pre></td></tr></table></figure>
<p>上面通过将cassandra/lib所有jar包加入到-libjars下, 也可以在编译的时候把cassandra做成fatjar, 这样就不需要指定-libjars参数了.  </p>
<figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="title">fatjar</span> <span class="string">'org.apache.cassandra:cassandra-all:2.0.15'</span></span><br></pre></td></tr></table></figure>
<h3 id="yarn_log日志打印不出来,_是/user/history权限问题">yarn log日志打印不出来, 是/user/history权限问题</h3><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">guava的什么鬼问题, 只是Error,并没有提示说NoSuchMethod, 那么怎么查看具体的日志呢?    </span><br><span class="line">15/11/08 17:<span class="number">02</span>:<span class="number">02</span> INFO mapreduce.<span class="string">Job:</span> Task <span class="string">Id :</span> attempt_1446657831952_0021_m_000003_0, <span class="string">Status :</span> FAILED</span><br><span class="line"><span class="string">Error:</span> com.google.common.collect.Sets.newConcurrentHashSet()Ljava<span class="regexp">/util/</span>Set;</span><br><span class="line">Container killed by the ApplicationMaster.</span><br><span class="line">Container killed on request. Exit code is <span class="number">143</span></span><br><span class="line">Container exited with a non-zero exit code <span class="number">143</span></span><br><span class="line"></span><br><span class="line">用yarn现在连日志都出不来了. 所以我们需要查看application的日志!    </span><br><span class="line">[qihuang.zheng<span class="annotation">@spark</span>047219 ~]$ <span class="regexp">/usr/</span>install<span class="regexp">/hadoop/</span>bin/yarn logs -applicationId application_1446657831952_0021</span><br><span class="line"><span class="string">SLF4J:</span> Class path contains multiple SLF4J bindings.</span><br><span class="line"><span class="string">SLF4J:</span> Found binding <span class="keyword">in</span> [<span class="string">jar:</span><span class="string">file:</span><span class="regexp">/usr/</span>install<span class="regexp">/hadoop-2.4.1/</span>share<span class="regexp">/hadoop/</span>common<span class="regexp">/lib/</span>slf4j-log4j12-<span class="number">1.7</span><span class="number">.5</span>.jar!<span class="regexp">/org/</span>slf4j<span class="regexp">/impl/</span>StaticLoggerBinder.<span class="keyword">class</span>]</span><br><span class="line"><span class="string">SLF4J:</span> Found binding <span class="keyword">in</span> [<span class="string">jar:</span><span class="string">file:</span><span class="regexp">/usr/</span>install<span class="regexp">/apache-cassandra-2.0.15/</span>lib<span class="regexp">/slf4j-log4j12-1.7.2.jar!/</span>org<span class="regexp">/slf4j/</span>impl/StaticLoggerBinder.<span class="keyword">class</span>]</span><br><span class="line"><span class="string">SLF4J:</span> See <span class="string">http:</span><span class="comment">//www.slf4j.org/codes.html#multiple_bindings for an explanation.</span></span><br><span class="line"><span class="string">SLF4J:</span> Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]</span><br><span class="line"><span class="number">15</span><span class="regexp">/11/</span><span class="number">08</span> <span class="number">17</span>:<span class="number">33</span>:<span class="number">04</span> INFO client.<span class="string">ConfiguredRMFailoverProxyProvider:</span> Failing over to rm2</span><br></pre></td></tr></table></figure>
<p>找到当前 <strong>作业的运行节点</strong> 然后进入改节点的日志目录查看 <strong>appliation的日志</strong>.<br>如果遇到history日志权限问题, 需要修改hdfs上的/user/history目录:  </p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">08</span> <span class="number">17</span>:<span class="number">51</span>:<span class="number">52</span>,<span class="number">814</span> INFO [Thread-<span class="number">66</span>] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: </span><br><span class="line">Unable to write out JobSummaryInfo to [hdfs:<span class="comment">//tdhdfs/user/history/done_intermediate/qihuang.zheng/job_1446657831952_0029.summary_tmp]</span></span><br><span class="line">org.apache.hadoop.security.AccessControlException: Permission denied: user=qihuang.zheng, access=EXECUTE, inode=<span class="string">"/user/history"</span>:admin:supergroup:drwxrwx---</span><br><span class="line"></span><br><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">08</span> <span class="number">17</span>:<span class="number">51</span>:<span class="number">52</span>,<span class="number">816</span> INFO [Thread-<span class="number">66</span>] org.apache.hadoop.service.AbstractService: Service JobHistoryEventHandler failed in state STOPPED; </span><br><span class="line">cause: org.apache.hadoop.yarn.exceptions.YarnRuntimeException: org.apache.hadoop.security.AccessControlException: </span><br><span class="line">Permission denied: user=qihuang.zheng, access=EXECUTE, inode=<span class="string">"/user/history"</span>:admin:supergroup:drwxrwx---</span><br><span class="line"></span><br><span class="line">/usr/install/hadoop/bin/hadoop fs -ls /user/ | grep history</span><br><span class="line">drwxrwx---   - admin          supergroup          <span class="number">0</span> <span class="number">2015</span>-<span class="number">05</span>-<span class="number">04</span> <span class="number">14</span>:<span class="number">58</span> /user/history</span><br><span class="line"></span><br><span class="line">sudo -u admin /usr/install/hadoop/bin/hadoop fs -chmod -R <span class="number">777</span> /user/history</span><br><span class="line"></span><br><span class="line">/usr/install/hadoop/bin/hadoop fs -ls /user/history</span><br><span class="line">drwxrwxrwx   - admin supergroup          <span class="number">0</span> <span class="number">2015</span>-<span class="number">05</span>-<span class="number">04</span> <span class="number">15</span>:<span class="number">01</span> /user/history/done</span><br><span class="line">drwxrwxrwt   - admin supergroup          <span class="number">0</span> <span class="number">2015</span>-<span class="number">10</span>-<span class="number">23</span> <span class="number">17</span>:<span class="number">06</span> /user/history/done_intermediate</span><br></pre></td></tr></table></figure>
<h3 id="guava版本问题">guava版本问题</h3><blockquote>
<p>下面两种查看日志的方式使用1.yarn logs比较方便, 可以结合&gt;输出到文件查看,否则满屏都是.<br>而第二种要登陆到作业的运行节点,还要再找到这个Application, 更改application文件夹的权限,才能找到container的日志.   </p>
</blockquote>
<p>1.查看日志的方式也可以通过上面进入节点的application, 选择一个container的日志:  </p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">cd /home/admin/output/hadoop/logs/application_1446657831952_0030</span><br><span class="line">vi + /container_1446657831952_0030_01_000010</span><br><span class="line"></span><br><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">08</span> <span class="number">18</span>:<span class="number">02</span>:<span class="number">06</span>,<span class="number">897</span> INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir <span class="keyword">for</span> child: /home/admin/hadoop/data/yarn-tmp/nmdir/usercache/qihuang.zheng/appcache/application_1446657831952_0030</span><br><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">08</span> <span class="number">18</span>:<span class="number">02</span>:<span class="number">07</span>,<span class="number">830</span> INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: SSTableSplit&#123;dataStart=<span class="number">0</span>, dataEnd=<span class="number">0</span>, idxStart=<span class="number">0</span>, length=<span class="number">8497039</span>, idxEnd=<span class="number">8497039</span>, dataFile=hdfs:<span class="comment">//tdhdfs/user/qihuang.zheng/velocity_backup_1107/226_1105/1/forseti/velocity/forseti-velocity-jb-96999-Data.db, hosts=null&#125;</span></span><br><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">08</span> <span class="number">18</span>:<span class="number">02</span>:<span class="number">07</span>,<span class="number">843</span> INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector <span class="keyword">class</span> = org.apache.hadoop.mapred.MapTask$MapOutputBuffer</span><br><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">08</span> <span class="number">18</span>:<span class="number">02</span>:<span class="number">08</span>,<span class="number">399</span> FATAL [main] org.apache.hadoop.mapred.YarnChild: Error running child : java.lang.NoSuchMethodError: com.google.common.collect.Sets.newConcurrentHashSet()Ljava/util/Set;</span><br><span class="line">        at org.apache.cassandra.config.Config.&lt;init&gt;(Config.java:<span class="number">55</span>)</span><br><span class="line">        at org.apache.cassandra.config.DatabaseDescriptor.&lt;clinit&gt;(DatabaseDescriptor.java:<span class="number">106</span>)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>这下终于爆出了正确的异常信息, 不像前面只有一个Error,鬼知道是什么错误.  </p>
</blockquote>
<p>2.或者上面修复了/user/history的权限问题后, yarn logs也能正常打印出日志了:  </p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">[qihuang.zheng@spark047219 ~]$ /usr/install/hadoop/bin/yarn logs -applicationId application_1446657831952_0030</span><br><span class="line">Container: container_1446657831952_0030_01_000004 on cass047208_44431</span><br><span class="line">=======================================================================</span><br><span class="line">LogType: <span class="built_in">stderr</span></span><br><span class="line">LogLength: <span class="number">803</span></span><br><span class="line">Log Contents:</span><br><span class="line"></span><br><span class="line">LogType: <span class="built_in">stdout</span></span><br><span class="line">LogLength: <span class="number">247</span></span><br><span class="line">Log Contents:</span><br><span class="line">Initialized split: SSTableSplit&#123;dataStart=<span class="number">0</span>, dataEnd=<span class="number">586888015</span>, idxStart=<span class="number">0</span>, length=<span class="number">8472466</span>, idxEnd=<span class="number">8472466</span>, dataFile=hdfs:<span class="comment">//tdhdfs/user/qihuang.zheng/velocity_backup_1107/226_1105/1/forseti/velocity/forseti-velocity-jb-102234-Data.db, hosts=null&#125;</span></span><br><span class="line"></span><br><span class="line">LogType: syslog</span><br><span class="line">LogLength: <span class="number">4560</span></span><br><span class="line">Log Contents:</span><br><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">08</span> <span class="number">18</span>:<span class="number">02</span>:<span class="number">06</span>,<span class="number">721</span> INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:</span><br><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">08</span> <span class="number">18</span>:<span class="number">02</span>:<span class="number">06</span>,<span class="number">721</span> INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1446657831952_0030, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@<span class="number">71</span>b72681)</span><br><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">08</span> <span class="number">18</span>:<span class="number">02</span>:<span class="number">06</span>,<span class="number">787</span> INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping <span class="keyword">for</span> <span class="number">0</span>ms before retrying again. Got null now.</span><br><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">08</span> <span class="number">18</span>:<span class="number">02</span>:<span class="number">07</span>,<span class="number">035</span> INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir <span class="keyword">for</span> child: /home/admin/hadoop/data/yarn-tmp/nmdir/usercache/qihuang.zheng/appcache/application_1446657831952_0030</span><br><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">08</span> <span class="number">18</span>:<span class="number">02</span>:<span class="number">07</span>,<span class="number">457</span> INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id</span><br><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">08</span> <span class="number">18</span>:<span class="number">02</span>:<span class="number">07</span>,<span class="number">841</span> INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]</span><br><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">08</span> <span class="number">18</span>:<span class="number">02</span>:<span class="number">08</span>,<span class="number">079</span> INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: SSTableSplit&#123;dataStart=<span class="number">0</span>, dataEnd=<span class="number">0</span>, idxStart=<span class="number">0</span>, length=<span class="number">8472466</span>, idxEnd=<span class="number">8472466</span>, dataFile=hdfs:<span class="comment">//tdhdfs/user/qihuang.zheng/velocity_backup_1107/226_1105/1/forseti/velocity/forseti-velocity-jb-102234-Data.db, hosts=null&#125;</span></span><br><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">08</span> <span class="number">18</span>:<span class="number">02</span>:<span class="number">08</span>,<span class="number">093</span> INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector <span class="keyword">class</span> = org.apache.hadoop.mapred.MapTask$MapOutputBuffer</span><br><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">08</span> <span class="number">18</span>:<span class="number">02</span>:<span class="number">08</span>,<span class="number">384</span> INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) <span class="number">0</span> kvi <span class="number">262143996</span>(<span class="number">1048575984</span>)</span><br><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">08</span> <span class="number">18</span>:<span class="number">02</span>:<span class="number">08</span>,<span class="number">385</span> INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: <span class="number">1000</span></span><br><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">08</span> <span class="number">18</span>:<span class="number">02</span>:<span class="number">08</span>,<span class="number">385</span> INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at <span class="number">838860800</span></span><br><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">08</span> <span class="number">18</span>:<span class="number">02</span>:<span class="number">08</span>,<span class="number">385</span> INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = <span class="number">0</span>; bufvoid = <span class="number">1048576000</span></span><br><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">08</span> <span class="number">18</span>:<span class="number">02</span>:<span class="number">08</span>,<span class="number">385</span> INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = <span class="number">262143996</span>; length = <span class="number">65536000</span></span><br><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">08</span> <span class="number">18</span>:<span class="number">02</span>:<span class="number">08</span>,<span class="number">461</span> INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of <span class="built_in">map</span> output</span><br><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">08</span> <span class="number">18</span>:<span class="number">02</span>:<span class="number">08</span>,<span class="number">531</span> FATAL [main] org.apache.hadoop.mapred.YarnChild: Error running child : java.lang.NoSuchMethodError: com.google.common.collect.Sets.newConcurrentHashSet()Ljava/util/Set;</span><br><span class="line">    at org.apache.cassandra.config.Config.&lt;init&gt;(Config.java:<span class="number">55</span>)</span><br><span class="line">    at org.apache.cassandra.config.DatabaseDescriptor.&lt;clinit&gt;(DatabaseDescriptor.java:<span class="number">106</span>)</span><br><span class="line">    at org.apache.cassandra.io.util.Memory.&lt;clinit&gt;(Memory.java:<span class="number">31</span>)</span><br><span class="line">    at com.fullcontact.cassandra.io.compress.CompressionMetadata.readChunkOffsets(CompressionMetadata.java:<span class="number">168</span>)</span><br><span class="line">    at com.fullcontact.cassandra.io.compress.CompressionMetadata.&lt;init&gt;(CompressionMetadata.java:<span class="number">125</span>)</span><br><span class="line">    at com.fullcontact.cassandra.io.compress.CompressionMetadata.create(CompressionMetadata.java:<span class="number">73</span>)</span><br><span class="line">    at com.fullcontact.sstable.hadoop.mapreduce.SSTableRecordReader.initialize(SSTableRecordReader.java:<span class="number">69</span>)</span><br><span class="line">    at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:<span class="number">525</span>)</span><br><span class="line">    at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:<span class="number">763</span>)</span><br><span class="line">    at org.apache.hadoop.mapred.MapTask.run(MapTask.java:<span class="number">340</span>)</span><br><span class="line">    at org.apache.hadoop.mapred.YarnChild$<span class="number">2.</span>run(YarnChild.java:<span class="number">167</span>)</span><br><span class="line">    at java.security.AccessController.doPrivileged(Native Method)</span><br><span class="line">    at javax.security.auth.Subject.doAs(Subject.java:<span class="number">415</span>)</span><br><span class="line">    at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:<span class="number">1556</span>)</span><br><span class="line">    at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:<span class="number">162</span>)</span><br></pre></td></tr></table></figure>
<p>可以看到MapTask有在运行, 如果去掉<code>hadoop.sstable.cql</code>:  </p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">15</span>/<span class="number">11</span>/<span class="number">08</span> <span class="number">19</span>:<span class="number">16</span>:<span class="number">57</span> INFO mapreduce<span class="class">.Job</span>: Task Id : attempt_1446657831952_0038_m_000005_0, Status : FAILED</span><br><span class="line">Error: java<span class="class">.lang</span><span class="class">.NullPointerException</span>: Cannot proceed without CQL definition.</span><br><span class="line">    at com<span class="class">.google</span><span class="class">.common</span><span class="class">.base</span><span class="class">.Preconditions</span><span class="class">.checkNotNull</span>(Preconditions<span class="class">.java</span>:<span class="number">229</span>)</span><br><span class="line">    at com<span class="class">.fullcontact</span><span class="class">.sstable</span><span class="class">.hadoop</span><span class="class">.mapreduce</span><span class="class">.SSTableRecordReader</span><span class="class">.initializeCfMetaData</span>(SSTableRecordReader<span class="class">.java</span>:<span class="number">142</span>)</span><br><span class="line">    at com<span class="class">.fullcontact</span><span class="class">.sstable</span><span class="class">.hadoop</span><span class="class">.mapreduce</span><span class="class">.SSTableRecordReader</span><span class="class">.initialize</span>(SSTableRecordReader<span class="class">.java</span>:<span class="number">79</span>)</span><br><span class="line">    at org<span class="class">.apache</span><span class="class">.hadoop</span><span class="class">.mapred</span><span class="class">.MapTask</span><span class="variable">$NewTrackingRecordReader</span>.<span class="function"><span class="title">initialize</span><span class="params">(MapTask.java:<span class="number">525</span>)</span></span></span><br><span class="line">    at org<span class="class">.apache</span><span class="class">.hadoop</span><span class="class">.mapred</span><span class="class">.MapTask</span><span class="class">.runNewMapper</span>(MapTask<span class="class">.java</span>:<span class="number">763</span>)</span><br><span class="line">    at org<span class="class">.apache</span><span class="class">.hadoop</span><span class="class">.mapred</span><span class="class">.MapTask</span><span class="class">.run</span>(MapTask<span class="class">.java</span>:<span class="number">340</span>)</span><br><span class="line">    at org<span class="class">.apache</span><span class="class">.hadoop</span><span class="class">.mapred</span><span class="class">.YarnChild</span>$<span class="number">2</span>.<span class="function"><span class="title">run</span><span class="params">(YarnChild.java:<span class="number">167</span>)</span></span></span><br><span class="line">    at java<span class="class">.security</span><span class="class">.AccessController</span><span class="class">.doPrivileged</span>(Native Method)</span><br><span class="line">    at javax<span class="class">.security</span><span class="class">.auth</span><span class="class">.Subject</span><span class="class">.doAs</span>(Subject<span class="class">.java</span>:<span class="number">415</span>)</span><br><span class="line">    at org<span class="class">.apache</span><span class="class">.hadoop</span><span class="class">.security</span><span class="class">.UserGroupInformation</span><span class="class">.doAs</span>(UserGroupInformation<span class="class">.java</span>:<span class="number">1556</span>)</span><br><span class="line">    at org<span class="class">.apache</span><span class="class">.hadoop</span><span class="class">.mapred</span><span class="class">.YarnChild</span><span class="class">.main</span>(YarnChild<span class="class">.java</span>:<span class="number">162</span>)</span><br></pre></td></tr></table></figure>
<p>解决guava的版本冲突问题参考这里: 优先使用用户定义的, 否则尽管把16的guava打进hadoop-sstable,也不会被优先加载.<br><a href="http://stackoverflow.com/questions/27089126/nosuchmethoderror-sets-newconcurrenthashset-while-running-jar-using-hadoop" target="_blank" rel="external">http://stackoverflow.com/questions/27089126/nosuchmethoderror-sets-newconcurrenthashset-while-running-jar-using-hadoop</a>  </p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> HADOOP_USER_CLASSPATH_FIRST=<span class="literal">true</span></span><br><span class="line"></span><br><span class="line">/usr/install/hadoop/bin/hadoop jar hadoop-sstable-<span class="number">2.0</span>.<span class="number">0</span>.jar com.fullcontact.sstable.example.SimpleExample \</span><br><span class="line">    -libjars guava-<span class="number">16.0</span>.<span class="number">1</span>.jar \</span><br><span class="line">    -D hadoop.sstable.cql=<span class="string">"CREATE TABLE velocity (attribute text,partner_code text,app_name text,type text,\"timestamp\" bigint,event text,sequence_id text,PRIMARY KEY ((attribute), partner_code, app_name, type, \"timestamp\")) WITH compression=&#123;'sstable_compression': 'LZ4Compressor'&#125;"</span> \</span><br><span class="line">    -D mapred.task.timeout=<span class="number">21600000</span> \</span><br><span class="line">    -D mapred.map.tasks.speculative.execution=<span class="literal">false</span> \</span><br><span class="line">    -D mapred.job.reuse.jvm.num.tasks=<span class="number">1</span> \</span><br><span class="line">    -D io.sort.mb=<span class="number">1000</span> \</span><br><span class="line">    -D io.sort.factor=<span class="number">100</span> \</span><br><span class="line">    -D mapred.reduce.tasks=<span class="number">512</span> \</span><br><span class="line">    -D hadoop.sstable.split.mb=<span class="number">1024</span> \</span><br><span class="line">    -D mapred.child.java.opts=<span class="string">"-Xmx2G -XX:MaxPermSize=512m"</span> \</span><br><span class="line">    -D hadoop.sstable.keyspace=<span class="string">"forseti"</span> \</span><br><span class="line">    -D hadoop.sstable.column.family.name=<span class="string">"velocity"</span> \</span><br><span class="line">    -D mapreduce.job.user.classpath.first=<span class="literal">true</span> \</span><br><span class="line">    /user/qihuang.zheng/velocity_backup_1107/<span class="number">226</span>_1105/<span class="number">10</span>/forseti/velocity /user/qihuang.zheng/velocity_<span class="built_in">test</span>20</span><br></pre></td></tr></table></figure>
<blockquote>
<p>关于依赖包:<a href="http://www.solveitinjava.com/2015/05/bulkload-to-cassandra-with-hadoop.html" target="_blank" rel="external">http://www.solveitinjava.com/2015/05/bulkload-to-cassandra-with-hadoop.html</a> 在hadoop中要exclude掉guava.  </p>
</blockquote>
<h3 id="JSON解析异常">JSON解析异常</h3><p>终于换了另外一个错误! getJson解析出错.   </p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">15</span>/<span class="number">11</span>/<span class="number">08</span> <span class="number">19</span>:<span class="number">13</span>:<span class="number">50</span> INFO mapreduce<span class="class">.Job</span>: Task Id : attempt_1446657831952_0037_m_000005_0, Status : FAILED</span><br><span class="line">Error: java<span class="class">.lang</span><span class="class">.NullPointerException</span></span><br><span class="line">    at com<span class="class">.fullcontact</span><span class="class">.sstable</span><span class="class">.example</span><span class="class">.JsonColumnParser</span><span class="class">.getColumnValueConvertor</span>(JsonColumnParser<span class="class">.java</span>:<span class="number">55</span>)</span><br><span class="line">    at com<span class="class">.fullcontact</span><span class="class">.sstable</span><span class="class">.example</span><span class="class">.JsonColumnParser</span><span class="class">.serializeColumns</span>(JsonColumnParser<span class="class">.java</span>:<span class="number">87</span>)</span><br><span class="line">    at com<span class="class">.fullcontact</span><span class="class">.sstable</span><span class="class">.example</span><span class="class">.JsonColumnParser</span><span class="class">.getJson</span>(JsonColumnParser<span class="class">.java</span>:<span class="number">37</span>)</span><br><span class="line">    at com<span class="class">.fullcontact</span><span class="class">.sstable</span><span class="class">.example</span><span class="class">.SimpleExampleMapper</span><span class="class">.map</span>(SimpleExampleMapper<span class="class">.java</span>:<span class="number">57</span>)</span><br><span class="line">    at com<span class="class">.fullcontact</span><span class="class">.sstable</span><span class="class">.example</span><span class="class">.SimpleExampleMapper</span><span class="class">.map</span>(SimpleExampleMapper<span class="class">.java</span>:<span class="number">21</span>)</span><br><span class="line">    at org<span class="class">.apache</span><span class="class">.hadoop</span><span class="class">.mapreduce</span><span class="class">.Mapper</span><span class="class">.run</span>(Mapper<span class="class">.java</span>:<span class="number">145</span>)</span><br><span class="line">    at org<span class="class">.apache</span><span class="class">.hadoop</span><span class="class">.mapred</span><span class="class">.MapTask</span><span class="class">.runNewMapper</span>(MapTask<span class="class">.java</span>:<span class="number">764</span>)</span><br><span class="line">    at org<span class="class">.apache</span><span class="class">.hadoop</span><span class="class">.mapred</span><span class="class">.MapTask</span><span class="class">.run</span>(MapTask<span class="class">.java</span>:<span class="number">340</span>)</span><br><span class="line">    at org<span class="class">.apache</span><span class="class">.hadoop</span><span class="class">.mapred</span><span class="class">.YarnChild</span>$<span class="number">2</span>.<span class="function"><span class="title">run</span><span class="params">(YarnChild.java:<span class="number">167</span>)</span></span></span><br><span class="line">    at java<span class="class">.security</span><span class="class">.AccessController</span><span class="class">.doPrivileged</span>(Native Method)</span><br><span class="line">    at javax<span class="class">.security</span><span class="class">.auth</span><span class="class">.Subject</span><span class="class">.doAs</span>(Subject<span class="class">.java</span>:<span class="number">415</span>)</span><br><span class="line">    at org<span class="class">.apache</span><span class="class">.hadoop</span><span class="class">.security</span><span class="class">.UserGroupInformation</span><span class="class">.doAs</span>(UserGroupInformation<span class="class">.java</span>:<span class="number">1556</span>)</span><br><span class="line">    at org<span class="class">.apache</span><span class="class">.hadoop</span><span class="class">.mapred</span><span class="class">.YarnChild</span><span class="class">.main</span>(YarnChild<span class="class">.java</span>:<span class="number">162</span>)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>空指针的异常是因为SQL里面有引号吗? 将\”timestamp\”换成”timestamp”还是一样的错误. 或者直接把双引号去掉也不行.    </p>
</blockquote>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">/usr/install/hadoop/bin/hadoop jar hadoop-sstable-<span class="number">2.0</span>.<span class="number">0</span><span class="class">.jar</span> com<span class="class">.fullcontact</span><span class="class">.sstable</span><span class="class">.example</span><span class="class">.SimpleExample</span> \</span><br><span class="line">    -libjars guava-<span class="number">16.0</span>.<span class="number">1</span><span class="class">.jar</span> \</span><br><span class="line">    -D hadoop<span class="class">.sstable</span><span class="class">.cql</span>=<span class="string">"CREATE TABLE velocity (attribute text,partner_code text,app_name text,type text,&amp;timestamp&amp; bigint,event text,sequence_id text,PRIMARY KEY ((attribute), partner_code, app_name, type, &amp;timestamp&amp;)) WITH compression=&#123;'sstable_compression': 'LZ4Compressor'&#125;"</span> \</span><br><span class="line">    -D mapred<span class="class">.task</span><span class="class">.timeout</span>=<span class="number">21600000</span> \</span><br><span class="line">    -D mapred<span class="class">.map</span><span class="class">.tasks</span><span class="class">.speculative</span><span class="class">.execution</span>=false \</span><br><span class="line">    -D mapred<span class="class">.job</span><span class="class">.reuse</span><span class="class">.jvm</span><span class="class">.num</span><span class="class">.tasks</span>=<span class="number">1</span> \</span><br><span class="line">    -D io<span class="class">.sort</span><span class="class">.mb</span>=<span class="number">1000</span> \</span><br><span class="line">    -D io<span class="class">.sort</span><span class="class">.factor</span>=<span class="number">100</span> \</span><br><span class="line">    -D mapred<span class="class">.reduce</span><span class="class">.tasks</span>=<span class="number">512</span> \</span><br><span class="line">    -D hadoop<span class="class">.sstable</span><span class="class">.split</span><span class="class">.mb</span>=<span class="number">1024</span> \</span><br><span class="line">    -D mapred<span class="class">.child</span><span class="class">.java</span><span class="class">.opts</span>=<span class="string">"-Xmx2G -XX:MaxPermSize=512m"</span> \</span><br><span class="line">    -D hadoop<span class="class">.sstable</span><span class="class">.keyspace</span>=<span class="string">"forseti"</span> \</span><br><span class="line">    -D hadoop<span class="class">.sstable</span><span class="class">.column</span><span class="class">.family</span><span class="class">.name</span>=<span class="string">"velocity"</span> \</span><br><span class="line">    -D mapreduce<span class="class">.job</span><span class="class">.user</span><span class="class">.classpath</span><span class="class">.first</span>=true \</span><br><span class="line">    /user/qihuang.zheng/velocity_backup_1107/<span class="number">226</span>_1105/<span class="number">10</span>/forseti/velocity /user/qihuang.zheng/velocity_test03</span><br></pre></td></tr></table></figure>
<p>用到CQL的地方还有SSTableRecordReader, 一并转换.  </p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">15</span>/<span class="number">11</span>/<span class="number">09</span> <span class="number">08</span>:<span class="number">13</span>:<span class="number">52</span> INFO mapreduce<span class="class">.Job</span>: Task Id : attempt_1446983986550_0001_m_000005_1, Status : FAILED</span><br><span class="line">Error: java<span class="class">.lang</span><span class="class">.RuntimeException</span>: Error configuring SSTable reader. Cannot proceed</span><br><span class="line">    at com<span class="class">.fullcontact</span><span class="class">.sstable</span><span class="class">.hadoop</span><span class="class">.mapreduce</span><span class="class">.SSTableRecordReader</span><span class="class">.getCreateTableStatement</span>(SSTableRecordReader<span class="class">.java</span>:<span class="number">166</span>)</span><br><span class="line">    at com<span class="class">.fullcontact</span><span class="class">.sstable</span><span class="class">.hadoop</span><span class="class">.mapreduce</span><span class="class">.SSTableRecordReader</span><span class="class">.initializeCfMetaData</span>(SSTableRecordReader<span class="class">.java</span>:<span class="number">144</span>)</span><br><span class="line">    at com<span class="class">.fullcontact</span><span class="class">.sstable</span><span class="class">.hadoop</span><span class="class">.mapreduce</span><span class="class">.SSTableRecordReader</span><span class="class">.initialize</span>(SSTableRecordReader<span class="class">.java</span>:<span class="number">79</span>)</span><br><span class="line">    at org<span class="class">.apache</span><span class="class">.hadoop</span><span class="class">.mapred</span><span class="class">.MapTask</span><span class="variable">$NewTrackingRecordReader</span>.<span class="function"><span class="title">initialize</span><span class="params">(MapTask.java:<span class="number">525</span>)</span></span></span><br><span class="line">    at org<span class="class">.apache</span><span class="class">.hadoop</span><span class="class">.mapred</span><span class="class">.MapTask</span><span class="class">.runNewMapper</span>(MapTask<span class="class">.java</span>:<span class="number">763</span>)</span><br><span class="line">    at org<span class="class">.apache</span><span class="class">.hadoop</span><span class="class">.mapred</span><span class="class">.MapTask</span><span class="class">.run</span>(MapTask<span class="class">.java</span>:<span class="number">340</span>)</span><br><span class="line">    at org<span class="class">.apache</span><span class="class">.hadoop</span><span class="class">.mapred</span><span class="class">.YarnChild</span>$<span class="number">2</span>.<span class="function"><span class="title">run</span><span class="params">(YarnChild.java:<span class="number">167</span>)</span></span></span><br><span class="line">    at java<span class="class">.security</span><span class="class">.AccessController</span><span class="class">.doPrivileged</span>(Native Method)</span><br><span class="line">    at javax<span class="class">.security</span><span class="class">.auth</span><span class="class">.Subject</span><span class="class">.doAs</span>(Subject<span class="class">.java</span>:<span class="number">415</span>)</span><br><span class="line">    at org<span class="class">.apache</span><span class="class">.hadoop</span><span class="class">.security</span><span class="class">.UserGroupInformation</span><span class="class">.doAs</span>(UserGroupInformation<span class="class">.java</span>:<span class="number">1556</span>)</span><br><span class="line">    at org<span class="class">.apache</span><span class="class">.hadoop</span><span class="class">.mapred</span><span class="class">.YarnChild</span><span class="class">.main</span>(YarnChild<span class="class">.java</span>:<span class="number">162</span>)</span><br><span class="line">Caused by: org<span class="class">.apache</span><span class="class">.cassandra</span><span class="class">.exceptions</span><span class="class">.SyntaxException</span>: line <span class="number">1</span>:<span class="number">193</span> no viable alternative at character <span class="string">'&amp;'</span></span><br><span class="line">    at org<span class="class">.apache</span><span class="class">.cassandra</span><span class="class">.cql3</span><span class="class">.CqlLexer</span><span class="class">.throwLastRecognitionError</span>(CqlLexer<span class="class">.java</span>:<span class="number">199</span>)</span><br><span class="line">    at org<span class="class">.apache</span><span class="class">.cassandra</span><span class="class">.cql3</span><span class="class">.QueryProcessor</span><span class="class">.parseStatement</span>(QueryProcessor<span class="class">.java</span>:<span class="number">351</span>)</span><br><span class="line">    at com<span class="class">.fullcontact</span><span class="class">.sstable</span><span class="class">.hadoop</span><span class="class">.mapreduce</span><span class="class">.SSTableRecordReader</span><span class="class">.getCreateTableStatement</span>(SSTableRecordReader<span class="class">.java</span>:<span class="number">163</span>)</span><br></pre></td></tr></table></figure>
<h3 id="添加Mapper的日志和查看Map日志">添加Mapper的日志和查看Map日志</h3><p>container_1446983986550_0006_01_000001是ApplicationMaster的日志, 即控制台上看到的日志.<br>而Map/ReduceTask的日志是其他编号结尾的, 比如: container_1446983986550_0006_01_000002.<br>如果你在控制台上或者ApplicationMaster是看不到MapperTask中的日志的!   </p>
<blockquote>
<p>Container日志包含ApplicationMaster日志和普通Task日志，其中ApplicationMaster日志目录名称为container_xxx_000001，普通task日志目录名称则为container_xxx_000002，container_xxx_000003，….</p>
</blockquote>
<figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">09</span> <span class="number">09</span>:<span class="number">14</span>:<span class="number">29</span>,<span class="number">331</span> ERROR [main] org.apache.cassandra.cql3.<span class="string">QueryProcessor:</span> Unable to initialize MemoryMeter (jamm not specified <span class="keyword">as</span> javaagent).  This means Cassandra will be unable to measure object sizes accurately and may consequently OOM.</span><br><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">09</span> <span class="number">09</span>:<span class="number">14</span>:<span class="number">30</span>,<span class="number">805</span> INFO [main] com.fullcontact.sstable.example.<span class="string">SimpleExampleMapper:</span> <span class="string">CFMetaData:</span> org.apache.cassandra.config.CFMetaData@<span class="number">767</span>d75b3[cfId=e2d9ce2b-b493-<span class="number">35</span>bd-<span class="number">9</span>f24-<span class="number">4</span>df1fee8237d,ksName=forseti,cfName=velocity,cfType=Standard,comparator=org.apache.cassandra.db.marshal.CompositeType(org.apache.cassandra.db.marshal.UTF8Type,org.apache.cassandra.db.marshal.UTF8Type,org.apache.cassandra.db.marshal.UTF8Type,org.apache.cassandra.db.marshal.LongType,org.apache.cassandra.db.marshal.UTF8Type),comment=,readRepairChance=<span class="number">0.0</span>,dclocalReadRepairChance=<span class="number">0.1</span>,replicateOnWrite=<span class="literal">true</span>,gcGraceSeconds=<span class="number">864000</span>,defaultValidator=org.apache.cassandra.db.marshal.BytesType,keyValidator=org.apache.cassandra.db.marshal.UTF8Type,minCompactionThreshold=<span class="number">4</span>,maxCompactionThreshold=<span class="number">32</span>,column_metadata=&#123;java.nio.HeapByteBuffer[pos=<span class="number">0</span> lim=<span class="number">8</span> cap=<span class="number">8</span>]=ColumnDefinition&#123;name=<span class="number">6170705</span>f6e616d65, validator=org.apache.cassandra.db.marshal.UTF8Type, type=CLUSTERING_KEY, componentIndex=<span class="number">1</span>, indexName=<span class="literal">null</span>, indexType=<span class="literal">null</span>&#125;, java.nio.HeapByteBuffer[pos=<span class="number">0</span> lim=<span class="number">9</span> cap=<span class="number">9</span>]=ColumnDefinition&#123;name=<span class="number">617474726962757465</span>, validator=org.apache.cassandra.db.marshal.UTF8Type, type=PARTITION_KEY, componentIndex=<span class="literal">null</span>, indexName=<span class="literal">null</span>, indexType=<span class="literal">null</span>&#125;, java.nio.HeapByteBuffer[pos=<span class="number">0</span> lim=<span class="number">4</span> cap=<span class="number">4</span>]=ColumnDefinition&#123;name=<span class="number">74797065</span>, validator=org.apache.cassandra.db.marshal.UTF8Type, type=CLUSTERING_KEY, componentIndex=<span class="number">2</span>, indexName=<span class="literal">null</span>, indexType=<span class="literal">null</span>&#125;, java.nio.HeapByteBuffer[pos=<span class="number">0</span> lim=<span class="number">12</span> cap=<span class="number">12</span>]=ColumnDefinition&#123;name=<span class="number">706172746e65725</span>f636f6465, validator=org.apache.cassandra.db.marshal.UTF8Type, type=CLUSTERING_KEY, componentIndex=<span class="number">0</span>, indexName=<span class="literal">null</span>, indexType=<span class="literal">null</span>&#125;, java.nio.HeapByteBuffer[pos=<span class="number">0</span> lim=<span class="number">11</span> cap=<span class="number">11</span>]=ColumnDefinition&#123;name=<span class="number">73657175656e63655</span>f6964, validator=org.apache.cassandra.db.marshal.UTF8Type, type=REGULAR, componentIndex=<span class="number">4</span>, indexName=<span class="literal">null</span>, indexType=<span class="literal">null</span>&#125;, java.nio.HeapByteBuffer[pos=<span class="number">0</span> lim=<span class="number">9</span> cap=<span class="number">9</span>]=ColumnDefinition&#123;name=<span class="number">74696</span>d657374616d70, validator=org.apache.cassandra.db.marshal.LongType, type=CLUSTERING_KEY, componentIndex=<span class="number">3</span>, indexName=<span class="literal">null</span>, indexType=<span class="literal">null</span>&#125;, java.nio.HeapByteBuffer[pos=<span class="number">0</span> lim=<span class="number">5</span> cap=<span class="number">5</span>]=ColumnDefinition&#123;name=<span class="number">6576656e74</span>, validator=org.apache.cassandra.db.marshal.UTF8Type, type=REGULAR, componentIndex=<span class="number">4</span>, indexName=<span class="literal">null</span>, indexType=<span class="literal">null</span>&#125;&#125;,compactionStrategyClass=<span class="class"><span class="keyword">class</span> <span class="title">org</span>.<span class="title">apache</span>.<span class="title">cassandra</span>.<span class="title">db</span>.<span class="title">compaction</span>.<span class="title">SizeTieredCompactionStrategy</span>,<span class="title">compactionStrategyOptions</span>=&#123;</span>&#125;,compressionOptions=&#123;sstable_compression=org.apache.cassandra.io.compress.LZ4Compressor&#125;,bloomFilterFpChance=<span class="number">0.01</span>,memtable_flush_period_in_ms=<span class="number">0</span>,caching=KEYS_ONLY,defaultTimeToLive=<span class="number">0</span>,speculative_retry=<span class="number">99.0</span>PERCENTILE,indexInterval=<span class="number">128</span>,populateIoCacheOnFlush=<span class="literal">false</span>,droppedColumns=&#123;&#125;,triggers=&#123;&#125;,isDense=<span class="literal">false</span>]</span><br><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">09</span> <span class="number">09</span>:<span class="number">14</span>:<span class="number">31</span>,<span class="number">340</span> INFO [main] com.fullcontact.sstable.example.<span class="string">JsonColumnParser:</span> <span class="string">columnName:</span><span class="string">fenqile:</span><span class="string">fenqile_web:</span><span class="string">smartId:</span><span class="number">1111111111111</span>:,<span class="string">colId:</span><span class="string">fenqile:</span><span class="string">fenqile_web:</span><span class="string">smartid:</span><span class="number">1111111111111</span>:,<span class="string">cfd:</span><span class="literal">null</span></span><br><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">09</span> <span class="number">09</span>:<span class="number">14</span>:<span class="number">31</span>,<span class="number">341</span> INFO [main] org.apache.hadoop.mapred.<span class="string">MapTask:</span> Starting flush of map output</span><br><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">09</span> <span class="number">09</span>:<span class="number">14</span>:<span class="number">31</span>,<span class="number">715</span> WARN [main] org.apache.hadoop.mapred.<span class="string">YarnChild:</span> Exception running <span class="string">child :</span> java.lang.NullPointerException</span><br><span class="line">        at com.fullcontact.sstable.example.JsonColumnParser.getColumnValueConvertor(JsonColumnParser.<span class="string">java:</span><span class="number">61</span>)</span><br><span class="line">        at com.fullcontact.sstable.example.JsonColumnParser.serializeColumns(JsonColumnParser.<span class="string">java:</span><span class="number">93</span>)</span><br><span class="line">        at com.fullcontact.sstable.example.JsonColumnParser.getJson(JsonColumnParser.<span class="string">java:</span><span class="number">40</span>)</span><br><span class="line">        at com.fullcontact.sstable.example.SimpleExampleMapper.map(SimpleExampleMapper.<span class="string">java:</span><span class="number">86</span>)</span><br><span class="line">        at com.fullcontact.sstable.example.SimpleExampleMapper.map(SimpleExampleMapper.<span class="string">java:</span><span class="number">22</span>)</span><br><span class="line">        at org.apache.hadoop.mapreduce.Mapper.run(Mapper.<span class="string">java:</span><span class="number">145</span>)</span><br><span class="line">        at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.<span class="string">java:</span><span class="number">764</span>)</span><br><span class="line">        at org.apache.hadoop.mapred.MapTask.run(MapTask.<span class="string">java:</span><span class="number">340</span>)</span><br><span class="line">        at org.apache.hadoop.mapred.YarnChild$<span class="number">2.</span>run(YarnChild.<span class="string">java:</span><span class="number">167</span>)</span><br><span class="line">        at java.security.AccessController.doPrivileged(Native Method)</span><br><span class="line">        at javax.security.auth.Subject.doAs(Subject.<span class="string">java:</span><span class="number">415</span>)</span><br><span class="line">        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.<span class="string">java:</span><span class="number">1556</span>)</span><br><span class="line">        at org.apache.hadoop.mapred.YarnChild.main(YarnChild.<span class="string">java:</span><span class="number">162</span>)</span><br></pre></td></tr></table></figure>
<p>我们在两个地方添加了日志, 一是SimpleExampleMapper: <code>LOG.info(&quot;CFMetaData: {}&quot;, cfm);</code><br>二是JsonColumnParser.getColumnValueConvertor: <code>LOG.info(&quot;columnName:&quot; +columnName + &quot;,colId:&quot; + colId + &quot;,cfd:&quot; + cfd);</code><br>上面第一个日志是正常的, 第二个日志中cfd为null.  </p>
<figure class="highlight fsharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line">PRIMARY KEY ((attribute), partner_code, app_name, <span class="class"><span class="keyword">type</span>, &amp;<span class="title">timestamp</span>&amp;))</span></span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">  java.nio.HeapByteBuffer[</span><br><span class="line">    pos=<span class="number">0</span>lim=<span class="number">8</span>cap=<span class="number">8</span></span><br><span class="line">  ]=ColumnDefinition&#123;</span><br><span class="line">    name=<span class="number">6170705</span>f6e616d65,</span><br><span class="line">    validator=org.apache.cassandra.db.marshal.UTF8Type,</span><br><span class="line">    <span class="class"><span class="keyword">type</span></span>=CLUSTERING_KEY,</span><br><span class="line">    componentIndex=<span class="number">1</span>,           第<span class="number">2</span>个排序键, app_name</span><br><span class="line">  &#125;,</span><br><span class="line">  java.nio.HeapByteBuffer[</span><br><span class="line">    pos=<span class="number">0</span>lim=<span class="number">9</span>cap=<span class="number">9</span></span><br><span class="line">  ]=ColumnDefinition&#123;</span><br><span class="line">    name=<span class="number">617474726962757465</span>,</span><br><span class="line">    validator=org.apache.cassandra.db.marshal.UTF8Type,</span><br><span class="line">    <span class="class"><span class="keyword">type</span></span>=PARTITION_KEY,         这个是attribute. 因为只有它是分区键</span><br><span class="line">    componentIndex=<span class="keyword">null</span>,</span><br><span class="line">  &#125;,</span><br><span class="line">  java.nio.HeapByteBuffer[</span><br><span class="line">    pos=<span class="number">0</span>lim=<span class="number">4</span>cap=<span class="number">4</span></span><br><span class="line">  ]=ColumnDefinition&#123;</span><br><span class="line">    name=<span class="number">74797065</span>,</span><br><span class="line">    validator=org.apache.cassandra.db.marshal.UTF8Type,</span><br><span class="line">    <span class="class"><span class="keyword">type</span></span>=CLUSTERING_KEY,</span><br><span class="line">    componentIndex=<span class="number">2</span>,           第三个排序键, <span class="class"><span class="keyword">type</span></span></span><br><span class="line">  &#125;,</span><br><span class="line">  java.nio.HeapByteBuffer[</span><br><span class="line">    pos=<span class="number">0</span>lim=<span class="number">12</span>cap=<span class="number">12</span></span><br><span class="line">  ]=ColumnDefinition&#123;</span><br><span class="line">    name=<span class="number">706172746e65725</span>f636f6465,</span><br><span class="line">    validator=org.apache.cassandra.db.marshal.UTF8Type,</span><br><span class="line">    <span class="class"><span class="keyword">type</span></span>=CLUSTERING_KEY,</span><br><span class="line">    componentIndex=<span class="number">0</span>,           第一个排序键, partner_code</span><br><span class="line">  &#125;,</span><br><span class="line">  java.nio.HeapByteBuffer[</span><br><span class="line">    pos=<span class="number">0</span>lim=<span class="number">11</span>cap=<span class="number">11</span></span><br><span class="line">  ]=ColumnDefinition&#123;</span><br><span class="line">    name=<span class="number">73657175656e63655</span>f6964,</span><br><span class="line">    validator=org.apache.cassandra.db.marshal.UTF8Type,</span><br><span class="line">    <span class="class"><span class="keyword">type</span></span>=REGULAR,</span><br><span class="line">    componentIndex=<span class="number">4</span>,           正常的键, event</span><br><span class="line">  &#125;,</span><br><span class="line">  java.nio.HeapByteBuffer[</span><br><span class="line">    pos=<span class="number">0</span>lim=<span class="number">9</span>cap=<span class="number">9</span></span><br><span class="line">  ]=ColumnDefinition&#123;</span><br><span class="line">    name=<span class="number">74696</span>d657374616d70,</span><br><span class="line">    validator=org.apache.cassandra.db.marshal.LongType,</span><br><span class="line">    <span class="class"><span class="keyword">type</span></span>=CLUSTERING_KEY,</span><br><span class="line">    componentIndex=<span class="number">3</span>,           第四个排序键: timestamp</span><br><span class="line">  &#125;,</span><br><span class="line">  java.nio.HeapByteBuffer[</span><br><span class="line">    pos=<span class="number">0</span>lim=<span class="number">5</span>cap=<span class="number">5</span></span><br><span class="line">  ]=ColumnDefinition&#123;</span><br><span class="line">    name=<span class="number">6576656e74</span>,</span><br><span class="line">    validator=org.apache.cassandra.db.marshal.UTF8Type,</span><br><span class="line">    <span class="class"><span class="keyword">type</span></span>=REGULAR,</span><br><span class="line">    componentIndex=<span class="number">4</span>,           正常的键: sequence_id</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>对应的系统schema信息:  </p>
<figure class="highlight gherkin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">SELECT comparator,subcomparator,type,key_validator FROM system.schema_columnfamilies WHERE keyspace_name = 'forseti' AND columnfamily_name = 'velocity';</span><br><span class="line">org.apache.cassandra.db.marshal.CompositeType(org.apache.cassandra.db.marshal.UTF8Type,org.apache.cassandra.db.marshal.UTF8Type,org.apache.cassandra.db.marshal.UTF8Type,org.apache.cassandra.db.marshal.LongType,org.apache.cassandra.db.marshal.UTF8Type) |<span class="string">          null </span>|<span class="string"> Standard </span>|<span class="string"> org.apache.cassandra.db.marshal.UTF8Type</span><br><span class="line"></span><br><span class="line">cqlsh:system&gt; select * from system.schema_columns where keyspace_name='forseti' and columnfamily_name='velocity';</span><br><span class="line"> keyspace_name </span>|<span class="string"> columnfamily_name </span>|<span class="string"> column_name  </span>|<span class="string"> component_index </span>|<span class="string"> index_name </span>|<span class="string"> index_options </span>|<span class="string"> index_type </span>|<span class="string"> type           </span>|<span class="string"> validator</span><br><span class="line">---------------+-------------------+--------------+-----------------+------------+---------------+------------+----------------+------------------------------------------</span><br><span class="line">       forseti </span>|<span class="string">          velocity </span>|<span class="string">     app_name </span>|<span class="string">               1 </span>|<span class="string">       null </span>|<span class="string">          null </span>|<span class="string">       null </span>|<span class="string"> clustering_key </span>|<span class="string"> org.apache.cassandra.db.marshal.UTF8Type</span><br><span class="line">       forseti </span>|<span class="string">          velocity </span>|<span class="string">    attribute </span>|<span class="string">            null </span>|<span class="string">       null </span>|<span class="string">          null </span>|<span class="string">       null </span>|<span class="string">  partition_key </span>|<span class="string"> org.apache.cassandra.db.marshal.UTF8Type</span><br><span class="line">       forseti </span>|<span class="string">          velocity </span>|<span class="string">        event </span>|<span class="string">               4 </span>|<span class="string">       null </span>|<span class="string">          null </span>|<span class="string">       null </span>|<span class="string">        regular </span>|<span class="string"> org.apache.cassandra.db.marshal.UTF8Type</span><br><span class="line">       forseti </span>|<span class="string">          velocity </span>|<span class="string"> partner_code </span>|<span class="string">               0 </span>|<span class="string">       null </span>|<span class="string">          null </span>|<span class="string">       null </span>|<span class="string"> clustering_key </span>|<span class="string"> org.apache.cassandra.db.marshal.UTF8Type</span><br><span class="line">       forseti </span>|<span class="string">          velocity </span>|<span class="string">  sequence_id </span>|<span class="string">               4 </span>|<span class="string">       null </span>|<span class="string">          null </span>|<span class="string">       null </span>|<span class="string">        regular </span>|<span class="string"> org.apache.cassandra.db.marshal.UTF8Type</span><br><span class="line">       forseti </span>|<span class="string">          velocity </span>|<span class="string">    timestamp </span>|<span class="string">               3 </span>|<span class="string">       null </span>|<span class="string">          null </span>|<span class="string">       null </span>|<span class="string"> clustering_key </span>|<span class="string"> org.apache.cassandra.db.marshal.LongType</span><br><span class="line">       forseti </span>|<span class="string">          velocity </span>|<span class="string">         type </span>|<span class="string">               2 </span>|<span class="string">       null </span>|<span class="string">          null </span>|<span class="string">       null </span>|<span class="string"> clustering_key </span>|<span class="string"> org.apache.cassandra.db.marshal.UTF8Type</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>CompositeType(UTF8Type,UTF8Type,UTF8Type,LongType,UTF8Type)有五个字段:分别对应了attribute,partner_code,app_name,type,timestamp<br>包含了partition key, 但是似乎顺序没有对应上, 倒数第二个是LongType,而timestamp是Long类型,在最后一个字段.  </p>
</blockquote>
<p>给CQL加上完整的所有信息, cql最后需不需要加分号?(NO)  </p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">/usr/install/hadoop/bin/hadoop jar hadoop-sstable-<span class="number">2.0</span>.<span class="number">0</span><span class="class">.jar</span> com<span class="class">.fullcontact</span><span class="class">.sstable</span><span class="class">.example</span><span class="class">.SimpleExample</span> \</span><br><span class="line">    -libjars guava-<span class="number">16.0</span>.<span class="number">1</span><span class="class">.jar</span> \</span><br><span class="line">    -D hadoop<span class="class">.sstable</span><span class="class">.cql</span>=<span class="string">"CREATE TABLE velocity (attribute text,partner_code text,app_name text,type text,&amp;timestamp&amp; bigint,event text,sequence_id text,PRIMARY KEY ((attribute), partner_code, app_name, type, &amp;timestamp&amp;)) WITH bloom_filter_fp_chance=0.100000 AND caching='ALL' AND comment='' AND dclocal_read_repair_chance=0.000000 AND gc_grace_seconds=0 AND index_interval=128 AND read_repair_chance=0.100000 AND replicate_on_write='true' AND populate_io_cache_on_flush='false' AND default_time_to_live=0 AND speculative_retry='99.0PERCENTILE' AND memtable_flush_period_in_ms=0 AND compaction=&#123;'unchecked_tombstone_compaction': 'true', 'tombstone_threshold': '0.1', 'class': 'LeveledCompactionStrategy'&#125; AND compression=&#123;'sstable_compression': 'LZ4Compressor'&#125;"</span> \</span><br><span class="line">    -D mapred<span class="class">.task</span><span class="class">.timeout</span>=<span class="number">21600000</span> \</span><br><span class="line">    -D mapred<span class="class">.map</span><span class="class">.tasks</span><span class="class">.speculative</span><span class="class">.execution</span>=false \</span><br><span class="line">    -D mapred<span class="class">.job</span><span class="class">.reuse</span><span class="class">.jvm</span><span class="class">.num</span><span class="class">.tasks</span>=<span class="number">1</span> \</span><br><span class="line">    -D io<span class="class">.sort</span><span class="class">.mb</span>=<span class="number">1000</span> \</span><br><span class="line">    -D io<span class="class">.sort</span><span class="class">.factor</span>=<span class="number">100</span> \</span><br><span class="line">    -D mapred<span class="class">.reduce</span><span class="class">.tasks</span>=<span class="number">512</span> \</span><br><span class="line">    -D hadoop<span class="class">.sstable</span><span class="class">.split</span><span class="class">.mb</span>=<span class="number">1024</span> \</span><br><span class="line">    -D mapred<span class="class">.child</span><span class="class">.java</span><span class="class">.opts</span>=<span class="string">"-Xmx2G -XX:MaxPermSize=512m"</span> \</span><br><span class="line">    -D hadoop<span class="class">.sstable</span><span class="class">.keyspace</span>=<span class="string">"forseti"</span> \</span><br><span class="line">    -D hadoop<span class="class">.sstable</span><span class="class">.column</span><span class="class">.family</span><span class="class">.name</span>=<span class="string">"velocity"</span> \</span><br><span class="line">    -D mapreduce<span class="class">.job</span><span class="class">.user</span><span class="class">.classpath</span><span class="class">.first</span>=true \</span><br><span class="line">    /user/qihuang.zheng/velocity_backup_1107/<span class="number">226</span>_1105/<span class="number">10</span>/forseti/velocity /user/qihuang.zheng/velocity_test02</span><br></pre></td></tr></table></figure>
<h3 id="Cassandra类型的验证">Cassandra类型的验证</h3><p>获取字符串时有问题:  </p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">sb</span><span class="class">.append</span>(<span class="tag">JSONObject</span><span class="class">.escape</span>(<span class="tag">getColumnValueConvertor</span>(<span class="tag">handleCompositeColumnName</span>(<span class="tag">cn</span>), <span class="tag">BytesType</span><span class="class">.instance</span>)<span class="class">.getString</span>(<span class="tag">column</span><span class="class">.value</span>())));</span><br></pre></td></tr></table></figure>
<p>为了方便查看key, 在SimpleExampleMapper.map中添加打印key:  </p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">09</span> <span class="number">14</span>:<span class="number">25</span>:<span class="number">04</span>,<span class="number">733</span> INFO [main] com.fullcontact.sstable.example.SimpleExampleMapper: C* KEY:s_bc91a07f9f66485d867a8499f2678d0d</span><br><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">09</span> <span class="number">14</span>:<span class="number">25</span>:<span class="number">04</span>,<span class="number">737</span> INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of <span class="built_in">map</span> output</span><br><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">09</span> <span class="number">14</span>:<span class="number">25</span>:<span class="number">06</span>,<span class="number">468</span> WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.lang.NullPointerException</span><br><span class="line">    at com.fullcontact.sstable.example.JsonColumnParser.getColumnValueConvertor(JsonColumnParser.java:<span class="number">60</span>)</span><br><span class="line">    at com.fullcontact.sstable.example.JsonColumnParser.serializeColumns(JsonColumnParser.java:<span class="number">77</span>)</span><br><span class="line">    at com.fullcontact.sstable.example.JsonColumnParser.getJson(JsonColumnParser.java:<span class="number">44</span>)</span><br><span class="line">    at com.fullcontact.sstable.example.SimpleExampleMapper.<span class="built_in">map</span>(SimpleExampleMapper.java:<span class="number">89</span>)</span><br><span class="line">    at com.fullcontact.sstable.example.SimpleExampleMapper.<span class="built_in">map</span>(SimpleExampleMapper.java:<span class="number">22</span>)</span><br><span class="line">    at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:<span class="number">145</span>)</span><br><span class="line">    at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:<span class="number">764</span>)</span><br><span class="line">    at org.apache.hadoop.mapred.MapTask.run(MapTask.java:<span class="number">340</span>)</span><br><span class="line">    at org.apache.hadoop.mapred.YarnChild$<span class="number">2.</span>run(YarnChild.java:<span class="number">167</span>)</span><br><span class="line">    at java.security.AccessController.doPrivileged(Native Method)</span><br><span class="line">    at javax.security.auth.Subject.doAs(Subject.java:<span class="number">415</span>)</span><br><span class="line">    at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:<span class="number">1556</span>)</span><br><span class="line">    at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:<span class="number">162</span>)</span><br></pre></td></tr></table></figure>
<p>更改为UTF8Type</p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">sb</span><span class="class">.append</span>(<span class="tag">JSONObject</span><span class="class">.escape</span>(<span class="tag">getColumnValueConvertor</span>(<span class="tag">handleCompositeColumnName</span>(<span class="tag">cn</span>), <span class="tag">UTF8Type</span><span class="class">.instance</span>)<span class="class">.getString</span>(<span class="tag">column</span><span class="class">.value</span>())));</span><br></pre></td></tr></table></figure>
<p>一条记录的columnName是partition-key对应的column, 而column在DataModel中是不包括partition key的, 只有cluster key的值+regular column的名字.<br>比如cluster_key=(partner_code, app_name, type, sequence_id)=(fenqile:fenqile_web:smartId:1111111111111), regular column有两列:event,sequence_id,<br>所以column Name有fenqile:fenqile_web:smartId:1111111111111:event和fenqile:fenqile_web:smartId:sequence_id两列.  </p>
<figure class="highlight dns"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2015-11-09</span> <span class="number">10:43:56,96</span>8 INFO [main] com.fullcontact.sstable.example.JsonColumnParser: CFDefinition:attribute, partner_code, app_name, type, timestamp =&gt; &#123;event, sequence_id&#125;</span><br><span class="line"></span><br><span class="line"><span class="number">2015-11-09</span> <span class="number">10:43:56,99</span>2 INFO [main] com.fullcontact.sstable.example.JsonColumnParser: columnName:fenqile:fenqile_web:smartId:<span class="number">1111111111111</span>:,colId:fenqile:fenqile_web:smartid:<span class="number">1111111111111</span>:,cfd:attribute, partner_code, app_name, type, timestamp =&gt; &#123;event, sequence_id&#125;</span><br><span class="line"><span class="number">2015-11-09</span> <span class="number">10:43:56,99</span>5 INFO [main] com.fullcontact.sstable.example.JsonColumnParser: columnName:event,colId:event,cfd:attribute, partner_code, app_name, type, timestamp =&gt; &#123;event, sequence_id&#125;</span><br><span class="line"><span class="number">2015-11-09</span> <span class="number">10:43:56,99</span>6 INFO [main] com.fullcontact.sstable.example.JsonColumnParser: columnName:sequence_id,colId:sequence_id,cfd:attribute, partner_code, app_name, type, timestamp =&gt; &#123;event, sequence_id&#125;</span><br><span class="line"></span><br><span class="line"><span class="number">2015-11-09</span> <span class="number">10:43:56,99</span>8 INFO [main] com.fullcontact.sstable.example.JsonColumnParser: columnName:zzbbs_com:zzbbs_com_web:tokenId:<span class="number">2222222222</span>:,colId:zzbbs_com:zzbbs_com_web:tokenid:<span class="number">222222222222</span>:,cfd:attribute, partner_code, app_name, type, timestamp =&gt; &#123;event, sequence_id&#125;</span><br><span class="line"><span class="number">2015-11-09</span> <span class="number">10:43:56,99</span>8 INFO [main] com.fullcontact.sstable.example.JsonColumnParser: columnName:event,colId:event,cfd:attribute, partner_code, app_name, type, timestamp =&gt; &#123;event, sequence_id&#125;</span><br><span class="line"><span class="number">2015-11-09</span> <span class="number">10:43:56,99</span>9 INFO [main] com.fullcontact.sstable.example.JsonColumnParser: columnName:sequence_id,colId:sequence_id,cfd:attribute, partner_code, app_name, type, timestamp =&gt; &#123;event, sequence_id&#125;</span><br><span class="line"></span><br><span class="line"><span class="number">2015-11-09</span> <span class="number">10:43:57,80</span>6 INFO [main] com.fullcontact.sstable.example.JsonColumnParser: columnName:koudai:weidian:accountLogin:<span class="number">143801202355</span>8:,colId:koudai:weidian:accountlogin:<span class="number">143801202355</span>8:,cfd:attribute, partner_code, app_name, type, timestamp =&gt; &#123;event, sequence_id&#125;</span><br><span class="line"><span class="number">2015-11-09</span> <span class="number">10:43:57,80</span>7 INFO [main] com.fullcontact.sstable.example.JsonColumnParser: columnName:event,colId:event,cfd:attribute, partner_code, app_name, type, timestamp =&gt; &#123;event, sequence_id&#125;</span><br><span class="line"><span class="number">2015-11-09</span> <span class="number">10:43:57,80</span>7 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output</span><br><span class="line"><span class="number">2015-11-09</span> <span class="number">10:43:57,80</span>7 INFO [main] org.apache.hadoop.mapred.MapTask: Spilling map output</span><br><span class="line"><span class="number">2015-11-09</span> <span class="number">10:43:57,80</span>7 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0<span class="comment">; bufend = 629620; bufvoid = 1048576000</span></span><br><span class="line"><span class="number">2015-11-09</span> <span class="number">10:43:57,80</span>7 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = <span class="number">262143996(104</span><span class="number">8575984</span>)<span class="comment">; kvend = 262142888(1048571552); length = 1109/65536000</span></span><br><span class="line"><span class="number">2015-11-09</span> <span class="number">10:43:57,87</span>4 INFO [main] org.apache.hadoop.mapred.MapTask: Finished spill 0</span><br><span class="line"><span class="number">2015-11-09</span> <span class="number">10:43:57,88</span>0 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : </span><br><span class="line">org.apache.cassandra.serializers.MarshalException: String didn't validate.</span><br><span class="line">        at org.apache.cassandra.serializers.UTF8Serializer.validate(UTF8Serializer.java:35)</span><br><span class="line">        at org.apache.cassandra.db.marshal.AbstractType.getString(AbstractType.java:154)</span><br><span class="line">        at com.fullcontact.sstable.example.JsonColumnParser.serializeColumns(JsonColumnParser.java:93)</span><br><span class="line">        at com.fullcontact.sstable.example.JsonColumnParser.getJson(JsonColumnParser.java:42)</span><br><span class="line">        at com.fullcontact.sstable.example.SimpleExampleMapper.map(SimpleExampleMapper.java:87)</span><br><span class="line">        at com.fullcontact.sstable.example.SimpleExampleMapper.map(SimpleExampleMapper.java:22)</span><br><span class="line">        at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:145)</span><br><span class="line">        at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:764)</span><br><span class="line">        at org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)</span><br><span class="line">        at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)</span><br><span class="line">        at java.security.AccessController.doPrivileged(Native Method)</span><br><span class="line">        at javax.security.auth.Subject.doAs(Subject.java:415)</span><br><span class="line">        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1556)</span><br><span class="line">        at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)</span><br></pre></td></tr></table></figure>
<p>没有row-key怎么办, 在Mapper中打印C* Key:  </p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">09</span> <span class="number">11</span>:<span class="number">36</span>:<span class="number">25</span>,<span class="number">742</span> INFO [main] com.fullcontact.sstable.example.SimpleExampleMapper: C* KEY:http:<span class="comment">//3g.baihe.com/mail/view?senderId=125007715&amp;id=5829667645</span></span><br><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">09</span> <span class="number">11</span>:<span class="number">36</span>:<span class="number">25</span>,<span class="number">743</span> INFO [main] com.fullcontact.sstable.example.JsonColumnParser: columnName:baihe:baihe:referCust:<span class="number">1445689629820</span>:,colId:baihe:baihe:refercust:<span class="number">1445689629820</span>:,cfd:attribute, partner_code, app_name, type, timestamp =&gt; &#123;event, sequence_id&#125;</span><br><span class="line"></span><br><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">09</span> <span class="number">11</span>:<span class="number">36</span>:<span class="number">25</span>,<span class="number">787</span> INFO [main] com.fullcontact.sstable.example.SimpleExampleMapper: C* KEY:Mozilla/<span class="number">5.0</span> (iPhone; CPU iPhone OS <span class="number">7</span>_0_3 like Mac OS X) AppleWebKit/<span class="number">537.51</span><span class="number">.1</span> (KHTML, like Gecko) Mobile/<span class="number">11</span>B511 MicroMessenger/<span class="number">6.2</span> NetType/<span class="number">2</span>G Language/zh_CN</span><br><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">09</span> <span class="number">11</span>:<span class="number">36</span>:<span class="number">25</span>,<span class="number">787</span> INFO [main] com.fullcontact.sstable.example.JsonColumnParser: columnName:cashbus:cashbus:userAgentCust:<span class="number">1445684570382</span>:,colId:cashbus:cashbus:useragentcust:<span class="number">1445684570382</span>:,cfd:attribute, partner_code, app_name, type, timestamp =&gt; &#123;event, sequence_id&#125;</span><br><span class="line"></span><br><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">09</span> <span class="number">11</span>:<span class="number">36</span>:<span class="number">26</span>,<span class="number">510</span> INFO [main] com.fullcontact.sstable.example.SimpleExampleMapper: C* KEY:<span class="number">22.841306</span>/<span class="number">108.263826</span></span><br><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">09</span> <span class="number">11</span>:<span class="number">36</span>:<span class="number">26</span>,<span class="number">510</span> INFO [main] com.fullcontact.sstable.example.JsonColumnParser: columnName:meituan:meituan_andr:gpsAddress:<span class="number">1445739745644</span>:,colId:meituan:meituan_andr:gpsaddress:<span class="number">1445739745644</span>:,cfd:attribute, partner_code, app_name, type, timestamp =&gt; &#123;event, sequence_id&#125;</span><br></pre></td></tr></table></figure>
<p>一行记录有多个行:</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">09</span> <span class="number">11</span>:<span class="number">36</span>:<span class="number">25</span>,<span class="number">797</span> INFO [main] com.fullcontact.sstable.example.SimpleExampleMapper: C* KEY:<span class="number">13929558950</span></span><br><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">09</span> <span class="number">11</span>:<span class="number">36</span>:<span class="number">25</span>,<span class="number">797</span> INFO [main] com.fullcontact.sstable.example.JsonColumnParser: columnName:dianping:dianping_web:accountMobile:<span class="number">1445668503869</span>:,colId:dianping:dianping_web:accountmobile:<span class="number">1445668503869</span>:,cfd:attribute, partner_code, app_name, type, timestamp =&gt; &#123;event, sequence_id&#125;</span><br><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">09</span> <span class="number">11</span>:<span class="number">36</span>:<span class="number">25</span>,<span class="number">798</span> INFO [main] com.fullcontact.sstable.example.JsonColumnParser: columnName:dianping:dianping_web:accountMobile:<span class="number">1445669297664</span>:,colId:dianping:dianping_web:accountmobile:<span class="number">1445669297664</span>:,cfd:attribute, partner_code, app_name, type, timestamp =&gt; &#123;event, sequence_id&#125;</span><br><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">09</span> <span class="number">11</span>:<span class="number">36</span>:<span class="number">25</span>,<span class="number">799</span> INFO [main] com.fullcontact.sstable.example.JsonColumnParser: columnName:dianping:dianping_web:accountMobile:<span class="number">1445669756951</span>:,colId:dianping:dianping_web:accountmobile:<span class="number">1445669756951</span>:,cfd:attribute, partner_code, app_name, type, timestamp =&gt; &#123;event, sequence_id&#125;</span><br><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">09</span> <span class="number">11</span>:<span class="number">36</span>:<span class="number">25</span>,<span class="number">800</span> INFO [main] com.fullcontact.sstable.example.JsonColumnParser: columnName:dianping:dianping_web:accountMobile:<span class="number">1445669776335</span>:,colId:dianping:dianping_web:accountmobile:<span class="number">1445669776335</span>:,cfd:attribute, partner_code, app_name, type, timestamp =&gt; &#123;event, sequence_id&#125;</span><br><span class="line"></span><br><span class="line">相同attribute的, 不一定是同一个合作方, 也不一定是同一个字段. 比如key=<span class="string">"125.91.20"</span>, 这个字段可能是ip3,trueip3.  </span><br><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">09</span> <span class="number">11</span>:<span class="number">36</span>:<span class="number">26</span>,<span class="number">433</span> INFO [main] com.fullcontact.sstable.example.SimpleExampleMapper: C* KEY:<span class="number">125.91</span><span class="number">.20</span></span><br><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">09</span> <span class="number">11</span>:<span class="number">36</span>:<span class="number">26</span>,<span class="number">433</span> INFO [main] com.fullcontact.sstable.example.JsonColumnParser: columnName:jiedaibao:jiedaibao_andro:ip3:<span class="number">1445672779628</span>:,colId:jiedaibao:jiedaibao_andro:ip3:<span class="number">1445672779628</span>:,cfd:attribute, partner_code, app_name, type, timestamp =&gt; &#123;event, sequence_id&#125;</span><br><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">09</span> <span class="number">11</span>:<span class="number">36</span>:<span class="number">26</span>,<span class="number">434</span> INFO [main] com.fullcontact.sstable.example.JsonColumnParser: columnName:koudai:weidian:ip3:<span class="number">1445695936013</span>:,colId:koudai:weidian:ip3:<span class="number">1445695936013</span>:,cfd:attribute, partner_code, app_name, type, timestamp =&gt; &#123;event, sequence_id&#125;</span><br><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">09</span> <span class="number">11</span>:<span class="number">36</span>:<span class="number">26</span>,<span class="number">434</span> INFO [main] com.fullcontact.sstable.example.JsonColumnParser: columnName:koudai:weidian:trueip3:<span class="number">1445695936013</span>:,colId:koudai:weidian:trueip3:<span class="number">1445695936013</span>:,cfd:attribute, partner_code, app_name, type, timestamp =&gt; &#123;event, sequence_id&#125;</span><br><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">09</span> <span class="number">11</span>:<span class="number">36</span>:<span class="number">26</span>,<span class="number">435</span> INFO [main] com.fullcontact.sstable.example.JsonColumnParser: columnName:tcly:tcly:trueip3:<span class="number">1445714876562</span>:,colId:tcly:tcly:trueip3:<span class="number">1445714876562</span>:,cfd:attribute, partner_code, app_name, type, timestamp =&gt; &#123;event, sequence_id&#125;</span><br></pre></td></tr></table></figure>
<p>注意下面的日志中第一行的Column的name是null, 这是在JsonColumnParser.getColumnValueConvertor中添加的日志.  </p>
<figure class="highlight dns"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">LOG.info("&lt;&lt;columnName:" +columnName + ",colId:" + colId + ",name:" + (name==null?"DEFAULT(UDF8)":name.type) + "&gt;&gt;")<span class="comment">;</span></span><br><span class="line"></span><br><span class="line">C* <span class="keyword">KEY</span>: <span class="number">123456789</span></span><br><span class="line">columnName:fenqile:fenqile_web:smartId:<span class="number">1111111111111</span>:,colId:fenqile:fenqile_web:smartid:<span class="number">1111111111111</span>:,cfd:attribute, partner_code, app_name, type, timestamp =&gt; &#123;event, sequence_id&#125;</span><br><span class="line">columnName:event,colId:event,cfd:attribute, partner_code, app_name, type, timestamp =&gt; &#123;event, sequence_id&#125;</span><br><span class="line">columnName:sequence_id,colId:sequence_id,cfd:attribute, partner_code, app_name, type, timestamp =&gt; &#123;event, sequence_id&#125;</span><br><span class="line"></span><br><span class="line"><span class="number">2015-11-09</span> <span class="number">18:41:29,49</span>9 INFO [main] com.fullcontact.sstable.example.SimpleExampleMapper: C* <span class="keyword">KEY</span>:t458t75art3274v1lh9iutrs12</span><br><span class="line"><span class="number">2015-11-09</span> <span class="number">18:41:29,50</span>1 INFO [main] com.fullcontact.sstable.example.JsonColumnParser: &lt;&lt;columnName:zzbbs_com:zzbbs_com_web:tokenId:<span class="number">144567662986</span>4:,colId:zzbbs_com:zzbbs_com_web:tokenid:<span class="number">144567662986</span>4:,name:DEFAULT(UDF8)&gt;&gt;</span><br><span class="line"><span class="number">2015-11-09</span> <span class="number">18:41:29,50</span>1 INFO [main] com.fullcontact.sstable.example.JsonColumnParser: JSON:</span><br><span class="line"></span><br><span class="line"><span class="number">2015-11-09</span> <span class="number">18:41:29,50</span>1 INFO [main] com.fullcontact.sstable.example.JsonColumnParser: &lt;&lt;columnName:event,colId:event,name:org.apache.cassandra.db.marshal.UTF8Type&gt;&gt;</span><br><span class="line"><span class="number">2015-11-09</span> <span class="number">18:41:29,50</span>2 INFO [main] com.fullcontact.sstable.example.JsonColumnParser: JSON: &#123;\"eventId\":\"login_web\"&#125;</span><br><span class="line"></span><br><span class="line"><span class="number">2015-11-09</span> <span class="number">18:41:29,50</span>2 INFO [main] com.fullcontact.sstable.example.JsonColumnParser: &lt;&lt;columnName:sequence_id,colId:sequence_id,name:org.apache.cassandra.db.marshal.UTF8Type&gt;&gt;</span><br><span class="line"><span class="number">2015-11-09</span> <span class="number">18:41:29,50</span>2 INFO [main] com.fullcontact.sstable.example.JsonColumnParser: JSON: <span class="number">144567662971</span><span class="number">8-50987935</span></span><br><span class="line"></span><br><span class="line">后面两行的Column的name跟columnName,colId是一样的.  </span><br><span class="line"></span><br><span class="line">假设上面有三行记录, 对应的底层存储实际上是:</span><br><span class="line">                fenqile:fenqile_web:smartId:<span class="number">1111111111111</span>:event     fenqile:fenqile_web:smartId:<span class="number">1111111111111</span>:sequence_id</span><br><span class="line"><span class="number">123456789</span>       event value                                         sequence_id value</span><br><span class="line"></span><br><span class="line">所以同一row-key有多行记录, 在底层的DataModel中也只会有一条记录, 只不过这些行会以列的形式存储. 所以Cassandra叫做wide rows(columns??).</span><br></pre></td></tr></table></figure>
<h3 id="直接将ByteBuffer转换为字符串,_而不使用C*的类型转换">直接将ByteBuffer转换为字符串, 而不使用C*的类型转换</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">sb.append(JSONObject.escape(getColumnValueConvertor(handleCompositeColumnName(cn), UTF8Type.instance).getString(column.value())));</span><br><span class="line"></span><br><span class="line"><span class="comment">//手动将ByteBuffer转为字符串,不用Cassandra的Type转换</span></span><br><span class="line">ByteBuffer buffer = column.value();</span><br><span class="line">String content = byteBufferToString(buffer);</span><br><span class="line">String json = JSONObject.escape(content);</span><br><span class="line">LOG.info(<span class="string">"BUFFER: &#123;&#125;"</span>, buffer);</span><br><span class="line">LOG.info(<span class="string">"JSON: &#123;&#125;"</span>, json);</span><br><span class="line">sb.append(json);</span><br></pre></td></tr></table></figure>
<p>使用JSON转换, 内存不足.  </p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">5</span>/<span class="number">11</span>/<span class="number">09</span> <span class="number">15</span>:<span class="number">16</span>:<span class="number">34</span> INFO mapreduce.Job: Task Id : attempt_1446983986550_0017_m_000009_1, Status : FAILED</span><br><span class="line">Error: Java heap space</span><br><span class="line"><span class="number">15</span>/<span class="number">11</span>/<span class="number">09</span> <span class="number">15</span>:<span class="number">16</span>:<span class="number">35</span> INFO mapreduce.Job:  <span class="built_in">map</span> <span class="number">90</span>% reduce <span class="number">2</span>%</span><br><span class="line"><span class="number">15</span>/<span class="number">11</span>/<span class="number">09</span> <span class="number">15</span>:<span class="number">16</span>:<span class="number">48</span> INFO mapreduce.Job:  <span class="built_in">map</span> <span class="number">97</span>% reduce <span class="number">2</span>%</span><br><span class="line"><span class="number">15</span>/<span class="number">11</span>/<span class="number">09</span> <span class="number">15</span>:<span class="number">17</span>:<span class="number">46</span> INFO mapreduce.Job: Task Id : attempt_1446983986550_0017_m_000009_2, Status : FAILED</span><br><span class="line">Error: Java heap space</span><br><span class="line"><span class="number">15</span>/<span class="number">11</span>/<span class="number">09</span> <span class="number">15</span>:<span class="number">17</span>:<span class="number">47</span> INFO mapreduce.Job:  <span class="built_in">map</span> <span class="number">90</span>% reduce <span class="number">2</span>%</span><br><span class="line"><span class="number">15</span>/<span class="number">11</span>/<span class="number">09</span> <span class="number">15</span>:<span class="number">18</span>:<span class="number">00</span> INFO mapreduce.Job:  <span class="built_in">map</span> <span class="number">97</span>% reduce <span class="number">2</span>%</span><br></pre></td></tr></table></figure>
<h3 id="VelocityRead2Write测试">VelocityRead2Write测试</h3><p>测试直接输出Column的name和value, 先写到HDFS上:    </p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">/usr/install/hadoop/bin/hadoop jar hadoop-sstable-<span class="number">2.0</span>.<span class="number">0</span><span class="class">.jar</span> com<span class="class">.fullcontact</span><span class="class">.sstable</span><span class="class">.example</span><span class="class">.SimpleExample</span> \</span><br><span class="line">    -libjars guava-<span class="number">16.0</span>.<span class="number">1</span><span class="class">.jar</span> \</span><br><span class="line">    -D hadoop<span class="class">.sstable</span><span class="class">.cql</span>=<span class="string">"CREATE TABLE velocity (attribute text,partner_code text,app_name text,type text,&amp;timestamp&amp; bigint,event text,sequence_id text,PRIMARY KEY ((attribute), partner_code, app_name, type, &amp;timestamp&amp;)) WITH bloom_filter_fp_chance=0.100000 AND caching='ALL' AND comment='' AND dclocal_read_repair_chance=0.000000 AND gc_grace_seconds=0 AND index_interval=128 AND read_repair_chance=0.100000 AND replicate_on_write='true' AND populate_io_cache_on_flush='false' AND default_time_to_live=0 AND speculative_retry='99.0PERCENTILE' AND memtable_flush_period_in_ms=0 AND compaction=&#123;'unchecked_tombstone_compaction': 'true', 'tombstone_threshold': '0.1', 'class': 'LeveledCompactionStrategy'&#125; AND compression=&#123;'sstable_compression': 'LZ4Compressor'&#125;"</span> \</span><br><span class="line">    -D mapred<span class="class">.task</span><span class="class">.timeout</span>=<span class="number">21600000</span> \</span><br><span class="line">    -D mapred<span class="class">.map</span><span class="class">.tasks</span><span class="class">.speculative</span><span class="class">.execution</span>=false \</span><br><span class="line">    -D mapred<span class="class">.job</span><span class="class">.reuse</span><span class="class">.jvm</span><span class="class">.num</span><span class="class">.tasks</span>=<span class="number">1</span> \</span><br><span class="line">    -D io<span class="class">.sort</span><span class="class">.mb</span>=<span class="number">1000</span> \</span><br><span class="line">    -D io<span class="class">.sort</span><span class="class">.factor</span>=<span class="number">100</span> \</span><br><span class="line">    -D hadoop<span class="class">.sstable</span><span class="class">.split</span><span class="class">.mb</span>=<span class="number">1024</span> \</span><br><span class="line">    -D mapred<span class="class">.reduce</span><span class="class">.tasks</span>=<span class="number">5</span> \</span><br><span class="line">    -D mapred<span class="class">.child</span><span class="class">.java</span><span class="class">.opts</span>=<span class="string">"-Xmx3G -XX:MaxPermSize=512m"</span> \</span><br><span class="line">    -D hadoop<span class="class">.sstable</span><span class="class">.keyspace</span>=<span class="string">"forseti"</span> \</span><br><span class="line">    -D hadoop<span class="class">.sstable</span><span class="class">.column</span><span class="class">.family</span><span class="class">.name</span>=<span class="string">"velocity"</span> \</span><br><span class="line">    -D mapreduce<span class="class">.job</span><span class="class">.user</span><span class="class">.classpath</span><span class="class">.first</span>=true \</span><br><span class="line">    /user/qihuang.zheng/velocity_backup_1107/<span class="number">226</span>_1105/<span class="number">10</span>/forseti/velocity /user/qihuang.zheng/velocity_test12</span><br><span class="line"></span><br><span class="line">没有Reduce的测试示例. 直接输出, 查看输出的key,value数据是怎么样的:  </span><br><span class="line">/usr/install/hadoop/bin/hadoop jar hadoop-sstable-<span class="number">2.0</span>.<span class="number">0</span><span class="class">.jar</span> com<span class="class">.fullcontact</span><span class="class">.sstable</span><span class="class">.example</span><span class="class">.VelocityReadJobTest</span> \</span><br><span class="line">    -libjars guava-<span class="number">16.0</span>.<span class="number">1</span><span class="class">.jar</span> \</span><br><span class="line">    -D hadoop<span class="class">.sstable</span><span class="class">.cql</span>=<span class="string">"CREATE TABLE velocity (attribute text,partner_code text,app_name text,type text,&amp;timestamp&amp; bigint,event text,sequence_id text,PRIMARY KEY ((attribute), partner_code, app_name, type, &amp;timestamp&amp;)) WITH bloom_filter_fp_chance=0.100000 AND caching='ALL' AND comment='' AND dclocal_read_repair_chance=0.000000 AND gc_grace_seconds=0 AND index_interval=128 AND read_repair_chance=0.100000 AND replicate_on_write='true' AND populate_io_cache_on_flush='false' AND default_time_to_live=0 AND speculative_retry='99.0PERCENTILE' AND memtable_flush_period_in_ms=0 AND compaction=&#123;'unchecked_tombstone_compaction': 'true', 'tombstone_threshold': '0.1', 'class': 'LeveledCompactionStrategy'&#125; AND compression=&#123;'sstable_compression': 'LZ4Compressor'&#125;"</span> \</span><br><span class="line">    -D mapred<span class="class">.task</span><span class="class">.timeout</span>=<span class="number">21600000</span> \</span><br><span class="line">    -D mapred<span class="class">.map</span><span class="class">.tasks</span><span class="class">.speculative</span><span class="class">.execution</span>=false \</span><br><span class="line">    -D mapred<span class="class">.job</span><span class="class">.reuse</span><span class="class">.jvm</span><span class="class">.num</span><span class="class">.tasks</span>=<span class="number">1</span> \</span><br><span class="line">    -D io<span class="class">.sort</span><span class="class">.mb</span>=<span class="number">1000</span> \</span><br><span class="line">    -D io<span class="class">.sort</span><span class="class">.factor</span>=<span class="number">100</span> \</span><br><span class="line">    -D hadoop<span class="class">.sstable</span><span class="class">.split</span><span class="class">.mb</span>=<span class="number">1024</span> \</span><br><span class="line">    -D mapred<span class="class">.reduce</span><span class="class">.tasks</span>=<span class="number">0</span> \</span><br><span class="line">    -D mapred<span class="class">.child</span><span class="class">.java</span><span class="class">.opts</span>=<span class="string">"-Xmx3G -XX:MaxPermSize=512m"</span> \</span><br><span class="line">    -D hadoop<span class="class">.sstable</span><span class="class">.keyspace</span>=<span class="string">"forseti"</span> \</span><br><span class="line">    -D hadoop<span class="class">.sstable</span><span class="class">.column</span><span class="class">.family</span><span class="class">.name</span>=<span class="string">"velocity"</span> \</span><br><span class="line">    -D mapreduce<span class="class">.job</span><span class="class">.user</span><span class="class">.classpath</span><span class="class">.first</span>=true \</span><br><span class="line">    /user/qihuang.zheng/velocity_backup_1107/<span class="number">226</span>_1105/<span class="number">10</span>/forseti/velocity /user/qihuang.zheng/velocity_test01</span><br></pre></td></tr></table></figure>
<p>不要去掉Reduce Task的数量配置, 因为默认值是2个, 要直接改为0表示只有MapTask,没有ReduceTask.   </p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-D mapred<span class="class">.reduce</span><span class="class">.tasks</span>=<span class="number">10</span> \</span><br></pre></td></tr></table></figure>
<p>如果直接输出Column, 没有判断: </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Column column = (Column) atom;</span><br><span class="line">String columnName = byteBufferToString(column.name());</span><br><span class="line">String columnValue = byteBufferToString(column.value());</span><br><span class="line">LOG.info(<span class="string">"列名:"</span> + columnName + <span class="string">", 列值:"</span> + columnValue);</span><br><span class="line">context.write(mapKey, <span class="keyword">new</span> TextPair(<span class="keyword">new</span> Text(columnName), <span class="keyword">new</span> Text(columnValue)));</span><br></pre></td></tr></table></figure>
<p>对于上面第一行的数据就会存在问题:  </p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">09</span> <span class="number">15</span>:<span class="number">29</span>:<span class="number">38</span>,<span class="number">122</span> INFO [main] com.fullcontact.sstable.example.VelocityRead2Write: C* KEY:dca0d97327ea4bd2b828ca27e2adfaa5</span><br><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">09</span> <span class="number">15</span>:<span class="number">29</span>:<span class="number">38</span>,<span class="number">124</span> INFO [main] com.fullcontact.sstable.example.VelocityRead2Write: 列名:null, 列值:</span><br><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">09</span> <span class="number">15</span>:<span class="number">29</span>:<span class="number">38</span>,<span class="number">124</span> INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of <span class="built_in">map</span> output</span><br><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">09</span> <span class="number">15</span>:<span class="number">29</span>:<span class="number">38</span>,<span class="number">135</span> WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.lang.NullPointerException</span><br><span class="line">        at org.apache.hadoop.io.Text.encode(Text.java:<span class="number">443</span>)</span><br><span class="line">        at org.apache.hadoop.io.Text.<span class="built_in">set</span>(Text.java:<span class="number">198</span>)</span><br><span class="line">        at org.apache.hadoop.io.Text.&lt;init&gt;(Text.java:<span class="number">88</span>)</span><br><span class="line">        at com.fullcontact.sstable.example.VelocityRead2Write$VelocityReadMapper.<span class="built_in">map</span>(VelocityRead2Write.java:<span class="number">143</span>)</span><br><span class="line">        at com.fullcontact.sstable.example.VelocityRead2Write$VelocityReadMapper.<span class="built_in">map</span>(VelocityRead2Write.java:<span class="number">129</span>)</span><br><span class="line">        at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:<span class="number">145</span>)</span><br><span class="line">        at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:<span class="number">764</span>)</span><br><span class="line">        at org.apache.hadoop.mapred.MapTask.run(MapTask.java:<span class="number">340</span>)</span><br><span class="line">        at org.apache.hadoop.mapred.YarnChild$<span class="number">2.</span>run(YarnChild.java:<span class="number">167</span>)</span><br><span class="line">        at java.security.AccessController.doPrivileged(Native Method)</span><br><span class="line">        at javax.security.auth.Subject.doAs(Subject.java:<span class="number">415</span>)</span><br><span class="line">        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:<span class="number">1556</span>)</span><br><span class="line">        at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:<span class="number">162</span>)</span><br></pre></td></tr></table></figure>
<p>对ColumnName, Value进行非空判断:  </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (atom <span class="keyword">instanceof</span> Column) &#123;</span><br><span class="line">    Column column = (Column) atom;</span><br><span class="line">    ByteBuffer columnNameBB = column.name();</span><br><span class="line">    ByteBuffer columnValueBB = column.value();</span><br><span class="line">    LOG.info(<span class="string">"Column: &#123;&#125;"</span>, column);</span><br><span class="line">    LOG.info(<span class="string">"ColumnName: &#123;&#125;"</span>, columnNameBB);</span><br><span class="line">    LOG.info(<span class="string">"ColumnValue: &#123;&#125;"</span>, columnValueBB);</span><br><span class="line"></span><br><span class="line">    String columnName = byteBufferToString(column.name());</span><br><span class="line">    String columnValue = byteBufferToString(column.value());</span><br><span class="line">    LOG.info(<span class="string">"ColumnNameValueString: "</span> + columnName + <span class="string">","</span> + columnValue + <span class="string">"."</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>(<span class="keyword">null</span> != columnName &amp;&amp; <span class="keyword">null</span> != columnValue) &#123;</span><br><span class="line">        LOG.info(<span class="string">"列名:"</span> + columnName + <span class="string">", 列值:"</span> + columnValue);</span><br><span class="line">        context.write(mapKey, <span class="keyword">new</span> Text(columnName + <span class="string">"$"</span> + columnValue));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/*</span><br><span class="line">    Text columnName = new Text(UTF8Type.instance.getString(column.name()));</span><br><span class="line">    Text columnValue = new Text(UTF8Type.instance.getString(column.value()));</span><br><span class="line">    LOG.info(columnName + " , " + columnValue);</span><br><span class="line">    context.write(mapKey, new TextPair(columnName, columnValue));</span><br><span class="line">    */</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>详细输出日志: 注意到将ByteBuffer直接转换为字符串, columnName为null. 而第一行的columnValue是空字符串.  </p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">2015<span class="tag">-11-09</span> 17<span class="pseudo">:25</span><span class="pseudo">:47</span>,035 <span class="tag">INFO</span> <span class="attr_selector">[main]</span> <span class="tag">com</span><span class="class">.fullcontact</span><span class="class">.sstable</span><span class="class">.example</span><span class="class">.VelocityRead2Write</span>: <span class="tag">C</span>* <span class="tag">KEY</span><span class="pseudo">:dca0daaaaaaaaaaaaaaaaaa</span></span><br><span class="line">2015<span class="tag">-11-09</span> 17<span class="pseudo">:25</span><span class="pseudo">:47</span>,038 <span class="tag">INFO</span> <span class="attr_selector">[main]</span> <span class="tag">com</span><span class="class">.fullcontact</span><span class="class">.sstable</span><span class="class">.example</span><span class="class">.VelocityRead2Write</span>: <span class="tag">Column</span>: <span class="tag">org</span><span class="class">.apache</span><span class="class">.cassandra</span><span class="class">.db</span><span class="class">.ExpiringColumn</span><span class="at_rule">@<span class="keyword">5c4b5693</span></span><br><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">09</span> <span class="number">17</span>:<span class="number">25</span>:<span class="number">47</span>,<span class="number">038</span> INFO [main] com.fullcontact.sstable.example.VelocityRead2Write: ColumnName: java.nio.HeapByteBuffer[pos=<span class="number">0</span> lim=<span class="number">42</span> cap=<span class="number">42</span>]</span><br><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">09</span> <span class="number">17</span>:<span class="number">25</span>:<span class="number">47</span>,<span class="number">038</span> INFO [main] com.fullcontact.sstable.example.VelocityRead2Write: ColumnValue: java.nio.HeapByteBuffer[pos=<span class="number">0</span> lim=<span class="number">0</span> cap=<span class="number">0</span>]</span><br><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">09</span> <span class="number">17</span>:<span class="number">25</span>:<span class="number">47</span>,<span class="number">039</span> INFO [main] com.fullcontact.sstable.example.VelocityRead2Write: ColumnNameValueString: null,.</span><br><span class="line"></span><br><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">09</span> <span class="number">17</span>:<span class="number">25</span>:<span class="number">47</span>,<span class="number">039</span> INFO [main] com.fullcontact.sstable.example.VelocityRead2Write: Column: org.apache.cassandra.db.ExpiringColumn@<span class="number">3229</span>da81</span><br><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">09</span> <span class="number">17</span>:<span class="number">25</span>:<span class="number">47</span>,<span class="number">039</span> INFO [main] com.fullcontact.sstable.example.VelocityRead2Write: ColumnName: java.nio.HeapByteBuffer[pos=<span class="number">0</span> lim=<span class="number">47</span> cap=<span class="number">47</span>]</span><br><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">09</span> <span class="number">17</span>:<span class="number">25</span>:<span class="number">47</span>,<span class="number">039</span> INFO [main] com.fullcontact.sstable.example.VelocityRead2Write: ColumnValue: java.nio.HeapByteBuffer[pos=<span class="number">0</span> lim=<span class="number">586</span> cap=<span class="number">586</span>]</span><br><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">09</span> <span class="number">17</span>:<span class="number">25</span>:<span class="number">47</span>,<span class="number">039</span> INFO [main] com.fullcontact.sstable.example.VelocityRead2Write: ColumnNameValueString: null,</span>&#123;"<span class="tag">payAmount</span>"<span class="pseudo">:990000</span>,"<span class="tag">ext_merchant_accont</span>"<span class="pseudo">:"1</span>&#125;.</span><br><span class="line"></span><br><span class="line">2015<span class="tag">-11-09</span> 17<span class="pseudo">:25</span><span class="pseudo">:47</span>,039 <span class="tag">INFO</span> <span class="attr_selector">[main]</span> <span class="tag">com</span><span class="class">.fullcontact</span><span class="class">.sstable</span><span class="class">.example</span><span class="class">.VelocityRead2Write</span>: <span class="tag">Column</span>: <span class="tag">org</span><span class="class">.apache</span><span class="class">.cassandra</span><span class="class">.db</span><span class="class">.ExpiringColumn</span><span class="at_rule">@<span class="keyword">d5df21ef</span></span><br><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">09</span> <span class="number">17</span>:<span class="number">25</span>:<span class="number">47</span>,<span class="number">039</span> INFO [main] com.fullcontact.sstable.example.VelocityRead2Write: ColumnName: java.nio.HeapByteBuffer[pos=<span class="number">0</span> lim=<span class="number">53</span> cap=<span class="number">53</span>]</span><br><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">09</span> <span class="number">17</span>:<span class="number">25</span>:<span class="number">47</span>,<span class="number">039</span> INFO [main] com.fullcontact.sstable.example.VelocityRead2Write: ColumnValue: java.nio.HeapByteBuffer[pos=<span class="number">0</span> lim=<span class="number">22</span> cap=<span class="number">22</span>]</span><br><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">09</span> <span class="number">17</span>:<span class="number">25</span>:<span class="number">47</span>,<span class="number">040</span> INFO [main] com.fullcontact.sstable.example.VelocityRead2Write: ColumnNameValueString: null,<span class="number">1445314378193</span>-<span class="number">11111</span>.</span></span><br></pre></td></tr></table></figure>
<p>KEY对应在Cassandra中的记录只有一条:  </p>
<figure class="highlight gherkin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cqlsh:forseti&gt; select <span class="keyword">*</span> from velocity where attribute='dca0d973aaaaaaaaaaaaaaaaaaaaaaaa';</span><br><span class="line"></span><br><span class="line"> attribute                        |<span class="string"> partner_code </span>|<span class="string"> app_name </span>|<span class="string"> type    </span>|<span class="string"> timestamp     </span>|<span class="string"> event                       </span>|<span class="string"> sequence_id</span><br><span class="line">----------------------------------+--------------+----------+---------+---------------+-----------------------------+------------------------</span><br><span class="line"> dca0d973aaaaaaaaaaaaaaaaaaaaaaaa </span>|<span class="string">       reapal </span>|<span class="string">   reapal </span>|<span class="string"> tokenId </span>|<span class="string"> 1445314378187 </span>|<span class="string"> &#123;"payAmount":990000,"_1.."&#125; </span>|<span class="string"> 1445314378193-111111</span></span><br></pre></td></tr></table></figure>
<p>还会出现字符串解析的错误, 这是因为采用UTF8解析, 但是字符串中还有其他编码:    </p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">09</span> <span class="number">16</span>:<span class="number">04</span>:<span class="number">04</span>,<span class="number">554</span> INFO [main] com.fullcontact.sstable.example.VelocityRead2Write: C* KEY:pdf472547b-ddb7-<span class="number">4</span>ebe-b54f-<span class="number">07</span>a01e42699c</span><br><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">09</span> <span class="number">16</span>:<span class="number">04</span>:<span class="number">04</span>,<span class="number">561</span> INFO [main] com.fullcontact.sstable.example.VelocityRead2Write: C* KEY:NNh3mj5kv165lcg4brn1heashhs4</span><br><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">09</span> <span class="number">16</span>:<span class="number">04</span>:<span class="number">04</span>,<span class="number">565</span> INFO [main] com.fullcontact.sstable.example.VelocityRead2Write: C* KEY:<span class="number">239.33</span><span class="number">.100</span><span class="number">.128</span></span><br><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">09</span> <span class="number">16</span>:<span class="number">04</span>:<span class="number">04</span>,<span class="number">568</span> INFO [main] com.fullcontact.sstable.example.VelocityRead2Write: C* KEY:<span class="number">18759539862</span></span><br><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">09</span> <span class="number">16</span>:<span class="number">04</span>:<span class="number">04</span>,<span class="number">581</span> INFO [main] com.fullcontact.sstable.example.VelocityRead2Write: 列名:^@^Hfirstp2p^@^@^Lfirstp2p_web^@^@^LaccountLogin^@^@^H^@^@^AOn˓<span class="number">7</span>^@^@^@^@, 列值:</span><br><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">09</span> <span class="number">16</span>:<span class="number">04</span>:<span class="number">04</span>,<span class="number">582</span> INFO [main] com.fullcontact.sstable.example.VelocityRead2Write: 列名:^@^Hfirstp2p^@^@^Lfirstp2p_web^@^@^LaccountLogin^@^@^H^@^@^AOn˓<span class="number">7</span>^@^@^Eevent^@, 列值:&#123;<span class="string">"trueIp"</span>:<span class="string">"182.99.127.246"</span>,<span class="string">"eventId"</span>:<span class="string">"login_web"</span>,&#125;</span><br><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">09</span> <span class="number">16</span>:<span class="number">04</span>:<span class="number">04</span>,<span class="number">582</span> INFO [main] com.fullcontact.sstable.example.VelocityRead2Write: 列名:^@^Hfirstp2p^@^@^Lfirstp2p_web^@^@^LaccountLogin^@^@^H^@^@^AOn˓<span class="number">7</span>^@^@^Ksequence_id^@, 列值:<span class="number">1440672879237</span>-<span class="number">74693892</span></span><br><span class="line"></span><br><span class="line">java.nio.charset.MalformedInputException: Input length = <span class="number">1</span></span><br><span class="line">        at java.nio.charset.CoderResult.throwException(CoderResult.java:<span class="number">277</span>)</span><br><span class="line">        at java.nio.charset.CharsetDecoder.decode(CharsetDecoder.java:<span class="number">798</span>)</span><br><span class="line">        at com.fullcontact.sstable.example.VelocityRead2Write.byteBufferToString(VelocityRead2Write.java:<span class="number">162</span>)</span><br><span class="line">        at com.fullcontact.sstable.example.VelocityRead2Write$VelocityReadMapper.<span class="built_in">map</span>(VelocityRead2Write.java:<span class="number">141</span>)</span><br><span class="line">        at com.fullcontact.sstable.example.VelocityRead2Write$VelocityReadMapper.<span class="built_in">map</span>(VelocityRead2Write.java:<span class="number">129</span>)</span><br><span class="line">        at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:<span class="number">145</span>)</span><br><span class="line">        at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:<span class="number">764</span>)</span><br><span class="line">        at org.apache.hadoop.mapred.MapTask.run(MapTask.java:<span class="number">340</span>)</span><br><span class="line">        at org.apache.hadoop.mapred.YarnChild$<span class="number">2.</span>run(YarnChild.java:<span class="number">167</span>)</span><br><span class="line">        at java.security.AccessController.doPrivileged(Native Method)</span><br><span class="line">        at javax.security.auth.Subject.doAs(Subject.java:<span class="number">415</span>)</span><br><span class="line">        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:<span class="number">1556</span>)</span><br><span class="line">        at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:<span class="number">162</span>)</span><br></pre></td></tr></table></figure>
<p>解决方式: <a href="http://stackoverflow.com/questions/13625024/how-to-read-a-text-file-with-mixed-encodings-in-scala-or-java" target="_blank" rel="external">http://stackoverflow.com/questions/13625024/how-to-read-a-text-file-with-mixed-encodings-in-scala-or-java</a></p>
<h3 id="CFMetaData-comparator">CFMetaData.comparator</h3><p>根据CFMetaData获取columnNameConverter, 之前以为columnNameConverter就是UTF8Type,导致数据一直报错NullPointerException:<br>这里的columnNameConverter是CompositeType, 而不是简单的UTF8Type.  </p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">2015<span class="tag">-11-09</span> 19<span class="pseudo">:02</span><span class="pseudo">:29</span>,206 <span class="tag">INFO</span> <span class="attr_selector">[main]</span> <span class="tag">com</span><span class="class">.fullcontact</span><span class="class">.sstable</span><span class="class">.example</span><span class="class">.VelocityRead2Write</span>: <span class="tag">------------------</span></span><br><span class="line">2015<span class="tag">-11-09</span> 19<span class="pseudo">:02</span><span class="pseudo">:29</span>,206 <span class="tag">INFO</span> <span class="attr_selector">[main]</span> <span class="tag">com</span><span class="class">.fullcontact</span><span class="class">.sstable</span><span class="class">.example</span><span class="class">.VelocityRead2Write</span>: <span class="tag">C</span>* <span class="tag">KEY</span><span class="pseudo">:s_bc91a07f9f66485d867a111111111111</span></span><br><span class="line">2015<span class="tag">-11-09</span> 19<span class="pseudo">:02</span><span class="pseudo">:29</span>,206 <span class="tag">INFO</span> <span class="attr_selector">[main]</span> <span class="tag">com</span><span class="class">.fullcontact</span><span class="class">.sstable</span><span class="class">.example</span><span class="class">.VelocityRead2Write</span>: <span class="tag">ROW</span> <span class="tag">KEY</span>: <span class="tag">DecoratedKey</span>(740835552612111111111111111111111, 735<span class="tag">f62633931613011111111111111111111111111111111111111632363738643064</span>)</span><br><span class="line">2015<span class="tag">-11-09</span> 19<span class="pseudo">:02</span><span class="pseudo">:29</span>,209 <span class="tag">INFO</span> <span class="attr_selector">[main]</span> <span class="tag">com</span><span class="class">.fullcontact</span><span class="class">.sstable</span><span class="class">.example</span><span class="class">.VelocityRead2Write</span>: _<span class="tag">COLUMN</span> <span class="tag">NAME</span>: <span class="tag">fenqile</span><span class="pseudo">:fenqile_web</span><span class="pseudo">:smartId</span><span class="pseudo">:1111111111111</span>:, <span class="tag">cn</span><span class="pseudo">:fenqile</span><span class="pseudo">:fenqile_web</span><span class="pseudo">:smartId</span><span class="pseudo">:1111111111111</span>:</span><br><span class="line">2015<span class="tag">-11-09</span> 19<span class="pseudo">:02</span><span class="pseudo">:29</span>,209 <span class="tag">INFO</span> <span class="attr_selector">[main]</span> <span class="tag">com</span><span class="class">.fullcontact</span><span class="class">.sstable</span><span class="class">.example</span><span class="class">.VelocityRead2Write</span>: _<span class="tag">COLUMN</span> <span class="tag">NAME</span>: <span class="tag">event</span>, <span class="tag">cn</span><span class="pseudo">:fenqile</span><span class="pseudo">:fenqile_web</span><span class="pseudo">:smartId</span><span class="pseudo">:1111111111111</span><span class="pseudo">:event</span></span><br><span class="line">2015<span class="tag">-11-09</span> 19<span class="pseudo">:02</span><span class="pseudo">:29</span>,209 <span class="tag">INFO</span> <span class="attr_selector">[main]</span> <span class="tag">com</span><span class="class">.fullcontact</span><span class="class">.sstable</span><span class="class">.example</span><span class="class">.VelocityRead2Write</span>: _<span class="tag">COLUMN</span> <span class="tag">NAME</span>: <span class="tag">sequence_id</span>, <span class="tag">cn</span><span class="pseudo">:fenqile</span><span class="pseudo">:fenqile_web</span><span class="pseudo">:smartId</span><span class="pseudo">:1111111111111</span><span class="pseudo">:sequence_id</span></span><br><span class="line">2015<span class="tag">-11-09</span> 19<span class="pseudo">:02</span><span class="pseudo">:29</span>,211 <span class="tag">INFO</span> <span class="attr_selector">[main]</span> <span class="tag">com</span><span class="class">.fullcontact</span><span class="class">.sstable</span><span class="class">.example</span><span class="class">.VelocityRead2Write</span>: <span class="tag">------------------</span></span><br></pre></td></tr></table></figure>
<p>真正的ColumnName是cn字段: </p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">fenqile</span><span class="pseudo">:fenqile_web</span><span class="pseudo">:smartId</span><span class="pseudo">:1111111111111</span>:</span><br><span class="line"><span class="tag">fenqile</span><span class="pseudo">:fenqile_web</span><span class="pseudo">:smartId</span><span class="pseudo">:1111111111111</span><span class="pseudo">:event</span></span><br><span class="line"><span class="tag">fenqile</span><span class="pseudo">:fenqile_web</span><span class="pseudo">:smartId</span><span class="pseudo">:1111111111111</span><span class="pseudo">:sequence_id</span></span><br></pre></td></tr></table></figure>
<p>虽然Job提示map已经100%, 但是在100%这里停了很久:  </p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">15</span>/<span class="number">11</span>/<span class="number">09</span> <span class="number">20</span>:<span class="number">50</span>:<span class="number">51</span> INFO mapreduce.Job:  <span class="built_in">map</span> <span class="number">99</span>% reduce <span class="number">0</span>%</span><br><span class="line"><span class="number">15</span>/<span class="number">11</span>/<span class="number">09</span> <span class="number">20</span>:<span class="number">50</span>:<span class="number">54</span> INFO mapreduce.Job:  <span class="built_in">map</span> <span class="number">100</span>% reduce <span class="number">0</span>%</span><br><span class="line"></span><br><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">09</span> <span class="number">20</span>:<span class="number">54</span>:<span class="number">07</span>,<span class="number">850</span> INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree <span class="number">1591</span> <span class="keyword">for</span> container-id container_1446983986550_0033_01_000010: <span class="number">1.0</span> GB of <span class="number">4</span> GB physical memory used; <span class="number">4.2</span> GB of <span class="number">8.4</span> GB <span class="keyword">virtual</span> memory used</span><br></pre></td></tr></table></figure>
<p>现在可以得到一条完整的velocity记录了:  </p>
<figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[qihuang.zheng<span class="annotation">@spark</span>047219 ~]$ <span class="regexp">/usr/</span>install<span class="regexp">/hadoop/</span>bin<span class="regexp">/hadoop fs -cat /</span>user<span class="regexp">/qihuang.zheng/</span>velocity_test01/part-m-<span class="number">00000</span> | head</span><br><span class="line"><span class="string">fenqile:</span><span class="string">fenqile_web:</span><span class="string">smartId:</span><span class="number">1111111111111</span>:&#123;<span class="string">"trueIp"</span>:<span class="string">"42.90.7.10"</span>,<span class="string">"location"</span>:<span class="string">"兰州市"</span>,<span class="string">"ip3"</span>:<span class="string">"42.90.7"</span>,<span class="string">"status"</span>:<span class="string">"Accept"</span>,<span class="string">"accountLogin"</span>:<span class="string">"1763065275@qq.com"</span>,<span class="string">"smartId"</span>:<span class="string">"s_bc91a07f9f61111111111"</span>,<span class="string">"eventType"</span>:<span class="string">"Login"</span>,<span class="string">"eventOccurTime"</span>:<span class="number">1111111111111</span>,<span class="string">"create"</span>:<span class="number">1111111111111</span>,<span class="string">"eventId"</span>:<span class="string">"login_web"</span>,<span class="string">""</span>&#125;:<span class="number">1445683752333</span>-<span class="number">40985025</span></span><br></pre></td></tr></table></figure>
<h3 id="Too_Many_Tasks">Too Many Tasks</h3><p>Data文件每个大概160M左右:  </p>
<p><img src="http://img.blog.csdn.net/20151110134149469" alt="160m"></p>
<p>一个节点的数据分成每组大概1G左右, Data文件一共有1674个:  </p>
<figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[qihuang.zheng<span class="annotation">@spark</span>047219 ~]$ <span class="regexp">/usr/</span>install<span class="regexp">/hadoop/</span>bin<span class="regexp">/hadoop fs -ls -R /</span>user<span class="regexp">/qihuang.zheng/</span>velocity_backup_1107/<span class="number">226</span>_1105 | grep <span class="string">"Data"</span> | wc -l</span><br><span class="line"><span class="number">1674</span></span><br></pre></td></tr></table></figure>
<p>对应的MapTasks数量也是1674个:  </p>
<p><img src="http://img.blog.csdn.net/20151110094117060" alt="1674tasks"></p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">10</span> <span class="number">13</span>:<span class="number">31</span>:<span class="number">14</span>,<span class="number">255</span> INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: SSTableSplit&#123;</span><br><span class="line">    dataStart=<span class="number">0</span>, dataEnd=<span class="number">0</span>, idxStart=<span class="number">0</span>, length=<span class="number">11216024</span>, idxEnd=<span class="number">11216024</span>, </span><br><span class="line">    dataFile=hdfs:<span class="comment">//tdhdfs/user/qihuang.zheng/velocity_backup_1107/226_1105/94/forseti/velocity/forseti-velocity-jb-107404-Data.db, </span></span><br><span class="line">    hosts=null&#125;</span><br></pre></td></tr></table></figure>
<h3 id="顺序读取">顺序读取</h3><p>不正确地读取会报错Corrupt (negative) value, 必须key读完顺序地读取value.    </p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">10</span> <span class="number">17</span>:<span class="number">19</span>:<span class="number">01</span>,<span class="number">655</span> WARN [main] org<span class="class">.apache</span><span class="class">.hadoop</span><span class="class">.mapred</span><span class="class">.YarnChild</span>: Exception running child : org<span class="class">.apache</span><span class="class">.cassandra</span><span class="class">.io</span><span class="class">.sstable</span><span class="class">.CorruptSSTableException</span>: java<span class="class">.io</span><span class="class">.IOException</span>: Corrupt (negative) value length encountered</span><br><span class="line">        at com<span class="class">.fullcontact</span><span class="class">.cassandra</span><span class="class">.io</span><span class="class">.sstable</span><span class="class">.SSTableIdentityIterator</span><span class="class">.hasNext</span>(SSTableIdentityIterator<span class="class">.java</span>:<span class="number">134</span>)</span><br><span class="line">        at com<span class="class">.fullcontact</span><span class="class">.sstable</span><span class="class">.velocity</span><span class="class">.VelocityReadJobTest</span><span class="variable">$VelocityReadMapper</span>.<span class="function"><span class="title">map</span><span class="params">(VelocityReadJobTest.java:<span class="number">142</span>)</span></span></span><br><span class="line">        at com<span class="class">.fullcontact</span><span class="class">.sstable</span><span class="class">.velocity</span><span class="class">.VelocityReadJobTest</span><span class="variable">$VelocityReadMapper</span>.<span class="function"><span class="title">map</span><span class="params">(VelocityReadJobTest.java:<span class="number">111</span>)</span></span></span><br><span class="line">        at org<span class="class">.apache</span><span class="class">.hadoop</span><span class="class">.mapreduce</span><span class="class">.Mapper</span><span class="class">.run</span>(Mapper<span class="class">.java</span>:<span class="number">145</span>)</span><br><span class="line">        at org<span class="class">.apache</span><span class="class">.hadoop</span><span class="class">.mapred</span><span class="class">.MapTask</span><span class="class">.runNewMapper</span>(MapTask<span class="class">.java</span>:<span class="number">764</span>)</span><br><span class="line">        at org<span class="class">.apache</span><span class="class">.hadoop</span><span class="class">.mapred</span><span class="class">.MapTask</span><span class="class">.run</span>(MapTask<span class="class">.java</span>:<span class="number">340</span>)</span><br><span class="line">        at org<span class="class">.apache</span><span class="class">.hadoop</span><span class="class">.mapred</span><span class="class">.YarnChild</span>$<span class="number">2</span>.<span class="function"><span class="title">run</span><span class="params">(YarnChild.java:<span class="number">167</span>)</span></span></span><br><span class="line">        at java<span class="class">.security</span><span class="class">.AccessController</span><span class="class">.doPrivileged</span>(Native Method)</span><br><span class="line">        at javax<span class="class">.security</span><span class="class">.auth</span><span class="class">.Subject</span><span class="class">.doAs</span>(Subject<span class="class">.java</span>:<span class="number">415</span>)</span><br><span class="line">        at org<span class="class">.apache</span><span class="class">.hadoop</span><span class="class">.security</span><span class="class">.UserGroupInformation</span><span class="class">.doAs</span>(UserGroupInformation<span class="class">.java</span>:<span class="number">1556</span>)</span><br><span class="line">        at org<span class="class">.apache</span><span class="class">.hadoop</span><span class="class">.mapred</span><span class="class">.YarnChild</span><span class="class">.main</span>(YarnChild<span class="class">.java</span>:<span class="number">162</span>)</span><br><span class="line">Caused by: java<span class="class">.io</span><span class="class">.IOException</span>: Corrupt (negative) value length encountered</span><br><span class="line">        at org<span class="class">.apache</span><span class="class">.cassandra</span><span class="class">.utils</span><span class="class">.ByteBufferUtil</span><span class="class">.readWithLength</span>(ByteBufferUtil<span class="class">.java</span>:<span class="number">352</span>)</span><br><span class="line">        at org<span class="class">.apache</span><span class="class">.cassandra</span><span class="class">.db</span><span class="class">.ColumnSerializer</span><span class="class">.deserializeColumnBody</span>(ColumnSerializer<span class="class">.java</span>:<span class="number">110</span>)</span><br><span class="line">        at org<span class="class">.apache</span><span class="class">.cassandra</span><span class="class">.db</span><span class="class">.OnDiskAtom</span><span class="variable">$Serializer</span>.<span class="function"><span class="title">deserializeFromSSTable</span><span class="params">(OnDiskAtom.java:<span class="number">85</span>)</span></span></span><br><span class="line">        at org<span class="class">.apache</span><span class="class">.cassandra</span><span class="class">.db</span><span class="class">.Column</span>$<span class="number">1</span>.<span class="function"><span class="title">computeNext</span><span class="params">(Column.java:<span class="number">75</span>)</span></span></span><br><span class="line">        at org<span class="class">.apache</span><span class="class">.cassandra</span><span class="class">.db</span><span class="class">.Column</span>$<span class="number">1</span>.<span class="function"><span class="title">computeNext</span><span class="params">(Column.java:<span class="number">64</span>)</span></span></span><br><span class="line">        at com<span class="class">.google</span><span class="class">.common</span><span class="class">.collect</span><span class="class">.AbstractIterator</span><span class="class">.tryToComputeNext</span>(AbstractIterator<span class="class">.java</span>:<span class="number">143</span>)</span><br><span class="line">        at com<span class="class">.google</span><span class="class">.common</span><span class="class">.collect</span><span class="class">.AbstractIterator</span><span class="class">.hasNext</span>(AbstractIterator<span class="class">.java</span>:<span class="number">138</span>)</span><br><span class="line">        at com<span class="class">.fullcontact</span><span class="class">.cassandra</span><span class="class">.io</span><span class="class">.sstable</span><span class="class">.SSTableIdentityIterator</span><span class="class">.hasNext</span>(SSTableIdentityIterator<span class="class">.java</span>:<span class="number">128</span>)</span><br><span class="line">        ... <span class="number">10</span> more</span><br><span class="line"></span><br><span class="line">如果跳过某个key,value有时候会报莫名其妙的错误:  </span><br><span class="line"><span class="number">2015</span>-<span class="number">11</span>-<span class="number">10</span> <span class="number">15</span>:<span class="number">21</span>:<span class="number">38</span>,<span class="number">827</span> WARN [main] org<span class="class">.apache</span><span class="class">.hadoop</span><span class="class">.mapred</span><span class="class">.YarnChild</span>: Exception running child : java<span class="class">.lang</span><span class="class">.NullPointerException</span></span><br><span class="line">        at com<span class="class">.fullcontact</span><span class="class">.cassandra</span><span class="class">.io</span><span class="class">.sstable</span><span class="class">.SSTableIdentityIterator</span>.&lt;init&gt;(SSTableIdentityIterator<span class="class">.java</span>:<span class="number">106</span>)</span><br><span class="line">        at com<span class="class">.fullcontact</span><span class="class">.sstable</span><span class="class">.hadoop</span><span class="class">.mapreduce</span><span class="class">.SSTableRowRecordReader</span><span class="class">.getIdentityIterator</span>(SSTableRowRecordReader<span class="class">.java</span>:<span class="number">60</span>)</span><br><span class="line">        at com<span class="class">.fullcontact</span><span class="class">.sstable</span><span class="class">.hadoop</span><span class="class">.mapreduce</span><span class="class">.SSTableRowRecordReader</span><span class="class">.nextKeyValue</span>(SSTableRowRecordReader<span class="class">.java</span>:<span class="number">50</span>)</span><br></pre></td></tr></table></figure>
<p>注意过滤数据, 要保证SSTableIdentityIterator value必须正常读取, 即使这行数据是有问题的, 也只能等到最后context.write时做过滤  </p>
<h3 id="数据压缩">数据压缩</h3><p>是否压缩数据. 一个SSTable文件夹1G左右, 需要将近20分钟. 主要消耗在写入上. MapTask的读取是很快的. 但是写入涉及到IO.  </p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">不压缩, 耗时<span class="number">1079</span>s. 但是文件比较大, 原先<span class="number">160</span>M的SSTable, 输出大概<span class="number">300</span>-<span class="number">400</span>M,而且还是过滤后的数据.  </span><br><span class="line">[qihuang.zheng@spark047219 ~]$ hadoop fs -ls /user/qihuang.zheng/velocity_1110_09</span><br><span class="line">Found <span class="number">11</span> items</span><br><span class="line">-rw-r--r--   <span class="number">3</span> qihuang.zheng supergroup          <span class="number">0</span> <span class="number">2015</span>-<span class="number">11</span>-<span class="number">10</span> <span class="number">19</span>:<span class="number">50</span> /user/qihuang.zheng/velocity_1110_09/_SUCCESS</span><br><span class="line">-rw-r--r--   <span class="number">3</span> qihuang.zheng supergroup  <span class="number">373921332</span> <span class="number">2015</span>-<span class="number">11</span>-<span class="number">10</span> <span class="number">19</span>:<span class="number">36</span> /user/qihuang.zheng/velocity_1110_09/part-m-<span class="number">00000</span></span><br><span class="line">-rw-r--r--   <span class="number">3</span> qihuang.zheng supergroup  <span class="number">410870793</span> <span class="number">2015</span>-<span class="number">11</span>-<span class="number">10</span> <span class="number">19</span>:<span class="number">47</span> /user/qihuang.zheng/velocity_1110_09/part-m-<span class="number">00001</span></span><br><span class="line">-rw-r--r--   <span class="number">3</span> qihuang.zheng supergroup  <span class="number">443988024</span> <span class="number">2015</span>-<span class="number">11</span>-<span class="number">10</span> <span class="number">19</span>:<span class="number">49</span> /user/qihuang.zheng/velocity_1110_09/part-m-<span class="number">00002</span></span><br><span class="line">-rw-r--r--   <span class="number">3</span> qihuang.zheng supergroup  <span class="number">392285322</span> <span class="number">2015</span>-<span class="number">11</span>-<span class="number">10</span> <span class="number">19</span>:<span class="number">50</span> /user/qihuang.zheng/velocity_1110_09/part-m-<span class="number">00003</span></span><br><span class="line">-rw-r--r--   <span class="number">3</span> qihuang.zheng supergroup  <span class="number">283241237</span> <span class="number">2015</span>-<span class="number">11</span>-<span class="number">10</span> <span class="number">19</span>:<span class="number">45</span> /user/qihuang.zheng/velocity_1110_09/part-m-<span class="number">00004</span></span><br><span class="line">-rw-r--r--   <span class="number">3</span> qihuang.zheng supergroup  <span class="number">372702479</span> <span class="number">2015</span>-<span class="number">11</span>-<span class="number">10</span> <span class="number">19</span>:<span class="number">47</span> /user/qihuang.zheng/velocity_1110_09/part-m-<span class="number">00005</span></span><br><span class="line">-rw-r--r--   <span class="number">3</span> qihuang.zheng supergroup  <span class="number">429722009</span> <span class="number">2015</span>-<span class="number">11</span>-<span class="number">10</span> <span class="number">19</span>:<span class="number">48</span> /user/qihuang.zheng/velocity_1110_09/part-m-<span class="number">00006</span></span><br><span class="line">-rw-r--r--   <span class="number">3</span> qihuang.zheng supergroup  <span class="number">340998333</span> <span class="number">2015</span>-<span class="number">11</span>-<span class="number">10</span> <span class="number">19</span>:<span class="number">48</span> /user/qihuang.zheng/velocity_1110_09/part-m-<span class="number">00007</span></span><br><span class="line">-rw-r--r--   <span class="number">3</span> qihuang.zheng supergroup  <span class="number">372808096</span> <span class="number">2015</span>-<span class="number">11</span>-<span class="number">10</span> <span class="number">19</span>:<span class="number">48</span> /user/qihuang.zheng/velocity_1110_09/part-m-<span class="number">00008</span></span><br><span class="line">-rw-r--r--   <span class="number">3</span> qihuang.zheng supergroup  <span class="number">420902888</span> <span class="number">2015</span>-<span class="number">11</span>-<span class="number">10</span> <span class="number">19</span>:<span class="number">33</span> /user/qihuang.zheng/velocity_1110_09/part-m-<span class="number">00009</span></span><br><span class="line"></span><br><span class="line">[qihuang.zheng@spark047219 ~]$ hadoop fs -cat /user/qihuang.zheng/velocity_1110_09/part-m-<span class="number">0000</span>* | wc -l</span><br><span class="line"><span class="number">10133360</span></span><br><span class="line"></span><br><span class="line">压缩, 耗时<span class="number">1559</span>s, 每个文件只有<span class="number">50</span>M. 采用gzip压缩. 读取的时候也要注意用Gzip解压.  </span><br><span class="line">[qihuang.zheng@spark047219 ~]$ hadoop fs -ls /user/qihuang.zheng/velocity_1110_10</span><br><span class="line">Found <span class="number">11</span> items</span><br><span class="line">-rw-r--r--   <span class="number">3</span> qihuang.zheng supergroup          <span class="number">0</span> <span class="number">2015</span>-<span class="number">11</span>-<span class="number">10</span> <span class="number">20</span>:<span class="number">31</span> /user/qihuang.zheng/velocity_1110_10/_SUCCESS</span><br><span class="line">-rw-r--r--   <span class="number">3</span> qihuang.zheng supergroup   <span class="number">54538610</span> <span class="number">2015</span>-<span class="number">11</span>-<span class="number">10</span> <span class="number">20</span>:<span class="number">31</span> /user/qihuang.zheng/velocity_1110_10/part-m-<span class="number">00000</span></span><br><span class="line">-rw-r--r--   <span class="number">3</span> qihuang.zheng supergroup   <span class="number">57205003</span> <span class="number">2015</span>-<span class="number">11</span>-<span class="number">10</span> <span class="number">20</span>:<span class="number">17</span> /user/qihuang.zheng/velocity_1110_10/part-m-<span class="number">00001</span></span><br><span class="line">-rw-r--r--   <span class="number">3</span> qihuang.zheng supergroup   <span class="number">60537200</span> <span class="number">2015</span>-<span class="number">11</span>-<span class="number">10</span> <span class="number">20</span>:<span class="number">26</span> /user/qihuang.zheng/velocity_1110_10/part-m-<span class="number">00002</span></span><br><span class="line">-rw-r--r--   <span class="number">3</span> qihuang.zheng supergroup   <span class="number">54984406</span> <span class="number">2015</span>-<span class="number">11</span>-<span class="number">10</span> <span class="number">20</span>:<span class="number">09</span> /user/qihuang.zheng/velocity_1110_10/part-m-<span class="number">00003</span></span><br><span class="line">-rw-r--r--   <span class="number">3</span> qihuang.zheng supergroup   <span class="number">40164974</span> <span class="number">2015</span>-<span class="number">11</span>-<span class="number">10</span> <span class="number">20</span>:<span class="number">16</span> /user/qihuang.zheng/velocity_1110_10/part-m-<span class="number">00004</span></span><br><span class="line">-rw-r--r--   <span class="number">3</span> qihuang.zheng supergroup   <span class="number">53023012</span> <span class="number">2015</span>-<span class="number">11</span>-<span class="number">10</span> <span class="number">20</span>:<span class="number">23</span> /user/qihuang.zheng/velocity_1110_10/part-m-<span class="number">00005</span></span><br><span class="line">-rw-r--r--   <span class="number">3</span> qihuang.zheng supergroup   <span class="number">55805058</span> <span class="number">2015</span>-<span class="number">11</span>-<span class="number">10</span> <span class="number">20</span>:<span class="number">09</span> /user/qihuang.zheng/velocity_1110_10/part-m-<span class="number">00006</span></span><br><span class="line">-rw-r--r--   <span class="number">3</span> qihuang.zheng supergroup   <span class="number">48103013</span> <span class="number">2015</span>-<span class="number">11</span>-<span class="number">10</span> <span class="number">20</span>:<span class="number">21</span> /user/qihuang.zheng/velocity_1110_10/part-m-<span class="number">00007</span></span><br><span class="line">-rw-r--r--   <span class="number">3</span> qihuang.zheng supergroup   <span class="number">51533456</span> <span class="number">2015</span>-<span class="number">11</span>-<span class="number">10</span> <span class="number">20</span>:<span class="number">25</span> /user/qihuang.zheng/velocity_1110_10/part-m-<span class="number">00008</span></span><br><span class="line">-rw-r--r--   <span class="number">3</span> qihuang.zheng supergroup   <span class="number">56592220</span> <span class="number">2015</span>-<span class="number">11</span>-<span class="number">10</span> <span class="number">20</span>:<span class="number">07</span> /user/qihuang.zheng/velocity_1110_10/part-m-<span class="number">00009</span></span><br></pre></td></tr></table></figure>
<h3 id="其他">其他</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">/usr/<span class="operator"><span class="keyword">install</span>/hadoop/<span class="keyword">bin</span>/hadoop fs -ls /<span class="keyword">user</span>/qihuang.zheng/velocity_backup_1107/<span class="number">226</span>_1105 | wc -<span class="keyword">l</span></span><br><span class="line"></span><br><span class="line">清理测试文件夹:  </span><br><span class="line">/usr/<span class="keyword">install</span>/hadoop/<span class="keyword">bin</span>/hadoop fs -rmr /<span class="keyword">user</span>/qihuang.zheng/velocity_test*</span><br><span class="line"></span><br><span class="line">查看Task日志:  </span><br><span class="line">cd /home/<span class="keyword">admin</span>/<span class="keyword">output</span>/hadoop/<span class="keyword">logs</span>/ &amp;&amp; ll -rth &amp;&amp; sudo chmod <span class="number">777</span> -R application_1446983986550_0032 &amp;&amp; cd application_1446983986550_0032 &amp;&amp; ll </span><br><span class="line"></span><br><span class="line">查看运行中的作业以及杀死作业:  </span><br><span class="line">/usr/<span class="keyword">install</span>/hadoop/<span class="keyword">bin</span>/yarn application -<span class="keyword">kill</span> application_1446983986550_0035</span><br><span class="line">/usr/<span class="keyword">install</span>/hadoop/<span class="keyword">bin</span>/yarn application -<span class="keyword">list</span></span></span><br></pre></td></tr></table></figure>

      
    </div>
    
  </div>
  
    
<div class="copyright">
  <p><span>本文标题:</span><a href="/2015/11/18/2015-11-18-Hadoop-SSTable/">Cassandra Migration Tool(hadoop-sstable)</a></p>
  <p><span>文章作者:</span><a href="/" title="访问 任何忧伤,都抵不过世界的美丽 的个人博客">任何忧伤,都抵不过世界的美丽</a></p>
  <p><span>发布时间:</span>2015年11月18日 - 00时00分</p>
  <p><span>最后更新:</span>2015年12月19日 - 21时17分</p>
  <p>
    <span>原始链接:</span><a href="/2015/11/18/2015-11-18-Hadoop-SSTable/" title="Cassandra Migration Tool(hadoop-sstable)">http://github.com/zqhxuyuan/2015/11/18/2015-11-18-Hadoop-SSTable/</a>
    <span class="btn" data-clipboard-text="原文: http://github.com/zqhxuyuan/2015/11/18/2015-11-18-Hadoop-SSTable/　　作者: 任何忧伤,都抵不过世界的美丽" title="点击复制文章链接">
        <i class="fa fa-clipboard"></i>
    </span>
  </p>
  <p><span>许可协议:</span><i class="fa fa-creative-commons"></i> <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/3.0/cn/" title="中国大陆 (CC BY-NC-SA 3.0 CN)">"署名-非商用-相同方式共享 3.0"</a> 转载请保留原文链接及作者。</p>
  <script src="/js/clipboard.min.js"></script>
  <script> var clipboard = new Clipboard('.btn'); </script>
</div>
<style type="text/css">
  .copyright p .btn {
    margin-left: 1em;
  }
  .copyright:hover p .btn::after {
    content: "复制"
  }
  .copyright p .btn:hover {
      color: gray;
      cursor: pointer;
    };
</style>



<nav id="article-nav">
  
    <div id="article-nav-newer" class="article-nav-title">
      <a href="/2015/11/19/2015-11-19-Cassandra-Migration7_VelocityHadoop/">
        Cassandra数据迁移 分离表
      </a>
    </div>
  
  
    <div id="article-nav-older" class="article-nav-title">
      <a href="/2015/11/17/2015-11-17-Cassandra-BulkLoad/">
        Cassandra Migration Tool
      </a>
    </div>
  
</nav>

  
</article>

<!-- 默认显示文章目录，在文章---前输入toc: false关闭目录 -->
<!-- Show TOC and tocButton in default, Hide TOC via putting "toc: false" before "---" at [post].md -->
<div id="toc" class="toc-article">
<strong class="toc-title">文章目录</strong>
<ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#hadoop-sstable"><span class="toc-number">1.</span> <span class="toc-text">hadoop-sstable</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Shell$ExitCodeException"><span class="toc-number">1.1.</span> <span class="toc-text">Shell$ExitCodeException</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#yarn_log查看日志:_找不到cassandra-all的jar包"><span class="toc-number">1.2.</span> <span class="toc-text">yarn log查看日志: 找不到cassandra-all的jar包</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#cassandra/lib下的jar包"><span class="toc-number">1.3.</span> <span class="toc-text">cassandra/lib下的jar包</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#yarn_log日志打印不出来,_是/user/history权限问题"><span class="toc-number">1.4.</span> <span class="toc-text">yarn log日志打印不出来, 是/user/history权限问题</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#guava版本问题"><span class="toc-number">1.5.</span> <span class="toc-text">guava版本问题</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#JSON解析异常"><span class="toc-number">1.6.</span> <span class="toc-text">JSON解析异常</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#添加Mapper的日志和查看Map日志"><span class="toc-number">1.7.</span> <span class="toc-text">添加Mapper的日志和查看Map日志</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Cassandra类型的验证"><span class="toc-number">1.8.</span> <span class="toc-text">Cassandra类型的验证</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#直接将ByteBuffer转换为字符串,_而不使用C*的类型转换"><span class="toc-number">1.9.</span> <span class="toc-text">直接将ByteBuffer转换为字符串, 而不使用C*的类型转换</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#VelocityRead2Write测试"><span class="toc-number">1.10.</span> <span class="toc-text">VelocityRead2Write测试</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#CFMetaData-comparator"><span class="toc-number">1.11.</span> <span class="toc-text">CFMetaData.comparator</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Too_Many_Tasks"><span class="toc-number">1.12.</span> <span class="toc-text">Too Many Tasks</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#顺序读取"><span class="toc-number">1.13.</span> <span class="toc-text">顺序读取</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#数据压缩"><span class="toc-number">1.14.</span> <span class="toc-text">数据压缩</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#其他"><span class="toc-number">1.15.</span> <span class="toc-text">其他</span></a></li></ol></li></ol>
</div>
<style type="text/css">
  .left-col .switch-btn {
    display: none;
  }
  .left-col .switch-area {
    display: none;
  }
</style>

<input type="button" id="tocButton" value="隐藏目录"  title="点击按钮隐藏或者显示文章目录">
<script type="text/javascript">
  var toc_button= document.getElementById("tocButton");
  var toc_div= document.getElementById("toc");
  /* Show or hide toc when click on tocButton.
  通过点击设置的按钮显示或者隐藏文章目录.*/
  toc_button.onclick=function(){
  if(toc_div.style.display=="none"){
  toc_div.style.display="block";
  toc_button.value="隐藏目录";
  document.getElementById("switch-btn").style.display="none";
  document.getElementById("switch-area").style.display="none";
  }
  else{
  toc_div.style.display="none";
  toc_button.value="显示目录";
  document.getElementById("switch-btn").style.display="block";
  document.getElementById("switch-area").style.display="block";
  }
  }
</script>


<div class="share">
	<div class="bdsharebuttonbox">
	<a href="#" class="bds_more" data-cmd="more"></a>
	<a href="#" class="bds_tsina" data-cmd="tsina" title="分享到新浪微博"></a>
	<a href="#" class="bds_sqq" data-cmd="sqq" title="分享给 QQ 好友"></a>
	<a href="#" class="bds_copy" data-cmd="copy" title="复制网址"></a>
	<a href="#" class="bds_mail" data-cmd="mail" title="通过邮件分享"></a>
	<a href="#" class="bds_weixin" data-cmd="weixin" title="生成文章二维码"></a>
	</div>
	<script>
	window._bd_share_config={
		"common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"0","bdSize":"24"},"share":{}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];
	</script>
</div>







    <style type="text/css">
    #scroll {
      display: none;
    }
    </style>
    <div class="scroll">
    <a href="#" title="返回顶部"><i class="fa fa-arrow-up"></i></a>
    <a href="#comments" title="查看评论"><i class="fa fa-comments-o"></i></a>
    <a href="#footer" title="转到底部"><i class="fa fa-arrow-down"></i></a>
    </div>


  
  
    
    <div  class="post-nav-button">
    <a href="/2015/11/19/2015-11-19-Cassandra-Migration7_VelocityHadoop/" title="上一篇: Cassandra数据迁移 分离表">
    <i class="fa fa-angle-left"></i>
    </a>
    <a href="/2015/11/17/2015-11-17-Cassandra-BulkLoad/" title="下一篇: Cassandra Migration Tool">
    <i class="fa fa-angle-right"></i>
    </a>
    </div>
  



    
        <link rel="stylesheet" href="/fancybox/jquery.fancybox.css" type="text/css">
        <script>
        var yiliaConfig = {
        fancybox: true,
        mathjax: true,
        animate: true,
        isHome: false,
        isPost: true,
        isArchive: false,
        isTag: false,
        isCategory: false,
        open_in_new: false
        }
        </script>
        
</div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
      <div class="footer-left">
        &copy; 2015 任何忧伤,都抵不过世界的美丽
      </div>
        <div class="footer-right">
          <a href="http://hexo.io/" target="_blank" title="快速、简洁且高效的静态博客框架">Hexo</a>  Theme <a href="https://github.com/MOxFIVE/hexo-theme-yelee" target="_blank" title="简而不减双栏 Hexo 博客主题">Yelee</a> by MOxFIVE
        </div>
    </div>
    <div class="visit">
      <span id="busuanzi_container_site_pv" style='display:none'>
        <span id="site-visit" >本站到访数: 
        <span id="busuanzi_value_site_uv"></span>
        </span>
      </span>
      <span id="busuanzi_container_page_pv" style='display:none'>
        <span id="page-visit">, 本页阅读量: 
        <span id="busuanzi_value_page_pv"></span>
        </span>
      </span>
    </div>
  </div>
</footer>
    </div>
    

<script src="http://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js" type="text/javascript"></script>
<script src="/js/main.js" type="text/javascript"></script>

<script>
  var backgroundnum = 5;
  var backgroundimg = "url(/background/bg-x.jpg)".replace(/x/gi, Math.ceil(Math.random() * backgroundnum));

  $("body").css({"background": backgroundimg, "background-attachment": "fixed", "background-size": "cover"});
</script>




<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<div class="scroll" id="scroll">
<a href="#" title="返回顶部"><i class="fa fa-arrow-up"></i></a>
<a href="#footer" title="转到底部"><i class="fa fa-arrow-down"></i></a>
</div>

<script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>
  </div>
</body>
</html>