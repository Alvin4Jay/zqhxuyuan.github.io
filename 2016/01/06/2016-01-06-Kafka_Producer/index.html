<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Kafka源码分析 Producer客户端 | zqhxuyuan</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Kafka的Producer新旧客户端API实现">
<meta property="og:type" content="article">
<meta property="og:title" content="Kafka源码分析 Producer客户端">
<meta property="og:url" content="http://github.com/zqhxuyuan/2016/01/06/2016-01-06-Kafka_Producer/index.html">
<meta property="og:site_name" content="zqhxuyuan">
<meta property="og:description" content="Kafka的Producer新旧客户端API实现">
<meta property="og:image" content="http://img.blog.csdn.net/20160119164949035">
<meta property="og:image" content="http://img.blog.csdn.net/20160119170630760">
<meta property="og:image" content="http://img.blog.csdn.net/20160119225630114">
<meta property="og:image" content="http://img.blog.csdn.net/20160119231458355">
<meta property="og:image" content="http://img.blog.csdn.net/20160119232024826">
<meta property="og:image" content="http://img.blog.csdn.net/20160120093720907">
<meta property="og:image" content="http://img.blog.csdn.net/20160120101250639">
<meta property="og:image" content="http://img.blog.csdn.net/20160120111819367">
<meta property="og:image" content="http://img.blog.csdn.net/20160120115614118">
<meta property="og:image" content="http://img.blog.csdn.net/20160120120921467">
<meta property="og:image" content="http://kafka.apache.org/images/producer_consumer.png">
<meta property="og:updated_time" content="2016-01-20T04:09:35.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Kafka源码分析 Producer客户端">
<meta name="twitter:description" content="Kafka的Producer新旧客户端API实现">
  
    <link rel="alternative" href="/atom.xml" title="zqhxuyuan" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link rel="stylesheet" href="/css/style.css" type="text/css">
  <link rel="stylesheet" href="/font-awesome/css/font-awesome.min.css">
  <link rel="apple-touch-icon" href="/apple-touch-icon.png">
</head>
<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			
			<img lazy-src="https://avatars1.githubusercontent.com/u/1088525?v=3&amp;s=180" class="js-avatar">
			
		</a>

		<hgroup>
		  <h1 class="header-author"><a href="/">任何忧伤,都抵不过世界的美丽</a></h1>
		</hgroup>

		
				


		
			<div id="switch-btn" class="switch-btn">
				<div class="icon">
					<div class="icon-ctn">
						<div class="icon-wrap icon-house" data-idx="0">
							<div class="birdhouse"></div>
							<div class="birdhouse_holes"></div>
						</div>
						<div class="icon-wrap icon-ribbon hide" data-idx="1">
							<div class="ribbon"></div>
						</div>
						
						
						<div class="icon-wrap icon-me hide" data-idx="3">
							<div class="user"></div>
							<div class="shoulder"></div>
						</div>
						
					</div>
					
				</div>
				<div class="tips-box hide">
					<div class="tips-arrow"></div>
					<ul class="tips-inner">
						<li>菜单</li>
						<li>标签</li>
						
						
						<li>关于我</li>
						
					</ul>
				</div>
			</div>
		

		<div id="switch-area" class="switch-area">
			<div class="switch-wrap">
				<section class="switch-part switch-part1">
					<nav class="header-menu">
						<ul>
						
							<li><a href="/">主页</a></li>
				        
							<li><a href="/archives/">归档</a></li>
				        
							<li><a href="/tags/">标签</a></li>
				        
							<li><a href="/about/">关于</a></li>
				        
						</ul>
					</nav>
					<nav class="header-nav">
						<ul class="social">
							
								<li id="新浪微博"><a class="新浪微博" target="_blank" href="http://weibo.com/xuyuantree" title="新浪微博"></a></li>
					        
								<li id="GitHub"><a class="GitHub" target="_blank" href="http://github.com/zqhxuyuan" title="GitHub"></a></li>
					        
						</ul>
					</nav>
				</section>
				
				
				<section class="switch-part switch-part2">
					<div class="widget tagcloud" id="js-tagcloud">
						<a href="/tags/apex/" style="font-size: 10px;">apex</a> <a href="/tags/cassandra/" style="font-size: 18.33px;">cassandra</a> <a href="/tags/clojure/" style="font-size: 10px;">clojure</a> <a href="/tags/drill/" style="font-size: 18.33px;">drill</a> <a href="/tags/druid/" style="font-size: 15px;">druid</a> <a href="/tags/elasticsearch/" style="font-size: 10px;">elasticsearch</a> <a href="/tags/geode/" style="font-size: 10px;">geode</a> <a href="/tags/hbase/" style="font-size: 16.67px;">hbase</a> <a href="/tags/ignite/" style="font-size: 10px;">ignite</a> <a href="/tags/kafka/" style="font-size: 20px;">kafka</a> <a href="/tags/scala/" style="font-size: 13.33px;">scala</a> <a href="/tags/spark/" style="font-size: 15px;">spark</a> <a href="/tags/storm/" style="font-size: 16.67px;">storm</a> <a href="/tags/timeseries/" style="font-size: 13.33px;">timeseries</a> <a href="/tags/translate/" style="font-size: 10px;">translate</a> <a href="/tags/work/" style="font-size: 11.67px;">work</a>
					</div>
				</section>
				
				
				

				
				
				<section class="switch-part switch-part3">
				
					<div id="js-aboutme">BIG(DATA)</div>
				</section>
				
			</div>
		</div>
	</header>				
</div>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
  	<div class="overlay">
  		<div class="slider-trigger"></div>
  		<h1 class="header-author js-mobile-header hide"><a href="/" title="回到主页">任何忧伤,都抵不过世界的美丽</a></h1>
  	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<a href="/" class="profilepic">
				<img lazy-src="https://avatars1.githubusercontent.com/u/1088525?v=3&amp;s=180" class="js-avatar">
			</a>
			<hgroup>
			  <h1 class="header-author"><a href="/" title="回到主页">任何忧伤,都抵不过世界的美丽</a></h1>
			</hgroup>
			
			<nav class="header-menu">
				<ul>
				
					<li><a href="/">主页</a></li>
		        
					<li><a href="/archives/">归档</a></li>
		        
					<li><a href="/tags/">标签</a></li>
		        
					<li><a href="/about/">关于</a></li>
		        
		        <div class="clearfix"></div>
				</ul>
			</nav>
			<nav class="header-nav">
						<ul class="social">
							
								<li id="新浪微博"><a class="新浪微博" target="_blank" href="http://weibo.com/xuyuantree" title="新浪微博"></a></li>
					        
								<li id="GitHub"><a class="GitHub" target="_blank" href="http://github.com/zqhxuyuan" title="GitHub"></a></li>
					        
						</ul>
			</nav>
		</header>				
	</div>
</nav>
      <div class="body-wrap"><article id="post-2016-01-06-Kafka_Producer" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/01/06/2016-01-06-Kafka_Producer/" class="article-date">
  	<time datetime="2016-01-05T16:00:00.000Z" itemprop="datePublished">2016-01-06</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Kafka源码分析 Producer客户端
    </h1>
  

      </header>
      
      <div class="article-info article-info-post">
        
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/Source/">Source</a>
	</div>


        
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/kafka/">kafka</a></li></ul>
	</div>

        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <p>Kafka的Producer新旧客户端API实现<br><a id="more"></a></p>
<h2 id="Producer">Producer</h2><p>生产者线程:异步发送消息,提供一个Callback;同步发送消息,则调用Future.get()会Block住直到结果返回.  </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Producer</span> <span class="keyword">extends</span> <span class="title">Thread</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> KafkaProducer&lt;Integer, String&gt; producer;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> String topic;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Boolean isAsync;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Producer</span><span class="params">(String topic, Boolean isAsync)</span> </span>&#123;</span><br><span class="line">        Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">        props.put(<span class="string">"bootstrap.servers"</span>, <span class="string">"localhost:9092"</span>);</span><br><span class="line">        props.put(<span class="string">"client.id"</span>, <span class="string">"DemoProducer"</span>);</span><br><span class="line">        props.put(<span class="string">"key.serializer"</span>, <span class="string">"org.apache.kafka.common.serialization.IntegerSerializer"</span>);</span><br><span class="line">        props.put(<span class="string">"value.serializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</span><br><span class="line">        producer = <span class="keyword">new</span> KafkaProducer&lt;Integer, String&gt;(props);</span><br><span class="line">        <span class="keyword">this</span>.topic = topic;</span><br><span class="line">        <span class="keyword">this</span>.isAsync = isAsync;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> messageNo = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">            String messageStr = <span class="string">"Message_"</span> + messageNo;</span><br><span class="line">            <span class="keyword">if</span> (isAsync) &#123;  <span class="comment">// Send asynchronously</span></span><br><span class="line">                producer.send(<span class="keyword">new</span> ProducerRecord&lt;Integer, String&gt;(topic, messageNo, messageStr), </span><br><span class="line">                    <span class="keyword">new</span> Callback() &#123;</span><br><span class="line">                        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onCompletion</span><span class="params">(RecordMetadata metadata, Exception e)</span> </span>&#123;</span><br><span class="line">                            System.out.println(<span class="string">"The offset of the record we just sent is: "</span> + metadata.offset());</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                );</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;        <span class="comment">// Send synchronously</span></span><br><span class="line">                producer.send(<span class="keyword">new</span> ProducerRecord&lt;Integer, String&gt;(topic, messageNo, messageStr)).get();</span><br><span class="line">            &#125;</span><br><span class="line">            ++messageNo;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>KafkaProducer需要指定消息Key,Value的类型<integer,string>. ProducerRecord还需要指定topic.</integer,string></li>
<li>根据配置文件创建KafkaProducer, 指定了Broker地址, Key,Value的序列化方式, 消息必须要指定topic</li>
<li>发送消息的返回结果RecordMetadata记录元数据包括了消息的offset(在哪个partition的哪里offset)</li>
</ul>
<p><img src="http://img.blog.csdn.net/20160119164949035" alt="k_producer_client"></p>
<h3 id="blocking_vs_non-blocking">blocking vs non-blocking</h3><p>KafkaProducer.send方法返回的是一个Future,那么它如何同时实现blocking方式和non-blocking方式.  </p>
<ul>
<li>blocking: 在调用send返回Future时, 立即调用get, 因为Future.get在没有返回结果时会一直阻塞</li>
<li>non-block: 提供一个callback,调用send后,可以继续发送消息而不用等待.当有结果返回时,callback会被自动通知执行</li>
</ul>
<p><img src="http://img.blog.csdn.net/20160119170630760" alt="k_future"></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Future&lt;RecordMetadata&gt; <span class="title">send</span><span class="params">(ProducerRecord&lt;K, V&gt; record, Callback callback)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// first make sure the metadata for the topic is available</span></span><br><span class="line">    <span class="keyword">long</span> waitedOnMetadataMs = waitOnMetadata(record.topic(), <span class="keyword">this</span>.maxBlockTimeMs);</span><br><span class="line">    <span class="keyword">long</span> remainingWaitMs = Math.max(<span class="number">0</span>, <span class="keyword">this</span>.maxBlockTimeMs - waitedOnMetadataMs);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 序列化key和value</span></span><br><span class="line">    <span class="keyword">byte</span>[] serializedKey= keySerializer.serialize(record.topic(), record.key());</span><br><span class="line">    <span class="keyword">byte</span>[] serializedValue = valueSerializer.serialize(record.topic(), record.value());</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 选择这条消息的Partition</span></span><br><span class="line">    <span class="keyword">int</span> partition = partition(record, serializedKey, serializedValue, metadata.fetch());</span><br><span class="line">    TopicPartition tp = <span class="keyword">new</span> TopicPartition(record.topic(), partition);</span><br><span class="line">    RecordAccumulator.RecordAppendResult result = accumulator.append(tp, serializedKey, serializedValue, callback, remainingWaitMs);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 在每次追加一条消息到收集器之后,都要判断是否满了.如果满了,就执行一次Sender操作,通知Sender将这批数据发送到Kafka</span></span><br><span class="line">    <span class="keyword">if</span> (result.batchIsFull || result.newBatchCreated) <span class="keyword">this</span>.sender.wakeup();</span><br><span class="line">    <span class="keyword">return</span> result.future;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="http://img.blog.csdn.net/20160119225630114" alt="k_send"></p>
<p>在发送消息前,消息所属的topic必须已经建好,并且也指定这个topic的partition数量(没有指定则默认是server.properties的<code>num.partitions</code>).  </p>
<figure class="highlight brainfuck"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">bin/kafka</span><span class="literal">-</span><span class="comment">topics</span><span class="string">.</span><span class="comment">sh</span> <span class="literal">-</span><span class="literal">-</span><span class="comment">create</span> <span class="literal">-</span><span class="literal">-</span><span class="comment">zookeeper</span> <span class="comment">localhost:2181</span> <span class="literal">-</span><span class="literal">-</span><span class="comment">replication</span><span class="literal">-</span><span class="comment">factor</span> <span class="comment">3</span> <span class="literal">-</span><span class="literal">-</span><span class="comment">partitions</span> <span class="comment">10</span> <span class="literal">-</span><span class="literal">-</span><span class="comment">topic</span> <span class="comment">test</span></span><br></pre></td></tr></table></figure>
<p>所以<code>Topic</code>,<code>Partition</code>,<code>Key</code>,<code>Value</code>组合起来就能表示<code>消息</code>发送到哪个<code>topic</code>的哪个<code>partition</code>上.  </p>
<h3 id="partition">partition</h3><p>一个Partition的主要组成部分是topic名称,partition编号,所在的Leader,所有的副本,isr列表.表示这个Partition的分布情况.  </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">public <span class="class"><span class="keyword">class</span> <span class="title">PartitionInfo</span> &#123;</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="type">String</span> topic;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> int partition;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="type">Node</span> leader;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="type">Node</span>[] replicas;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="type">Node</span>[] inSyncReplicas;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>下图是kafka-manager中某个topic的PartitionInfo信息(副本数=4,Broker数量刚好也是4,导致每个Partition都分布在所有Broker上).  </p>
<p><img src="http://img.blog.csdn.net/20160119231458355" alt="k_partitioninfo"></p>
<p>在Cluster的构造函数中, 会根据所有节点和所有partitions构建集群状态信息.availablePartitions只保存有Leader的Partition.  </p>
<blockquote>
<p>正常来说每个Partition都是有Leader Partition的. 如果Partition没有Leader的话,说明这个Partition就是有问题的.  </p>
</blockquote>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">List</span>&lt;<span class="type">PartitionInfo</span>&gt; availablePartitions = <span class="keyword">new</span> <span class="type">ArrayList</span>&lt;&gt;();</span><br><span class="line"><span class="keyword">for</span> (<span class="type">PartitionInfo</span> part : partitionList) &#123;</span><br><span class="line">    <span class="keyword">if</span> (part.leader() != <span class="literal">null</span>)</span><br><span class="line">        availablePartitions.add(part);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">this</span>.availablePartitionsByTopic.put(topic, <span class="type">Collections</span>.unmodifiableList(availablePartitions));</span><br></pre></td></tr></table></figure>
<p>要选择消息所属的partition,首先需要知道topic一共有多少个partition(numPartitions),<br>所以metadata.fetch获得的Cluster信息中有topic-&gt;partitions的映射关系(partitionsByTopic).  </p>
<p>消息有key的话,对key进行hash,然后和partitions数量取模,类似于round-robin的方式来确定key所在的partition达到负载均衡.<br>如果消息没有key, 会根据递增的counter的值确定partition, count不断递增,确保消息不会都发到同一个partition里.  </p>
<blockquote>
<p>问题: 写入消息时是写到Leader Partition的话,下面的代码如何体现Leader?<br>答案: 实际上为消息选择Partition,只是为了负载均衡, 跟Leader没有多大关系.<br>因为一个PartitionInfo一定能确定一个唯一的Leader(一个Partition只有一个Leader)<br>如果一个topic只有一个Partition的话,在集群环境下就不能水平扩展:这个topic的消息只能写到一个节点.<br>而为一个topic设置多个Partition,可以同时往多个节点的多个Partition写数据.<br>注意: 多个Partition都是同一个topic的,每个Partition的逻辑意义都是相同的,只是物理位置不同而已.    </p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">partition</span><span class="params">(String topic, Object key, <span class="keyword">byte</span>[] keyBytes, Object value, <span class="keyword">byte</span>[] valueBytes, Cluster cluster)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 这个topic所有的partitions. 用来负载均衡, 即Leader Partition不要都分布在同一台机器上</span></span><br><span class="line">    List&lt;PartitionInfo&gt; partitions = cluster.partitionsForTopic(topic);</span><br><span class="line">    <span class="keyword">int</span> numPartitions = partitions.size();</span><br><span class="line">    <span class="keyword">if</span> (keyBytes == <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">int</span> nextValue = counter.getAndIncrement();</span><br><span class="line">        <span class="comment">// 这个topic可以使用的partitions: availablePartitionsByTopic</span></span><br><span class="line">        List&lt;PartitionInfo&gt; availablePartitions = cluster.availablePartitionsForTopic(topic);</span><br><span class="line">        <span class="keyword">if</span> (availablePartitions.size() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">int</span> part = DefaultPartitioner.toPositive(nextValue) % availablePartitions.size();</span><br><span class="line">            <span class="keyword">return</span> availablePartitions.get(part).partition();</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// no partitions are available, give a non-available partition</span></span><br><span class="line">            <span class="keyword">return</span> DefaultPartitioner.toPositive(nextValue) % numPartitions;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// hash the keyBytes to choose a partition</span></span><br><span class="line">        <span class="keyword">return</span> DefaultPartitioner.toPositive(Utils.murmur2(keyBytes)) % numPartitions;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>下图是partition的分布算法.topic1有4个partition. 则总共有4个对应的PartitionInfo对象.<br>每个PartitionInfo(比如topic1-part1)都有唯一的Partition编号(1),replicas(1,2,3).  </p>
<blockquote>
<p>注意:replicas并不是一个PartitionInfo对象,它们仅仅是某个Partition编号对应的PartitionInfo的replicas信息.<br>即partitionsForTopic和availablePartitionsForTopic里面其实是没有follower replics的.<br>因为如果Replicas都算作PartitionInfo的话, 则Partition编号就不好表示了(4个Partition,每个Partition由3个副本).  </p>
<p>实际上在选择Partition的时候,根本就先不要考虑replicas的存在. 就只有Partition编号.<br>每个Partition是分布在不同的节点上的(可以把这个Partition就认为是Leader Partition).<br>然后在写消息的时候采用round-robin方式将消息平均负载到每一个Partition上.<br>假设第一条消息写到了topic1-part1,则下一条消息就写到topic1-part2,以此类推.  </p>
</blockquote>
<p><img src="http://img.blog.csdn.net/20160119232024826" alt="k_partition_algs"></p>
<h3 id="RecordAccumulator">RecordAccumulator</h3><p>由于生产者发送消息是异步地,所以可以将多条消息缓存起来,等到一定时机批量地写入到Kafka集群中,RecordAccumulator就扮演了缓冲者的角色.<br>生产者每生产一条消息,就向accumulator中追加一条消息,并且要返回本次追加是否导致batch满了,如果batch满了,则开始发送这一批数据.<br>最开始以为<code>Deque&lt;RecordBatch&gt;</code>就是一个消息队列,实际上<code>一批消息</code>会首先放在<code>RecordBatch</code>中,然后Batch又放在<code>双端队列</code>中.  </p>
<p><img src="http://img.blog.csdn.net/20160120093720907" alt="k_batches"></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> RecordAppendResult <span class="title">append</span><span class="params">(TopicPartition tp, <span class="keyword">byte</span>[] key, <span class="keyword">byte</span>[] value, Callback callback, <span class="keyword">long</span> maxTimeToBlock)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">    Deque&lt;RecordBatch&gt; dq = dequeFor(tp);</span><br><span class="line">    <span class="keyword">synchronized</span> (dq) &#123;</span><br><span class="line">        RecordBatch last = dq.peekLast();</span><br><span class="line">        <span class="keyword">if</span> (last != <span class="keyword">null</span>) &#123;</span><br><span class="line">            FutureRecordMetadata future = last.tryAppend(key, value, callback, time.milliseconds());</span><br><span class="line">            <span class="comment">// 有旧的batch, 并且能往这个batch继续追加消息</span></span><br><span class="line">            <span class="keyword">if</span> (future != <span class="keyword">null</span>) <span class="keyword">return</span> <span class="keyword">new</span> RecordAppendResult(future, dq.size() &gt; <span class="number">1</span> || last.records.isFull(), <span class="keyword">false</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 队列为空(没有一个RecordBatch,last=null), 或者新的RecordBatch为空(旧的Batch没有空间了,future=null), 则新分配一个Batch</span></span><br><span class="line">    <span class="keyword">int</span> size = Math.max(<span class="keyword">this</span>.batchSize, Records.LOG_OVERHEAD + Record.recordSize(key, value));</span><br><span class="line">    ByteBuffer buffer = free.allocate(size, maxTimeToBlock);</span><br><span class="line">    <span class="keyword">synchronized</span> (dq) &#123;</span><br><span class="line">        <span class="comment">// 内存的ByteBuffer, 追加新消息时,会最终写到这个ByteBuffer中</span></span><br><span class="line">        MemoryRecords records = MemoryRecords.emptyRecords(buffer, compression, <span class="keyword">this</span>.batchSize);</span><br><span class="line">        RecordBatch batch = <span class="keyword">new</span> RecordBatch(tp, records, time.milliseconds());</span><br><span class="line">        FutureRecordMetadata future = Utils.notNull(batch.tryAppend(key, value, callback, time.milliseconds()));</span><br><span class="line">        dq.addLast(batch);</span><br><span class="line">        incomplete.add(batch);</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> RecordAppendResult(future, dq.size() &gt; <span class="number">1</span> || batch.records.isFull(), <span class="keyword">true</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>batches是一个并发安全的,但是每个TopicPartition里的ArrayDeque并不是线程安全的,所以在修改Deque时都需要同步块操作.<br>队列中只要有一个以上的batch(dq.size),或者追加了这条消息后,当前Batch中的记录满了(batch.records),就可以发送消息了.   </p>
<p><img src="http://img.blog.csdn.net/20160120101250639" alt="k_deque"></p>
<p>RecordBatch的tryAppend判断MemoryRecords是否能容纳下新的消息,如果可以就追加,如果没有空间返回null,让调用者自己新建一个Batch.<br>所以一个RecordBatch只对应了一个MemoryRecords. 而一个MemoryRecords可以存放至多maxRecordSize大小的消息.  </p>
<blockquote>
<p>注意: 客户端传递的Callback是在这里和消息一起被加入的. 但是因为生产者是批量地写数据,所以回调函数是在一批数据完成后才被调用</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> FutureRecordMetadata <span class="title">tryAppend</span><span class="params">(<span class="keyword">byte</span>[] key, <span class="keyword">byte</span>[] value, Callback callback, <span class="keyword">long</span> now)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">boolean</span> roomEnough = <span class="keyword">this</span>.records.hasRoomFor(key, value)</span><br><span class="line">    <span class="keyword">if</span>(!roomEnough) <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">this</span>.records.append(<span class="number">0L</span>, key, value);</span><br><span class="line">    <span class="keyword">this</span>.maxRecordSize = Math.max(<span class="keyword">this</span>.maxRecordSize, Record.recordSize(key, value));</span><br><span class="line">    FutureRecordMetadata future = <span class="keyword">new</span> FutureRecordMetadata(<span class="keyword">this</span>.produceFuture, <span class="keyword">this</span>.recordCount);</span><br><span class="line">    <span class="keyword">if</span> (callback != <span class="keyword">null</span>) thunks.add(<span class="keyword">new</span> Thunk(callback, future));</span><br><span class="line">    <span class="keyword">this</span>.recordCount++;</span><br><span class="line">    <span class="keyword">return</span> future;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>思考:为什么追加数据的offset固定是0? 实际上由于消息之间都是独立的,一条消息自己是无法确定自己的offset的. 那么offset是怎么管理的?</p>
</blockquote>
<p>在Sender线程开始运行之前,首先要找到<code>每个PartitionInfo的Leader节点</code>,由RecordAccumulator统一收集已经准备好的节点.  </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> ReadyCheckResult <span class="title">ready</span><span class="params">(Cluster cluster, <span class="keyword">long</span> nowMs)</span> </span>&#123;</span><br><span class="line">    Set&lt;Node&gt; readyNodes = <span class="keyword">new</span> HashSet&lt;Node&gt;();</span><br><span class="line">    <span class="comment">// batches: 每个TopicPartition都对应了一个双端队列</span></span><br><span class="line">    <span class="keyword">for</span> (Map.Entry&lt;TopicPartition, Deque&lt;RecordBatch&gt;&gt; entry : <span class="keyword">this</span>.batches.entrySet()) &#123;</span><br><span class="line">        TopicPartition part = entry.getKey();</span><br><span class="line">        Deque&lt;RecordBatch&gt; deque = entry.getValue();</span><br><span class="line">        <span class="comment">// 找出这个TopicPartition的Leader节点, 在正式开始发送消息时, 会先建立到这些节点的连接</span></span><br><span class="line">        Node leader = cluster.leaderFor(part);</span><br><span class="line">        <span class="keyword">if</span> (leader == <span class="keyword">null</span>) &#123;</span><br><span class="line">            unknownLeadersExist = <span class="keyword">true</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (!readyNodes.contains(leader)) &#123;</span><br><span class="line">            <span class="keyword">synchronized</span> (deque) &#123;</span><br><span class="line">                RecordBatch batch = deque.peekFirst();</span><br><span class="line">                <span class="keyword">if</span> (batch != <span class="keyword">null</span>) &#123;</span><br><span class="line">                    <span class="keyword">boolean</span> sendable = full || expired || exhausted || closed || flushInProgress();</span><br><span class="line">                    <span class="keyword">if</span> (sendable &amp;&amp; !backingOff) &#123;</span><br><span class="line">                        <span class="comment">// 加入到等待连接的节点中. </span></span><br><span class="line">                        readyNodes.add(leader);</span><br><span class="line">                    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                        nextReadyCheckDelayMs = Math.min(timeLeftMs, nextReadyCheckDelayMs);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> ReadyCheckResult(readyNodes, nextReadyCheckDelayMs, unknownLeadersExist);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>数据有生产就会有被消费的地方,对应Deque队列的话,将RecordBatch加入,就有对应的pollFirst获取并删除第一个batch.<br>由于在生产数据的时候,每个TopicPartition都有自己的队列,并且都统一被收集到了RecordAccumulator的batches中.<br>在消费数据的时候,最好对batches中的每个TopicPartition重新整理成以Node节点为级别,对后面的发送流程是有很大帮助的.  </p>
<p><img src="http://img.blog.csdn.net/20160120111819367" alt="k_ready_drain"></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> Map&lt;Integer, List&lt;RecordBatch&gt;&gt; drain(Cluster cluster, Set&lt;Node&gt; nodes, <span class="keyword">int</span> maxSize, <span class="keyword">long</span> now) &#123;</span><br><span class="line">    Map&lt;Integer, List&lt;RecordBatch&gt;&gt; batches = <span class="keyword">new</span> HashMap&lt;Integer, List&lt;RecordBatch&gt;&gt;();</span><br><span class="line">    <span class="keyword">for</span> (Node node : nodes) &#123;</span><br><span class="line">        <span class="keyword">int</span> size = <span class="number">0</span>;</span><br><span class="line">        List&lt;PartitionInfo&gt; parts = cluster.partitionsForNode(node.id());  <span class="comment">// 节点上所有的Partition</span></span><br><span class="line">        List&lt;RecordBatch&gt; ready = <span class="keyword">new</span> ArrayList&lt;RecordBatch&gt;(); <span class="comment">// 用来保存这个节点的Batch</span></span><br><span class="line">        <span class="keyword">int</span> start = drainIndex = drainIndex % parts.size();     <span class="comment">// 为了不被饿死,start并不是从0开始. 初始时,start=drainIndex</span></span><br><span class="line">        do &#123;</span><br><span class="line">            PartitionInfo part = parts.get(drainIndex);</span><br><span class="line">            Deque&lt;RecordBatch&gt; deque = dequeFor(<span class="keyword">new</span> TopicPartition(part.topic(), part.partition()));</span><br><span class="line">            <span class="keyword">if</span> (deque != <span class="keyword">null</span>) &#123;                                <span class="comment">// 并不是所有的Partition都有队列的             </span></span><br><span class="line">                <span class="keyword">synchronized</span> (deque) &#123;                          <span class="comment">// 队列不是线程安全的,需要同步块</span></span><br><span class="line">                    RecordBatch first = deque.peekFirst();      <span class="comment">// Batch加入到队列的时候是加到尾部, 拉取Batch时则从头部, 所以叫做双端队列嘛</span></span><br><span class="line">                    <span class="keyword">if</span> (first != <span class="keyword">null</span>) &#123;</span><br><span class="line">                        RecordBatch batch = deque.pollFirst();  <span class="comment">// 上面并没有把Batch从队列中删除, 如果这个Batch真的可以被消费,才真正删除(在first后做了一些判断,这里省略了)</span></span><br><span class="line">                        batch.records.close();                  <span class="comment">// 释放内存</span></span><br><span class="line">                        ready.add(batch);                       <span class="comment">// 添加到待发送列表中</span></span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">this</span>.drainIndex = (<span class="keyword">this</span>.drainIndex + <span class="number">1</span>) % parts.size();</span><br><span class="line">        &#125; <span class="keyword">while</span> (start != drainIndex);                          <span class="comment">// 直到遍历完这个节点所有的Partition,说明这个节点不会有其他的Partition了,可以放心地退出循环</span></span><br><span class="line"></span><br><span class="line">        batches.put(node.id(), ready);                          <span class="comment">// Batch是以Node为级别的.表示这个Node可以接受一批的RecordBatch. 因为每个RecordBatch的Partition都是无序的.</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> batches;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="Sender">Sender</h3><p>RecordAccumulator.RecordAppendResult的batch满了,唤醒Sender线程.Sender线程的启动在创建KafkaProducer时.<br>Sender再唤醒NetworkClient(不是线程,相当于通知客户端开始服务了),client也唤醒Selector,最终唤醒NIO的Selector.  </p>
<blockquote>
<p>为什么需要有wakeup动作:因为可能有线程在select等待事件被阻塞了(没有事件),通过wakeup唤醒那个线程开始工作(有事件进来了)</p>
</blockquote>
<p>Sender不仅承载了RecordAccumulator记录的收集器,也要通知客户端服务:把Accumulator收集的批记录通过客户端发送出去.<br>Sender作为一个线程,是在后台不断运行的,如果线程被停止,可能RecordAccumulator中还有数据没有发送出去,所以要优雅地停止.  </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (running) &#123;</span><br><span class="line">        run(time.milliseconds());</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">while</span> (!forceClose &amp;&amp; (<span class="keyword">this</span>.accumulator.hasUnsent() || <span class="keyword">this</span>.client.inFlightRequestCount() &gt; <span class="number">0</span>)) &#123;</span><br><span class="line">        run(time.milliseconds());</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">this</span>.client.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>发送消息的工作统一由Sender来控制.之前的wakeup只是一个通知,实际的工作还是由线程的run方法来控制的.<br>同样调用client.send也只是把请求先放到队列中, client.poll才是会将读写真正发送到socket链路上.  </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">(<span class="keyword">long</span> now)</span> </span>&#123;</span><br><span class="line">    Cluster cluster = metadata.fetch();</span><br><span class="line">    <span class="comment">// ① get the list of partitions with data ready to send</span></span><br><span class="line">    RecordAccumulator.ReadyCheckResult result = <span class="keyword">this</span>.accumulator.ready(cluster, now);</span><br><span class="line">    <span class="comment">// ② remove any nodes we aren't ready to send to  建立到Leader的Socket连接</span></span><br><span class="line">    Iterator&lt;Node&gt; iter = result.readyNodes.iterator();</span><br><span class="line">    <span class="keyword">long</span> notReadyTimeout = Long.MAX_VALUE;</span><br><span class="line">    <span class="keyword">while</span> (iter.hasNext()) &#123;</span><br><span class="line">        Node node = iter.next();</span><br><span class="line">        <span class="keyword">if</span> (!<span class="keyword">this</span>.client.ready(node, now)) &#123;  </span><br><span class="line">            iter.remove();</span><br><span class="line">            notReadyTimeout = Math.min(notReadyTimeout, <span class="keyword">this</span>.client.connectionDelay(node, now));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// ③ create produce requests 之前加入到了accumulator收集器中, 现在从收集器获取出最开始放入的消息</span></span><br><span class="line">    Map&lt;Integer, List&lt;RecordBatch&gt;&gt; batches = <span class="keyword">this</span>.accumulator.drain(cluster, result.readyNodes, <span class="keyword">this</span>.maxRequestSize, now);</span><br><span class="line">    <span class="comment">// ④ Transfer the record batches into a list of produce requests on a per-node basis 以节点为级别的生产请求列表. 即每个节点只有一个ClientRequest</span></span><br><span class="line">    List&lt;ClientRequest&gt; requests = createProduceRequests(batches, now);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">long</span> pollTimeout = Math.min(result.nextReadyCheckDelayMs, notReadyTimeout);</span><br><span class="line">    <span class="comment">// ⑤ Queue up the given request for sending. Requests can only be sent out to ready nodes. 从注释中可以看出这是一个入队列的操作</span></span><br><span class="line">    <span class="keyword">for</span> (ClientRequest request : requests) client.send(request, now);</span><br><span class="line">    <span class="comment">// ⑥ Do actual reads and writes to sockets. 这里才是真正的读写操作</span></span><br><span class="line">    <span class="keyword">this</span>.client.poll(pollTimeout, now);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>accumulator在之前一直append数据,到真正要发送一批数据时,先①准备(ready)需要发送的partitions到哪些Nodes上,②并建立到节点的连接<br>然后③构造每个Node需要的RecordBatch列表(一个节点同时可以接受多批数据),④并转换为客户端的请求ClientRequest.  </p>
<p><img src="http://img.blog.csdn.net/20160120115614118" alt="k_sender_run"></p>
<p>由于batches已经是按照节点划分好的了,所以创建的客户端请求也是按照节点划分好了.不过虽然produceRequest方法中的batches<br>是某个节点所有的batches,但是客户端请求面向的还是Partition级别! 所以要对batches重新按照Partition的粒度整理.  </p>
<blockquote>
<p>问题: batches中会不会有相同的Partition? 不会的! 如果那样的话,两个Map的key因为都是Partition,会导致value被覆盖.但是怎么保证?  </p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> ClientRequest <span class="title">produceRequest</span><span class="params">(<span class="keyword">long</span> now, <span class="keyword">int</span> destination, <span class="keyword">short</span> acks, <span class="keyword">int</span> timeout, List&lt;RecordBatch&gt; batches)</span> </span>&#123;</span><br><span class="line">    Map&lt;TopicPartition, ByteBuffer&gt; produceRecordsByPartition = <span class="keyword">new</span> HashMap&lt;TopicPartition, ByteBuffer&gt;(batches.size());</span><br><span class="line">    <span class="keyword">final</span> Map&lt;TopicPartition, RecordBatch&gt; recordsByPartition = <span class="keyword">new</span> HashMap&lt;TopicPartition, RecordBatch&gt;(batches.size());</span><br><span class="line">    <span class="keyword">for</span> (RecordBatch batch : batches) &#123;</span><br><span class="line">        TopicPartition tp = batch.topicPartition;                   <span class="comment">// 每个RecordBatch都有唯一的TopicPartition</span></span><br><span class="line">        produceRecordsByPartition.put(tp, batch.records.buffer());  <span class="comment">// RecordBatch的records是MemoryRecords,底层是ByteBuffer</span></span><br><span class="line">        recordsByPartition.put(tp, batch);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 构造生产者的请求(每个Partition都有生产记录), 并指定目标节点,请求头和请求内容, 转换为发送请求对象</span></span><br><span class="line">    ProduceRequest request = <span class="keyword">new</span> ProduceRequest(acks, timeout, produceRecordsByPartition);</span><br><span class="line">    RequestSend send = <span class="keyword">new</span> RequestSend(Integer.toString(destination), <span class="keyword">this</span>.client.nextRequestHeader(ApiKeys.PRODUCE), request.toStruct());</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 回调函数会作为客户端请求的一个成员变量, 当客户端请求完成后, 会触发回调函数的执行!</span></span><br><span class="line">    RequestCompletionHandler callback = <span class="keyword">new</span> RequestCompletionHandler() &#123;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onComplete</span><span class="params">(ClientResponse response)</span> </span>&#123;</span><br><span class="line">            handleProduceResponse(response, recordsByPartition, time.milliseconds());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> ClientRequest(now, acks != <span class="number">0</span>, send, callback);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>ProduceRequest是Producer的生产请求,需要acks和timeout这两个参数,在后面的DelayedOperation中会用到.  </p>
</blockquote>
<h4 id="ClientRequest_&amp;_ClientResponse">ClientRequest &amp; ClientResponse</h4><p>ClientRequest是客户端的请求,这个请求会被发送(Send)到服务器上,所以它包装的是RequestSend<br>ClientResponse是客户端的响应,也需要ClientRequest是因为请求有返回值时响应要和请求对的上.<br>由于Callback是附加在Request里的,为了让Response能够触发Callback回调,将Request设置到Response.  </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// A request being sent to the server. This holds both the network send as well as the client-level metadata.</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">ClientRequest</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">long</span> createdTimeMs;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">boolean</span> expectResponse;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> RequestSend request;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> RequestCompletionHandler callback;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">boolean</span> isInitiatedByNetworkClient;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> sendTimeMs;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// A response from the server. Contains both the body of the response as well as the correlated request that was originally sent.</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ClientResponse</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">long</span> receivedTimeMs;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">boolean</span> disconnected;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> ClientRequest request;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Struct responseBody;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="Callback">Callback</h4><p>回调函数传给了ClientRequest客户端请求,当客户端真正发生读写后(poll),会产生ClientResponse对象,触发回调函数的执行.<br>因为回调对象RequestCompletionHandler的回调方法onComplete的参数是ClientResponse.<br>NetworkClient.poll是真正发生读写的地方,所以它也会负责生成客户端的响应信息.  </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> List&lt;ClientResponse&gt; <span class="title">poll</span><span class="params">(<span class="keyword">long</span> timeout, <span class="keyword">long</span> now)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// .....真正的读写操作, 会生成responses</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// invoke callbacks</span></span><br><span class="line">    <span class="keyword">for</span> (ClientResponse response : responses) &#123;</span><br><span class="line">        <span class="keyword">if</span> (response.request().hasCallback()) &#123;</span><br><span class="line">            response.request().callback().onComplete(response);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> responses;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="http://img.blog.csdn.net/20160120120921467" alt="k_req_callback"></p>
<h4 id="handleProduceResponse">handleProduceResponse</h4><h3 id="NetworkClient">NetworkClient</h3><p>send动作将ClientRequest添加到队列inFlightRequests用来缓冲请求,<br>然后触发Selector-&gt;KafkaChannel-&gt;transportLayer添加<code>OP_WRITE</code>写事件通知<br>poll动作也将实际处理交给Selector,客户端服务于读和写,即发送和接收. </p>
<blockquote>
<p>注意doSend不只是用于Producer发送,也可以用于Consumer消费.参数ClientRequest表示客户端的请求.<br>对于Kafka而言,P和C都是客户端.客户端发送请求给Kafka,从Kafka这方来说,都要Receive读取请求.<br>实际上KafkaProducer和KafkaConsumer都有NetworkClient,说明客户端是嵌入在P和C里面的.  </p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">doSend</span><span class="params">(ClientRequest request, <span class="keyword">long</span> now)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.inFlightRequests.add(request);             <span class="comment">//还没开始真正发送,先加入到队列中</span></span><br><span class="line">    selector.send(request.request());               <span class="comment">//标记下收到的是Send请求</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> List&lt;ClientResponse&gt; <span class="title">poll</span><span class="params">(<span class="keyword">long</span> timeout, <span class="keyword">long</span> now)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">long</span> metadataTimeout = metadataUpdater.maybeUpdate(now);</span><br><span class="line">    <span class="keyword">this</span>.selector.poll(Utils.min(timeout, metadataTimeout, requestTimeoutMs));</span><br><span class="line"></span><br><span class="line">    <span class="comment">// process completed actions</span></span><br><span class="line">    <span class="keyword">long</span> updatedNow = <span class="keyword">this</span>.time.milliseconds();</span><br><span class="line">    List&lt;ClientResponse&gt; responses = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">    handleCompletedSends(responses, updatedNow);    <span class="comment">//完成发送的handler</span></span><br><span class="line">    handleCompletedReceives(responses, updatedNow); <span class="comment">//完成接收的handler</span></span><br><span class="line">    handleDisconnections(responses, updatedNow);    <span class="comment">//断开连接的handler</span></span><br><span class="line">    handleConnections();                            <span class="comment">//处理连接的handler</span></span><br><span class="line">    handleTimedOutRequests(responses, updatedNow);  <span class="comment">//超时请求的handler</span></span><br><span class="line">    <span class="comment">// invoke callbacks</span></span><br><span class="line">    <span class="keyword">for</span> (ClientResponse response : responses) &#123;     <span class="comment">//触发回调函数的调用</span></span><br><span class="line">        <span class="keyword">if</span> (response.request().hasCallback()) &#123;</span><br><span class="line">            response.request().callback().onComplete(response);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> responses;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Selector在每次轮询调用之后,都会触发读写请求的完成handler,并添加到responses,用于回调函数的参数.<br>不管是Send发送请求还是NetworkReceive接受请求,都可以被转换为ClientRequest表示客户端的请求.  </p>
<blockquote>
<p>Send请求的destination, NetworkReceive的source都表示远程的Kafka节点.<br>因为在P和C的一亩三分地里, NetworkClient是它们和远程服务器交互的中间介质.  </p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Handle any completed request send. In particular if no response is expected consider the request complete.</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">handleCompletedSends</span><span class="params">(List&lt;ClientResponse&gt; responses, <span class="keyword">long</span> now)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// if no response is expected then when the send is completed, return it</span></span><br><span class="line">    <span class="keyword">for</span> (Send send : <span class="keyword">this</span>.selector.completedSends()) &#123;</span><br><span class="line">        ClientRequest request = <span class="keyword">this</span>.inFlightRequests.lastSent(send.destination());</span><br><span class="line">        <span class="comment">// 如果不需要响应,当Send请求完成时,就直接返回. 只有需要响应,才...</span></span><br><span class="line">        <span class="keyword">if</span> (!request.expectResponse()) &#123;</span><br><span class="line">            <span class="keyword">this</span>.inFlightRequests.completeLastSent(send.destination());</span><br><span class="line">            responses.add(<span class="keyword">new</span> ClientResponse(request, now, <span class="keyword">false</span>, <span class="keyword">null</span>));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Handle any completed receives and update the response list with the responses received.</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">handleCompletedReceives</span><span class="params">(List&lt;ClientResponse&gt; responses, <span class="keyword">long</span> now)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (NetworkReceive receive : <span class="keyword">this</span>.selector.completedReceives()) &#123;</span><br><span class="line">        String source = receive.source();</span><br><span class="line">        ClientRequest req = inFlightRequests.completeNext(source);</span><br><span class="line"></span><br><span class="line">        ResponseHeader header = ResponseHeader.parse(receive.payload());</span><br><span class="line">        <span class="comment">// Always expect the response version id to be the same as the request version id</span></span><br><span class="line">        <span class="keyword">short</span> apiKey = req.request().header().apiKey();</span><br><span class="line">        <span class="keyword">short</span> apiVer = req.request().header().apiVersion();</span><br><span class="line">        Struct body = ProtoUtils.responseSchema(apiKey, apiVer).read(receive.payload());</span><br><span class="line">        correlate(req.request().header(), header);</span><br><span class="line">        <span class="keyword">if</span> (!metadataUpdater.maybeHandleCompletedReceive(req, now, body))</span><br><span class="line">            responses.add(<span class="keyword">new</span> ClientResponse(req, now, <span class="keyword">false</span>, body));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>客户端发送请求后,处理handleCompletedSends,并不会将ClientRequest从inFlightRequests中移除.<br>因为inFlightRequests表示的是还没有收到响应的客户端请求,才发送请求,肯定还没收到响应,所以不会移除.  </p>
<p>收到响应是在handleCompletedReceives,这时候才可以调用completeNext删除source对应的ClientRequest<br>因为客户端响应ClientResponse除了header和payload(响应内容),还有ClientRequest,<br>所以要将inFlightRequests删除的那个ClientRequest和ClientResponse附带的ClientRequest进行比较.  </p>
<p><strong>InFlightRequests</strong>  </p>
<p>表示已经发送,或正在发送. 并且还没有收到响应的(客户端)请求. 请求首先加入到队列中.  </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">add</span><span class="params">(ClientRequest request)</span> </span>&#123;</span><br><span class="line">    Deque&lt;ClientRequest&gt; reqs = <span class="keyword">this</span>.requests.get(request.request().destination());</span><br><span class="line">    <span class="keyword">if</span> (reqs == <span class="keyword">null</span>) &#123;</span><br><span class="line">        reqs = <span class="keyword">new</span> ArrayDeque&lt;&gt;();</span><br><span class="line">        <span class="keyword">this</span>.requests.put(request.request().destination(), reqs);</span><br><span class="line">    &#125;</span><br><span class="line">    reqs.addFirst(request);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>requests Map的key是request.request().destination(),表示这个请求要发送到哪个Broker节点上.<br>所以从这里也可以看出,现在的作用域都只是在客户端,因为只有客户端才有目标节点destination.<br>如果是Kafka作为服务端,只需要和SocketChannel通信即可(客户端连接服务端,在服务端建立到客户端的连接)  </p>
<p>Deque是个双端队列,可以往头和尾方便地添加/删除/获取ClientRequest.  </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//Get the oldest request (the one that that will be completed next) for the given node</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> ClientRequest <span class="title">completeNext</span><span class="params">(String node)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> requestQueue(node).pollLast();</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// Get the last request we sent to the given node (but don't remove it from the queue)</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> ClientRequest <span class="title">lastSent</span><span class="params">(String node)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> requestQueue(node).peekFirst();</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// Complete the last request that was sent to a particular node.</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> ClientRequest <span class="title">completeLastSent</span><span class="params">(String node)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> requestQueue(node).pollFirst();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="Selector">Selector</h3><p>轮询的策略是如果有数据(timeout=0)直接调用nioSelector.selectNow,否则每隔一定时间触发一次select调用.<br>绑定到SelectionKey上的是KafkaChannel,基于Kafka的传输层TransportLayer包含了IO通信的SelectionKey,SocketChannel  </p>
<blockquote>
<p>poll轮询.一次轮询调用是不断地while循环,如果数据没有处理完,则SelectionKey的事件不会被注销</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">poll</span><span class="params">(<span class="keyword">long</span> timeout)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    clear();</span><br><span class="line">    <span class="keyword">if</span> (hasStagedReceives()) timeout = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">int</span> readyKeys = select(timeout);                <span class="comment">//选择器,触发立即调用,或者定时调用</span></span><br><span class="line">    <span class="keyword">if</span> (readyKeys &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        Set&lt;SelectionKey&gt; keys = <span class="keyword">this</span>.nioSelector.selectedKeys();</span><br><span class="line">        Iterator&lt;SelectionKey&gt; iter = keys.iterator();</span><br><span class="line">        <span class="keyword">while</span> (iter.hasNext()) &#123;</span><br><span class="line">            SelectionKey key = iter.next();</span><br><span class="line">            iter.remove();</span><br><span class="line">            KafkaChannel channel = channel(key);    <span class="comment">//获得绑定到SelectionKey的通道</span></span><br><span class="line">            <span class="comment">/* complete any connections that have finished their handshake */</span></span><br><span class="line">            <span class="keyword">if</span> (key.isConnectable()) channel.finishConnect();</span><br><span class="line">            <span class="comment">/* if channel is not ready finish prepare */</span></span><br><span class="line">            <span class="keyword">if</span> (channel.isConnected() &amp;&amp; !channel.ready()) channel.prepare();</span><br><span class="line"></span><br><span class="line">            <span class="comment">/* if channel is ready read from any connections that have readable data */</span></span><br><span class="line">            <span class="keyword">if</span> (channel.ready() &amp;&amp; key.isReadable() &amp;&amp; !hasStagedReceive(channel)) &#123;</span><br><span class="line">                NetworkReceive networkReceive;</span><br><span class="line">                <span class="keyword">while</span> ((networkReceive = channel.read()) != <span class="keyword">null</span>)</span><br><span class="line">                    addToStagedReceives(channel, networkReceive);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">/* if channel is ready write to any sockets that have space in their buffer and for which we have data */</span></span><br><span class="line">            <span class="keyword">if</span> (channel.ready() &amp;&amp; key.isWritable()) &#123;</span><br><span class="line">                Send send = channel.write();</span><br><span class="line">                <span class="keyword">if</span> (send != <span class="keyword">null</span>) <span class="keyword">this</span>.completedSends.add(send);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">/* cancel any defunct sockets */</span></span><br><span class="line">            <span class="keyword">if</span> (!key.isValid()) close(channel);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    addToCompletedReceives();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>对于生产者而言,RequestSend注册了OP_WRITE,所以发生在KafkaChannel的SelectionKey是Writable事件.<br>如果是消费者,要拉取数据,则客户端会接收到Readable事件. 读取将NetworkReceive添加到stagedReceives<br>写操作会将当前发送的Send加入到completedSends. 在最后会将stagedReceives添加到completedReceives  </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">addToCompletedReceives</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">this</span>.stagedReceives.size() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        Iterator&lt;Map.Entry&lt;KafkaChannel, Deque&lt;NetworkReceive&gt;&gt;&gt; iter = <span class="keyword">this</span>.stagedReceives.entrySet().iterator();</span><br><span class="line">        <span class="keyword">while</span> (iter.hasNext()) &#123;</span><br><span class="line">            Map.Entry&lt;KafkaChannel, Deque&lt;NetworkReceive&gt;&gt; entry = iter.next();</span><br><span class="line">            KafkaChannel channel = entry.getKey();</span><br><span class="line">            <span class="keyword">if</span> (!channel.isMute()) &#123;</span><br><span class="line">                Deque&lt;NetworkReceive&gt; deque = entry.getValue();</span><br><span class="line">                NetworkReceive networkReceive = deque.poll();</span><br><span class="line">                <span class="keyword">this</span>.completedReceives.add(networkReceive);</span><br><span class="line">                <span class="keyword">if</span> (deque.size() == <span class="number">0</span>) iter.remove();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>completedSends和completedReceives分别表示在Selector端已经发送的和接收到的请求.<br>它们会在NetworkClient的poll调用之后被不同的handleCompleteXXX使用.  </p>
<h3 id="KafkaChannel">KafkaChannel</h3><p>write()方法会使用之前doSend方法设置的RequestSend(继承ByteBufferSend)作为send的参数,向传输层通道写数据  </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">send</span><span class="params">(Send send)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    send.writeTo(transportLayer);       <span class="comment">//transportLayer有SocketChannel,所以是真正发生写的地方</span></span><br><span class="line">    <span class="keyword">if</span> (send.completed())               <span class="comment">//只有Sender说没有数据需要写了,才对transportLayer取消WRITE事件</span></span><br><span class="line">        transportLayer.removeInterestOps(SelectionKey.OP_WRITE);</span><br><span class="line">    <span class="keyword">return</span> send.completed();            <span class="comment">//如果Sender说还没完成,则SelectionKey还会监听到Writable事件的</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setSend</span><span class="params">(Send send)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.send = send;</span><br><span class="line">    <span class="keyword">this</span>.transportLayer.addInterestOps(SelectionKey.OP_WRITE);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="OldProducer">OldProducer</h2><p>core下也有Producer和Consumer.scala, 和clients中的KafkaProducer,KafkaConsumer有什么区别?<br>从ConsoleProducer看到两种不同的实现:OldProducer-&gt;scala的Producer,NewShinyProducer-&gt;KafkaProducer</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> producer = <span class="keyword">if</span>(config.useOldProducer) &#123;</span><br><span class="line">    <span class="keyword">new</span> <span class="type">OldProducer</span>(getOldProducerProps(config))</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">new</span> <span class="type">NewShinyProducer</span>(getNewProducerProps(config))</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>旧的Producer消息用KeyedMessage,新的用ProducerRecord.不同的Producer实现,用trait定义共同的send接口.</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">trait</span> <span class="title">BaseProducer</span> &#123;</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">send</span>(</span>topic: <span class="type">String</span>, key: <span class="type">Array</span>[<span class="type">Byte</span>], value: <span class="type">Array</span>[<span class="type">Byte</span>])</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">close</span>(</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>用scala实现的Producer构造方式是一样的,需要指定分区方式,Key,Value的序列化.如果是异步还有一个发送线程.  </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Producer</span>[</span><span class="type">K</span>,<span class="type">V</span>](<span class="keyword">val</span> config: <span class="type">ProducerConfig</span>, <span class="keyword">private</span> <span class="keyword">val</span> eventHandler: <span class="type">EventHandler</span>[<span class="type">K</span>,<span class="type">V</span>]) <span class="keyword">extends</span> <span class="type">Logging</span> &#123;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> queue = <span class="keyword">new</span> <span class="type">LinkedBlockingQueue</span>[<span class="type">KeyedMessage</span>[<span class="type">K</span>,<span class="type">V</span>]](config.queueBufferingMaxMessages)</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> producerSendThread: <span class="type">ProducerSendThread</span>[<span class="type">K</span>,<span class="type">V</span>] = <span class="literal">null</span></span><br><span class="line">  config.producerType <span class="keyword">match</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="string">"sync"</span> =&gt;</span><br><span class="line">    <span class="keyword">case</span> <span class="string">"async"</span> =&gt;</span><br><span class="line">      sync = <span class="literal">false</span></span><br><span class="line">      producerSendThread = <span class="keyword">new</span> <span class="type">ProducerSendThread</span>[<span class="type">K</span>,<span class="type">V</span>](<span class="string">"ProducerSendThread-"</span>+config.clientId, queue, eventHandler,config.queueBufferingMaxMs, config.batchNumMessages, config.clientId)</span><br><span class="line">      producerSendThread.start()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">this</span>(</span>config: <span class="type">ProducerConfig</span>) = <span class="keyword">this</span>(config, <span class="keyword">new</span> <span class="type">DefaultEventHandler</span>[<span class="type">K</span>,<span class="type">V</span>](config,</span><br><span class="line">                                      <span class="type">CoreUtils</span>.createObject[<span class="type">Partitioner</span>](config.partitionerClass, config.props),</span><br><span class="line">                                      <span class="type">CoreUtils</span>.createObject[<span class="type">Encoder</span>[<span class="type">V</span>]](config.serializerClass, config.props),</span><br><span class="line">                                      <span class="type">CoreUtils</span>.createObject[<span class="type">Encoder</span>[<span class="type">K</span>]](config.keySerializerClass, config.props),</span><br><span class="line">                                      <span class="keyword">new</span> <span class="type">ProducerPool</span>(config)))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>同步发送消息直接调用事件处理器, 异步发送消息则会加入到阻塞队列BlockingQueue,<br>通过后台ProducerSendThread线程完成异步发送,类似于KafkaProducer的Sender线程  </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">send</span>(</span>messages: <span class="type">KeyedMessage</span>[<span class="type">K</span>,<span class="type">V</span>]*) &#123;</span><br><span class="line">  lock synchronized &#123;</span><br><span class="line">    sync <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="literal">true</span> =&gt; eventHandler.handle(messages)</span><br><span class="line">      <span class="keyword">case</span> <span class="literal">false</span> =&gt; asyncSend(messages)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>同时注意ProducerSendThread线程处理消息也是通过事件处理器eventHandler的,当然少不了阻塞队列queue.  </p>
<h3 id="ProducerSendThread">ProducerSendThread</h3><p>批处理的方式是在每次从queue中poll一条消息,先加入到一个数组events中,并在每次加入之后判断是否超过batchSize.<br>如果超过batchSize,则进行一次批处理,同时重置events数组和设置最后一次发送的时间.最后还需要有一次handl处理.  </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">processEvents</span>(</span>) &#123;</span><br><span class="line">  <span class="keyword">var</span> lastSend = <span class="type">SystemTime</span>.milliseconds</span><br><span class="line">  <span class="keyword">var</span> events = <span class="keyword">new</span> <span class="type">ArrayBuffer</span>[<span class="type">KeyedMessage</span>[<span class="type">K</span>,<span class="type">V</span>]]</span><br><span class="line">  <span class="keyword">var</span> full: <span class="type">Boolean</span> = <span class="literal">false</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// drain the queue until you get a shutdown command</span></span><br><span class="line">  <span class="type">Iterator</span>.continually(queue.poll(scala.math.max(<span class="number">0</span>, (lastSend + queueTime) - <span class="type">SystemTime</span>.milliseconds), <span class="type">TimeUnit</span>.<span class="type">MILLISECONDS</span>))</span><br><span class="line">                    .takeWhile(item =&gt; <span class="keyword">if</span>(item != <span class="literal">null</span>) item ne shutdownCommand <span class="keyword">else</span> <span class="literal">true</span>).foreach &#123;</span><br><span class="line">    currentQueueItem =&gt;</span><br><span class="line">      <span class="keyword">val</span> expired = currentQueueItem == <span class="literal">null</span></span><br><span class="line">      <span class="keyword">if</span>(currentQueueItem != <span class="literal">null</span>) &#123;</span><br><span class="line">        events += currentQueueItem    <span class="comment">// 加入到临时数组中</span></span><br><span class="line">      &#125; </span><br><span class="line">      full = events.size &gt;= batchSize <span class="comment">// check if the batch size is reached</span></span><br><span class="line">      <span class="keyword">if</span>(full || expired) &#123;           <span class="comment">// 除了batch满了,还可能是没有消息了     </span></span><br><span class="line">        tryToHandle(events)           <span class="comment">// 开始批处理</span></span><br><span class="line">        events = <span class="keyword">new</span> <span class="type">ArrayBuffer</span>[<span class="type">KeyedMessage</span>[<span class="type">K</span>,<span class="type">V</span>]]</span><br><span class="line">      &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  tryToHandle(events)                 <span class="comment">// send the last batch of events</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="DefaultEventHandler">DefaultEventHandler</h3><p>事件处理器首先序列化,然后通过dispatchSerializedData发送消息,这里还带了重试发送功能.  </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">handle</span>(</span>events: <span class="type">Seq</span>[<span class="type">KeyedMessage</span>[<span class="type">K</span>,<span class="type">V</span>]]) &#123;</span><br><span class="line">  <span class="keyword">val</span> serializedData = serialize(events)</span><br><span class="line">  <span class="keyword">var</span> outstandingProduceRequests = serializedData</span><br><span class="line">  <span class="keyword">var</span> remainingRetries = config.messageSendMaxRetries + <span class="number">1</span></span><br><span class="line">  <span class="keyword">while</span> (remainingRetries &gt; <span class="number">0</span> &amp;&amp; outstandingProduceRequests.size &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    outstandingProduceRequests = dispatchSerializedData(outstandingProduceRequests)</span><br><span class="line">    <span class="keyword">if</span> (outstandingProduceRequests.size &gt; <span class="number">0</span>) &#123;</span><br><span class="line">      remainingRetries -= <span class="number">1</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>为什么要重新组织数据,因为消息发送到Kafka集群,根据分配的partition,落到不同的节点(写到partition的Leader节点)<br>通过将乱序的消息按照BrokerId进行分组,这样可以将属于某个Broker的消息一次性发送过去.Int就是BrokerId/NodeId.  </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">partitionAndCollate</span>(</span>messages: <span class="type">Seq</span>[<span class="type">KeyedMessage</span>[<span class="type">K</span>,<span class="type">Message</span>]]): <span class="type">Option</span>[<span class="type">Map</span>[<span class="type">Int</span>, collection.mutable.<span class="type">Map</span>[<span class="type">TopicAndPartition</span>, <span class="type">Seq</span>[<span class="type">KeyedMessage</span>[<span class="type">K</span>,<span class="type">Message</span>]]]]] = &#123;</span><br><span class="line">    <span class="keyword">val</span> ret = <span class="keyword">new</span> <span class="type">HashMap</span>[<span class="type">Int</span>, collection.mutable.<span class="type">Map</span>[<span class="type">TopicAndPartition</span>, <span class="type">Seq</span>[<span class="type">KeyedMessage</span>[<span class="type">K</span>,<span class="type">Message</span>]]]]</span><br><span class="line">    <span class="keyword">for</span> (message &lt;- messages) &#123;</span><br><span class="line">      <span class="comment">//一个topic有多个partition</span></span><br><span class="line">      <span class="keyword">val</span> topicPartitionsList = getPartitionListForTopic(message)</span><br><span class="line">      <span class="comment">//一条消息只会写到一个partition</span></span><br><span class="line">      <span class="keyword">val</span> partitionIndex = getPartition(message.topic, message.partitionKey, topicPartitionsList)</span><br><span class="line">      <span class="comment">//一个partition因为有副本,所以有多个broker,但是写的时候只写到Leader</span></span><br><span class="line">      <span class="keyword">val</span> brokerPartition = topicPartitionsList(partitionIndex)</span><br><span class="line">      <span class="comment">// postpone the failure until the send operation, so that requests for other brokers are handled correctly</span></span><br><span class="line">      <span class="keyword">val</span> leaderBrokerId = brokerPartition.leaderBrokerIdOpt.getOrElse(-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">      <span class="comment">// 每个Broker的data,即组织成一个Broker对应多条消息    </span></span><br><span class="line">      <span class="keyword">var</span> dataPerBroker: <span class="type">HashMap</span>[<span class="type">TopicAndPartition</span>, <span class="type">Seq</span>[<span class="type">KeyedMessage</span>[<span class="type">K</span>,<span class="type">Message</span>]]] = <span class="literal">null</span></span><br><span class="line">      ret.get(leaderBrokerId) <span class="keyword">match</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> <span class="type">Some</span>(element) =&gt;</span><br><span class="line">          dataPerBroker = element.asInstanceOf[<span class="type">HashMap</span>[<span class="type">TopicAndPartition</span>, <span class="type">Seq</span>[<span class="type">KeyedMessage</span>[<span class="type">K</span>,<span class="type">Message</span>]]]]</span><br><span class="line">        <span class="keyword">case</span> <span class="type">None</span> =&gt;</span><br><span class="line">          dataPerBroker = <span class="keyword">new</span> <span class="type">HashMap</span>[<span class="type">TopicAndPartition</span>, <span class="type">Seq</span>[<span class="type">KeyedMessage</span>[<span class="type">K</span>,<span class="type">Message</span>]]]</span><br><span class="line">          ret.put(leaderBrokerId, dataPerBroker)</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// 构造Topic和Partition对象    </span></span><br><span class="line">      <span class="keyword">val</span> topicAndPartition = <span class="type">TopicAndPartition</span>(message.topic, brokerPartition.partitionId)</span><br><span class="line">      <span class="comment">// Broker对应的消息集合, 即使是相同的Broker, Topic-Partition组合也不一定一样 </span></span><br><span class="line">      <span class="keyword">var</span> dataPerTopicPartition: <span class="type">ArrayBuffer</span>[<span class="type">KeyedMessage</span>[<span class="type">K</span>,<span class="type">Message</span>]] = <span class="literal">null</span></span><br><span class="line">      dataPerBroker.get(topicAndPartition) <span class="keyword">match</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> <span class="type">Some</span>(element) =&gt;</span><br><span class="line">          dataPerTopicPartition = element.asInstanceOf[<span class="type">ArrayBuffer</span>[<span class="type">KeyedMessage</span>[<span class="type">K</span>,<span class="type">Message</span>]]]</span><br><span class="line">        <span class="keyword">case</span> <span class="type">None</span> =&gt;</span><br><span class="line">          dataPerTopicPartition = <span class="keyword">new</span> <span class="type">ArrayBuffer</span>[<span class="type">KeyedMessage</span>[<span class="type">K</span>,<span class="type">Message</span>]]</span><br><span class="line">          dataPerBroker.put(topicAndPartition, dataPerTopicPartition)</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// 到这里,才是真正将消息添加到集合中</span></span><br><span class="line">      dataPerTopicPartition.append(message)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="type">Some</span>(ret)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在发送消息过程中,只要有失败的消息就加入到failedProduceRequests,这样返回的集合不为空,就会重试  </p>
<ul>
<li>partitionAndCollate: 重新组织数据, 格式: <code>BrokerId -&gt; (TopicAndPartition -&gt; Seq[KeyedMessage])</code></li>
<li>groupMessagesToSet:  将Message集合转成更加紧凑的MessageSet</li>
<li>send: 向BrokerId节点发送消息集MessageSet</li>
</ul>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">dispatchSerializedData</span>(</span>messages: <span class="type">Seq</span>[<span class="type">KeyedMessage</span>[<span class="type">K</span>,<span class="type">Message</span>]]): <span class="type">Seq</span>[<span class="type">KeyedMessage</span>[<span class="type">K</span>, <span class="type">Message</span>]] = &#123;</span><br><span class="line">  <span class="keyword">val</span> partitionedDataOpt = partitionAndCollate(messages)  <span class="comment">// 重新组织消息</span></span><br><span class="line">  partitionedDataOpt <span class="keyword">match</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="type">Some</span>(partitionedData) =&gt;</span><br><span class="line">      <span class="keyword">val</span> failedProduceRequests = <span class="keyword">new</span> <span class="type">ArrayBuffer</span>[<span class="type">KeyedMessage</span>[<span class="type">K</span>, <span class="type">Message</span>]]</span><br><span class="line">      <span class="keyword">for</span> ((brokerid, messagesPerBrokerMap) &lt;- partitionedData) &#123;</span><br><span class="line">        <span class="keyword">val</span> messageSetPerBrokerOpt = groupMessagesToSet(messagesPerBrokerMap)</span><br><span class="line">        messageSetPerBrokerOpt <span class="keyword">match</span> &#123;</span><br><span class="line">          <span class="keyword">case</span> <span class="type">Some</span>(messageSetPerBroker) =&gt;</span><br><span class="line">            <span class="keyword">val</span> failedTopicPartitions = send(brokerid, messageSetPerBroker)</span><br><span class="line">            failedTopicPartitions.foreach(topicPartition =&gt; &#123;</span><br><span class="line">              messagesPerBrokerMap.get(topicPartition) <span class="keyword">match</span> &#123;</span><br><span class="line">                <span class="keyword">case</span> <span class="type">Some</span>(data) =&gt; failedProduceRequests.appendAll(data)</span><br><span class="line">                <span class="keyword">case</span> <span class="type">None</span> =&gt; <span class="comment">// nothing, 所有的消息都发送成功</span></span><br><span class="line">              &#125;</span><br><span class="line">            &#125;)</span><br><span class="line">          <span class="keyword">case</span> <span class="type">None</span> =&gt; messagesPerBrokerMap.values.foreach(m =&gt; failedProduceRequests.appendAll(m))  <span class="comment">// failed to group messages</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      failedProduceRequests</span><br><span class="line">    <span class="keyword">case</span> <span class="type">None</span> =&gt; messages <span class="comment">// failed to collate messages</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>分组会将原始的Message如果有压缩格式,转换成压缩后的MessageSet. Key在分组中并没有发生变化.  </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">groupMessagesToSet</span>(</span>messagesPerTopicAndPartition: collection.mutable.<span class="type">Map</span>[<span class="type">TopicAndPartition</span>, <span class="type">Seq</span>[<span class="type">KeyedMessage</span>[<span class="type">K</span>, <span class="type">Message</span>]]]) = &#123;</span><br><span class="line">    <span class="keyword">val</span> messagesPerTopicPartition = messagesPerTopicAndPartition.map &#123; <span class="keyword">case</span> (topicAndPartition, messages) =&gt;</span><br><span class="line">      <span class="comment">// KeyedMessage包括了Key,Value, 其中message就是value原始数据</span></span><br><span class="line">      <span class="keyword">val</span> rawMessages = messages.map(_.message)</span><br><span class="line">      <span class="comment">// 输入是个Map(用case元组匹配),返回值也是元组,也会转成Map: key没有变化,value将Seq[Message]转成了MessageSet</span></span><br><span class="line">      (topicAndPartition,</span><br><span class="line">        config.compressionCodec <span class="keyword">match</span> &#123;</span><br><span class="line">          <span class="keyword">case</span> <span class="type">NoCompressionCodec</span> =&gt; <span class="keyword">new</span> <span class="type">ByteBufferMessageSet</span>(<span class="type">NoCompressionCodec</span>, rawMessages: _*)</span><br><span class="line">        &#125;</span><br><span class="line">      )</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="type">Some</span>(messagesPerTopicPartition)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>发送消息,从生产者池中获取SyncProducer(每个Broker一个Producer),将消息集封装到ProducerRequest,调用Producer.send发送请求  </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">send</span>(</span>brokerId: <span class="type">Int</span>, messagesPerTopic: collection.mutable.<span class="type">Map</span>[<span class="type">TopicAndPartition</span>, <span class="type">ByteBufferMessageSet</span>]) = &#123;</span><br><span class="line">    <span class="keyword">val</span> currentCorrelationId = correlationId.getAndIncrement</span><br><span class="line">    <span class="keyword">val</span> producerRequest = <span class="keyword">new</span> <span class="type">ProducerRequest</span>(currentCorrelationId, config.clientId, config.requestRequiredAcks, config.requestTimeoutMs, messagesPerTopic)</span><br><span class="line">    <span class="keyword">val</span> syncProducer = producerPool.getProducer(brokerId)</span><br><span class="line">    <span class="keyword">val</span> response = syncProducer.send(producerRequest)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>发送消息,只需要指定brokerId,以及消息内容(TopicPartition-&gt;MessageSet)  </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">ProducerRequest</span>(</span>versionId: <span class="type">Short</span> = <span class="type">ProducerRequest</span>.<span class="type">CurrentVersion</span>, correlationId: <span class="type">Int</span>, clientId: <span class="type">String</span>, </span><br><span class="line">                           requiredAcks: <span class="type">Short</span>, ackTimeoutMs: <span class="type">Int</span>, data: collection.mutable.<span class="type">Map</span>[<span class="type">TopicAndPartition</span>, <span class="type">ByteBufferMessageSet</span>])</span><br></pre></td></tr></table></figure>
<h3 id="SyncProducer">SyncProducer</h3><p>如果请求需要ack,则需要返回ProducerResponse给客户端(返回的消息内容放在response的payload字节缓冲区中).  </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">send</span>(</span>producerRequest: <span class="type">ProducerRequest</span>): <span class="type">ProducerResponse</span> = &#123;</span><br><span class="line">  <span class="keyword">var</span> response: <span class="type">NetworkReceive</span> = doSend(producerRequest, <span class="keyword">if</span>(producerRequest.requiredAcks == <span class="number">0</span>) <span class="literal">false</span> <span class="keyword">else</span> <span class="literal">true</span>)</span><br><span class="line">  <span class="keyword">if</span>(producerRequest.requiredAcks != <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="type">ProducerResponse</span>.readFrom(response.payload)</span><br><span class="line">  &#125; <span class="keyword">else</span> <span class="literal">null</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">doSend</span>(</span>request: <span class="type">RequestOrResponse</span>, readResponse: <span class="type">Boolean</span> = <span class="literal">true</span>): <span class="type">NetworkReceive</span> = &#123;</span><br><span class="line">    verifyRequest(request)</span><br><span class="line">    getOrMakeConnection()</span><br><span class="line">    <span class="keyword">var</span> response: <span class="type">NetworkReceive</span> = <span class="literal">null</span></span><br><span class="line">    blockingChannel.send(request)</span><br><span class="line">    <span class="keyword">if</span>(readResponse)</span><br><span class="line">      response = blockingChannel.receive()</span><br><span class="line">    response</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>实际的发送请求是交给BlockingChannel,它实现了I/O中的连接connect,发送请求send,接收响应receive<br>从它的名字看出这是一个阻塞类型的Channel,所以并没有用到NIO的多路选择特性,难怪这是Old的设计.<br>KafkaProducer构造的请求是RequestSend,这里是RequestOrResponseSend,不过都是ByteBufferSend</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">send</span>(</span>request: <span class="type">RequestOrResponse</span>): <span class="type">Long</span> = &#123;</span><br><span class="line">  <span class="keyword">val</span> send = <span class="keyword">new</span> <span class="type">RequestOrResponseSend</span>(connectionId, request)</span><br><span class="line">  send.writeCompletely(writeChannel)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">receive</span>(</span>): <span class="type">NetworkReceive</span> = &#123;</span><br><span class="line">  <span class="keyword">val</span> response = readCompletely(readChannel)</span><br><span class="line">  response.payload().rewind()     <span class="comment">//读取到响应的ByteBuffer,回到缓冲区的最开始,便于读取</span></span><br><span class="line">  response                        <span class="comment">//返回响应, 如果客户端需要ack,则直接使用response.payload即可</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>思考问题: Producer发送的消息是如何得知要发给哪个Broker上的Leader Partition?</p>
</blockquote>
<h2 id="KafkaServer">KafkaServer</h2><p>上面的Producer和Consumer都不是作为Kafka的内置服务,而是一种客户端(所以它们都在clients包).<br>客户端可以独立于Kafka,和Kafka服务所在的节点互相隔离.Producer和Consumer和Kafka集群进行交互.<br>每个Kafka节点都有一些自己内置的服务进程,比如Broker,KafkaController,GroupCoordinator,ReplicaManager</p>
<p><img src="http://kafka.apache.org/images/producer_consumer.png" alt="p_c_k"></p>
<p>接下来我们看下客户端的请求在服务端是怎么被处理的. 客户端有发送和接收请求, 服务端同样也有接收和发送的逻辑.<br>因为对于I/O来说是双向的:客户端发送请求,就意味着服务端要接收请求,同样服务端也会发送响应,客户端就要接收响应.  </p>
<h2 id="Ref">Ref</h2><ul>
<li><a href="http://blog.csdn.net/lizhitao/article/details/39499283" target="_blank" rel="external">http://blog.csdn.net/lizhitao/article/details/39499283</a></li>
</ul>

      
    </div>
    
  </div>
  
    
<div class="copyright">
  <p><span>本文标题:</span><a href="/2016/01/06/2016-01-06-Kafka_Producer/">Kafka源码分析 Producer客户端</a></p>
  <p><span>文章作者:</span><a href="/" title="访问 任何忧伤,都抵不过世界的美丽 的个人博客">任何忧伤,都抵不过世界的美丽</a></p>
  <p><span>发布时间:</span>2016年01月06日 - 00时00分</p>
  <p><span>最后更新:</span>2016年01月20日 - 12时09分</p>
  <p>
    <span>原始链接:</span><a href="/2016/01/06/2016-01-06-Kafka_Producer/" title="Kafka源码分析 Producer客户端">http://github.com/zqhxuyuan/2016/01/06/2016-01-06-Kafka_Producer/</a>
    <span class="btn" data-clipboard-text="原文: http://github.com/zqhxuyuan/2016/01/06/2016-01-06-Kafka_Producer/　　作者: 任何忧伤,都抵不过世界的美丽" title="点击复制文章链接">
        <i class="fa fa-clipboard"></i>
    </span>
  </p>
  <p><span>许可协议:</span><i class="fa fa-creative-commons"></i> <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/3.0/cn/" title="中国大陆 (CC BY-NC-SA 3.0 CN)">"署名-非商用-相同方式共享 3.0"</a> 转载请保留原文链接及作者。</p>
  <script src="/js/clipboard.min.js"></script>
  <script> var clipboard = new Clipboard('.btn'); </script>
</div>
<style type="text/css">
  .copyright p .btn {
    margin-left: 1em;
  }
  .copyright:hover p .btn::after {
    content: "复制"
  }
  .copyright p .btn:hover {
      color: gray;
      cursor: pointer;
    };
</style>



<nav id="article-nav">
  
    <div id="article-nav-newer" class="article-nav-title">
      <a href="/2016/01/08/2016-01-08-Kafka_SocketServer/">
        Kafka源码分析 SocketServer
      </a>
    </div>
  
  
    <div id="article-nav-older" class="article-nav-title">
      <a href="/2016/01/05/2016-01-05-Kafka-Unix/">
        Kafka和Unix管道的示例
      </a>
    </div>
  
</nav>

  
</article>

<!-- 默认显示文章目录，在文章---前输入toc: false关闭目录 -->
<!-- Show TOC and tocButton in default, Hide TOC via putting "toc: false" before "---" at [post].md -->
<div id="toc" class="toc-article">
<strong class="toc-title">文章目录</strong>
<ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Producer"><span class="toc-number">1.</span> <span class="toc-text">Producer</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#blocking_vs_non-blocking"><span class="toc-number">1.1.</span> <span class="toc-text">blocking vs non-blocking</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#partition"><span class="toc-number">1.2.</span> <span class="toc-text">partition</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#RecordAccumulator"><span class="toc-number">1.3.</span> <span class="toc-text">RecordAccumulator</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Sender"><span class="toc-number">1.4.</span> <span class="toc-text">Sender</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#ClientRequest_&_ClientResponse"><span class="toc-number">1.4.1.</span> <span class="toc-text">ClientRequest & ClientResponse</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Callback"><span class="toc-number">1.4.2.</span> <span class="toc-text">Callback</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#handleProduceResponse"><span class="toc-number">1.4.3.</span> <span class="toc-text">handleProduceResponse</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#NetworkClient"><span class="toc-number">1.5.</span> <span class="toc-text">NetworkClient</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Selector"><span class="toc-number">1.6.</span> <span class="toc-text">Selector</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#KafkaChannel"><span class="toc-number">1.7.</span> <span class="toc-text">KafkaChannel</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#OldProducer"><span class="toc-number">2.</span> <span class="toc-text">OldProducer</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#ProducerSendThread"><span class="toc-number">2.1.</span> <span class="toc-text">ProducerSendThread</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#DefaultEventHandler"><span class="toc-number">2.2.</span> <span class="toc-text">DefaultEventHandler</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#SyncProducer"><span class="toc-number">2.3.</span> <span class="toc-text">SyncProducer</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#KafkaServer"><span class="toc-number">3.</span> <span class="toc-text">KafkaServer</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Ref"><span class="toc-number">4.</span> <span class="toc-text">Ref</span></a></li></ol>
</div>
<style type="text/css">
  .left-col .switch-btn {
    display: none;
  }
  .left-col .switch-area {
    display: none;
  }
</style>

<input type="button" id="tocButton" value="隐藏目录"  title="点击按钮隐藏或者显示文章目录">
<script type="text/javascript">
  var toc_button= document.getElementById("tocButton");
  var toc_div= document.getElementById("toc");
  /* Show or hide toc when click on tocButton.
  通过点击设置的按钮显示或者隐藏文章目录.*/
  toc_button.onclick=function(){
  if(toc_div.style.display=="none"){
  toc_div.style.display="block";
  toc_button.value="隐藏目录";
  document.getElementById("switch-btn").style.display="none";
  document.getElementById("switch-area").style.display="none";
  }
  else{
  toc_div.style.display="none";
  toc_button.value="显示目录";
  document.getElementById("switch-btn").style.display="block";
  document.getElementById("switch-area").style.display="block";
  }
  }
    if ($(".toc").length < 1) {
        $("#toc").css("display","none");
        $("#tocButton").css("display","none");
        $(".switch-btn").css("display","block");
        $(".switch-area").css("display","block");
    }
</script>


    <style>
        .toc {
            white-space: nowrap;
            overflow-x: hidden;
        }
    </style>

    <script>
        $(document).ready(function() {
            $(".toc li a").mouseover(function() {
                var title = $(this).attr('href');
                $(this).attr("title", title);
            });
        })
    </script>




<div class="share">
	<div class="bdsharebuttonbox">
	<a href="#" class="bds_more" data-cmd="more"></a>
	<a href="#" class="bds_tsina" data-cmd="tsina" title="分享到新浪微博"></a>
	<a href="#" class="bds_sqq" data-cmd="sqq" title="分享给 QQ 好友"></a>
	<a href="#" class="bds_copy" data-cmd="copy" title="复制网址"></a>
	<a href="#" class="bds_mail" data-cmd="mail" title="通过邮件分享"></a>
	<a href="#" class="bds_weixin" data-cmd="weixin" title="生成文章二维码"></a>
	</div>
	<script>
	window._bd_share_config={
		"common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"0","bdSize":"24"},"share":{}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];
	</script>
</div>







    <style type="text/css">
    #scroll {
      display: none;
    }
    </style>
    <div class="scroll">
    <a href="#" title="返回顶部"><i class="fa fa-arrow-up"></i></a>
    <a href="#comments" title="查看评论"><i class="fa fa-comments-o"></i></a>
    <a href="#footer" title="转到底部"><i class="fa fa-arrow-down"></i></a>
    </div>


  
  
    
    <div  class="post-nav-button">
    <a href="/2016/01/08/2016-01-08-Kafka_SocketServer/" title="上一篇: Kafka源码分析 SocketServer">
    <i class="fa fa-angle-left"></i>
    </a>
    <a href="/2016/01/05/2016-01-05-Kafka-Unix/" title="下一篇: Kafka和Unix管道的示例">
    <i class="fa fa-angle-right"></i>
    </a>
    </div>
  



    
        <link rel="stylesheet" href="/fancybox/jquery.fancybox.css" type="text/css">
        <script>
        var yiliaConfig = {
        fancybox: true,
        mathjax: true,
        animate: true,
        isHome: false,
        isPost: true,
        isArchive: false,
        isTag: false,
        isCategory: false,
        open_in_new: false
        }
        </script>
        
</div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
      <div class="footer-left">
        &copy; 2016 任何忧伤,都抵不过世界的美丽
      </div>
        <div class="footer-right">
          <a href="http://hexo.io/" target="_blank" title="快速、简洁且高效的静态博客框架">Hexo</a>  Theme <a href="https://github.com/MOxFIVE/hexo-theme-yelee" target="_blank" title="简而不减双栏 Hexo 博客主题">Yelee</a> by MOxFIVE
        </div>
    </div>
    <div class="visit">
      <span id="busuanzi_container_site_pv" style='display:none'>
        <span id="site-visit" >本站到访数: 
        <span id="busuanzi_value_site_uv"></span>
        </span>
      </span>
      <span id="busuanzi_container_page_pv" style='display:none'>
        <span id="page-visit">, 本页阅读量: 
        <span id="busuanzi_value_page_pv"></span>
        </span>
      </span>
    </div>
  </div>
</footer>
    </div>
    

<script src="http://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js" type="text/javascript"></script>
<script src="/js/main.js" type="text/javascript"></script>

<script>
  var backgroundnum = 5;
  var backgroundimg = "url(/background/bg-x.jpg)".replace(/x/gi, Math.ceil(Math.random() * backgroundnum));

  $("body").css({"background": backgroundimg, "background-attachment": "fixed", "background-size": "cover"});
</script>




<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<div class="scroll" id="scroll">
<a href="#" title="返回顶部"><i class="fa fa-arrow-up"></i></a>
<a href="#footer" title="转到底部"><i class="fa fa-arrow-down"></i></a>
</div>

<script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>
  </div>
</body>
</html>