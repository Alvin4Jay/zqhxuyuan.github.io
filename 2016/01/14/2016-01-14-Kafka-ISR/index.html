<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Kafka源码分析 ISR | zqhxuyuan</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="接Kafla_LogAppend,消息存储到Leader的Partition之后…">
<meta property="og:type" content="article">
<meta property="og:title" content="Kafka源码分析 ISR">
<meta property="og:url" content="http://github.com/zqhxuyuan/2016/01/14/2016-01-14-Kafka-ISR/index.html">
<meta property="og:site_name" content="zqhxuyuan">
<meta property="og:description" content="接Kafla_LogAppend,消息存储到Leader的Partition之后…">
<meta property="og:image" content="http://img.blog.csdn.net/20160114142830405">
<meta property="og:image" content="http://img.blog.csdn.net/20160114145533803">
<meta property="og:image" content="http://img.blog.csdn.net/20160114153213150">
<meta property="og:image" content="http://img.blog.csdn.net/20160114163702208">
<meta property="og:image" content="http://img.blog.csdn.net/20160114094002808">
<meta property="og:updated_time" content="2016-01-14T15:43:41.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Kafka源码分析 ISR">
<meta name="twitter:description" content="接Kafla_LogAppend,消息存储到Leader的Partition之后…">
  
    <link rel="alternative" href="/atom.xml" title="zqhxuyuan" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link rel="stylesheet" href="/css/style.css" type="text/css">
  <link rel="stylesheet" href="/font-awesome/css/font-awesome.min.css">
  <link rel="apple-touch-icon" href="/apple-touch-icon.png">
</head>
<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			
			<img lazy-src="https://avatars1.githubusercontent.com/u/1088525?v=3&amp;s=180" class="js-avatar">
			
		</a>

		<hgroup>
		  <h1 class="header-author"><a href="/">任何忧伤,都抵不过世界的美丽</a></h1>
		</hgroup>

		
				


		
			<div id="switch-btn" class="switch-btn">
				<div class="icon">
					<div class="icon-ctn">
						<div class="icon-wrap icon-house" data-idx="0">
							<div class="birdhouse"></div>
							<div class="birdhouse_holes"></div>
						</div>
						<div class="icon-wrap icon-ribbon hide" data-idx="1">
							<div class="ribbon"></div>
						</div>
						
						
						<div class="icon-wrap icon-me hide" data-idx="3">
							<div class="user"></div>
							<div class="shoulder"></div>
						</div>
						
					</div>
					
				</div>
				<div class="tips-box hide">
					<div class="tips-arrow"></div>
					<ul class="tips-inner">
						<li>菜单</li>
						<li>标签</li>
						
						
						<li>关于我</li>
						
					</ul>
				</div>
			</div>
		

		<div id="switch-area" class="switch-area">
			<div class="switch-wrap">
				<section class="switch-part switch-part1">
					<nav class="header-menu">
						<ul>
						
							<li><a href="/">主页</a></li>
				        
							<li><a href="/archives/">归档</a></li>
				        
							<li><a href="/tags/">标签</a></li>
				        
							<li><a href="/about/">关于</a></li>
				        
						</ul>
					</nav>
					<nav class="header-nav">
						<ul class="social">
							
								<li id="新浪微博"><a class="新浪微博" target="_blank" href="http://weibo.com/xuyuantree" title="新浪微博"></a></li>
					        
								<li id="GitHub"><a class="GitHub" target="_blank" href="http://github.com/zqhxuyuan" title="GitHub"></a></li>
					        
						</ul>
					</nav>
				</section>
				
				
				<section class="switch-part switch-part2">
					<div class="widget tagcloud" id="js-tagcloud">
						<a href="/tags/apex/" style="font-size: 10px;">apex</a> <a href="/tags/cassandra/" style="font-size: 20px;">cassandra</a> <a href="/tags/clojure/" style="font-size: 10px;">clojure</a> <a href="/tags/drill/" style="font-size: 20px;">drill</a> <a href="/tags/druid/" style="font-size: 16px;">druid</a> <a href="/tags/elasticsearch/" style="font-size: 10px;">elasticsearch</a> <a href="/tags/geode/" style="font-size: 10px;">geode</a> <a href="/tags/hbase/" style="font-size: 18px;">hbase</a> <a href="/tags/ignite/" style="font-size: 10px;">ignite</a> <a href="/tags/kafka/" style="font-size: 18px;">kafka</a> <a href="/tags/scala/" style="font-size: 14px;">scala</a> <a href="/tags/spark/" style="font-size: 16px;">spark</a> <a href="/tags/storm/" style="font-size: 18px;">storm</a> <a href="/tags/timeseries/" style="font-size: 14px;">timeseries</a> <a href="/tags/translate/" style="font-size: 10px;">translate</a> <a href="/tags/work/" style="font-size: 12px;">work</a>
					</div>
				</section>
				
				
				

				
				
				<section class="switch-part switch-part3">
				
					<div id="js-aboutme">BIG(DATA)</div>
				</section>
				
			</div>
		</div>
	</header>				
</div>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
  	<div class="overlay">
  		<div class="slider-trigger"></div>
  		<h1 class="header-author js-mobile-header hide"><a href="/" title="回到主页">任何忧伤,都抵不过世界的美丽</a></h1>
  	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<a href="/" class="profilepic">
				<img lazy-src="https://avatars1.githubusercontent.com/u/1088525?v=3&amp;s=180" class="js-avatar">
			</a>
			<hgroup>
			  <h1 class="header-author"><a href="/" title="回到主页">任何忧伤,都抵不过世界的美丽</a></h1>
			</hgroup>
			
			<nav class="header-menu">
				<ul>
				
					<li><a href="/">主页</a></li>
		        
					<li><a href="/archives/">归档</a></li>
		        
					<li><a href="/tags/">标签</a></li>
		        
					<li><a href="/about/">关于</a></li>
		        
		        <div class="clearfix"></div>
				</ul>
			</nav>
			<nav class="header-nav">
						<ul class="social">
							
								<li id="新浪微博"><a class="新浪微博" target="_blank" href="http://weibo.com/xuyuantree" title="新浪微博"></a></li>
					        
								<li id="GitHub"><a class="GitHub" target="_blank" href="http://github.com/zqhxuyuan" title="GitHub"></a></li>
					        
						</ul>
			</nav>
		</header>				
	</div>
</nav>
      <div class="body-wrap"><article id="post-2016-01-14-Kafka-ISR" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/01/14/2016-01-14-Kafka-ISR/" class="article-date">
  	<time datetime="2016-01-13T16:00:00.000Z" itemprop="datePublished">2016-01-14</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Kafka源码分析 ISR
    </h1>
  

      </header>
      
      <div class="article-info article-info-post">
        
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/Source/">Source</a>
	</div>


        
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/kafka/">kafka</a></li></ul>
	</div>

        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <p>接Kafla_LogAppend,消息存储到Leader的Partition之后…<br><a id="more"></a></p>
<h2 id="Kafka_Replication">Kafka Replication</h2><blockquote>
<p>The leader maintains a set of in-sync replicas (ISR): the set of replicas that have fully caught up with the leader.<br>For each partition, we store in Zookeeper the current leader and the current ISR.<br>Leader维护了ISR(能完全赶得上Leader的副本集).每个Partition当前的Leader和ISR信息会记录在ZooKeeper中.  </p>
<p>问题:为什么是由Leader来维护ISR?<br>背景:Leader会跟踪与其保持同步的Replica列表，该列表称为ISR。如果一个Follower宕机，或者落后太多，Leader将把它从ISR中移除.<br>答案:只有Leader才能知道哪些Replica能够及时完全赶得上.所有Follower都会和Leader通信获取最新的消息.<br>但是Follower之间并不互相知道彼此的信息.所以由Leader来管理ISR最合适了.Leader还可以决定移除落后太多的Replicas. </p>
<p>Each replica stores messages in a local log and maintains a few important offset positions in the log.<br>The log end offset (LEO) represents the tail of the log.<br>The high watermark (HW) is the offset of the last committed message.<br>每个Replica都在自己的local log中存储消息,并在日志中维护了重要的offset位置信息.<br>LEO代表了日志的最新的偏移量,HW是最近提交消息的偏移量(HW也是每个Replica都有的吗?).  </p>
<p>Each log is periodically synced to disks. Data before the flushed offset is guaranteed to be persisted on disks.<br>As we will see, the flush offset can be before or after HW.<br>每个日志都会定时地同步到磁盘.在flushed offset之前的数据一定能保存成功持久化到磁盘上.<br>flush offset可以在HW之前或者之后(因为follower只是先写到内存中然后返回ack给leader,hw增加时,<br>follower在内存中的消息不一定什么时候写到磁盘上,即可能在hw增加前就写到磁盘,或者等hw增加后才写到磁盘).</p>
<p><strong>Writes</strong><br>To publish a message to a partition, the client first finds the <code>leader of the partition</code> from<br>Zookeeper and <code>sends the message to the leader</code>.The leader writes the message to its <code>local log</code>.<br>Each follower constantly <code>pulls</code> new messages from the leader using a single socket channel.<br>That way, the follower receives all messages in the <code>same order</code> as written in the leader.<br>为了将消息发布给一个Partition,客户端会从ZK中先找到这个Partition的Leader,然后把消息发送给Leader.<br>Leader会将消息写到自己的本地日志文件中,(Partition的)每个follower会从Leader一直拉取数据.<br>通过这种方式,follower接收的所有消息的顺序一定和写到leader的消息是同样的顺序.  </p>
<p>The follower writes each received message to its <code>own log</code> and sends an <code>acknowledgment</code> back to the leader.<br>Once the leader receives the acknowledgment from <code>all replicas in ISR</code>, the message is <code>committed</code>.<br>The <code>leader advances the HW</code> and sends an acknowledgment to the client.<br>follower收到的每条消息都会写到自己的日志中,并且发送ack给leader.<br>一旦leader接收到在ISR中所有副本的ack,这条消息就会被提交.然后Leader会增加HW,并发送ack给客户端.</p>
<p>For better performance, each follower sends an acknowledgment after the message is <code>written to memory</code>.<br>So, for each committed message, we guarantee that the message is stored in multiple replicas in memory.<br>However, there is <code>no guarantee</code> that any replica has <code>persisted</code> the commit message to disks though.<br>Given that correlated failures are relatively rare, this approach gives us a good balance between response time and durability.<br>In the future, we may consider adding options that provide even stronger guarantees.<br>为了性能考虑,每个follower当消息被写到内存时就发送ack(而不是要完全地刷写到磁盘上才ack).<br>所以对于每条提交的消息,我们能够保证的是这条消息一定是存储在多个副本(所有ISR)的内存中.<br>但是并不保证任何副本已经把这条提交的消息持久化到磁盘中.这是基于响应时间和持久性两者平衡的.    </p>
<p>The leader also periodically <code>broadcasts the HW</code> to all followers.<br>The broadcasting can be piggybacked(背负) on the return value of the <code>fetch requests</code> from the followers.<br>From time to time, <code>each replica checkpoints its HW to its disk</code>.<br>Leader也会定时地将HW广播给所有的followers. 广播消息可以附加在从follower过来的fetch请求的结果中.<br>同时,每个副本(不管是leader还是follower)也会定时地将HW持久化到自己的磁盘上.  </p>
<p>当follower向leader提交fetch请求时,leader也会告诉所有的follower说,我现在的hw是多少了.这是一种保护机制.<br>假设只有leader一个人保护了hw这个重要的信息,一旦leader不幸挂掉了,就没有人知道hw现在到底是多少了.<br>所以只要一有follower过来获取消息时,leader就不厌其烦地像个老太婆不断地唠叨说我这一次的hw更新到了哪里.<br>每个follower也就都会知道leader的最新hw.这样即使leader挂掉了,hw仍然在其他follower上都备份有这个重要信息.<br>几个follower在一阵商量后,选举出了新的leader,这些人都知道上一个leader最新的hw,因此hw这个香火会继续传承下去.  </p>
<p><strong>Reads</strong><br>For simplicity, reads are always served from the leader. Only messages up to the HW are exposed to the reader.<br>为了简单起见,只有leader可以提供读消息的服务.并且最多只到hw位置的消息才会暴露给客户端.  </p>
<hr>
<p>Producer在发布消息到某个Partition时，先通过Zookeeper找到该Partition的Leader，<br>然后无论该Topic的Replication Factor为多少（也即该Partition有多少个Replica），<br>Producer只将该消息发送到该Partition的Leader。Leader会将该消息写入其本地Log。每个Follower都从Leader pull数据。<br>这种方式上，Follower存储的数据顺序与Leader保持一致。Follower在收到该消息并写入其Log后，向Leader发送ACK。<br>一旦Leader收到了ISR中的所有Replica的ACK，该消息就被认为已经commit了，Leader将增加HW并且向Producer发送ACK。<br>为了提高性能，每个Follower在接收到数据后就立马向Leader发送ACK，而非等到数据写入Log中。<br>因此，对于已经commit的消息，Kafka只能保证它被存于多个Replica的内存中，而不能保证它们被持久化到磁盘中，<br>也就不能完全保证异常发生后该条消息一定能被Consumer消费。但考虑到这种场景非常少见，<br>可以认为这种方式在性能和数据持久化上做了一个比较好的平衡。在将来的版本中，Kafka会考虑提供更高的持久性。<br>Consumer读消息也是从Leader读取，只有被commit过的消息（offset低于HW的消息）才会暴露给Consumer。 </p>
<p>Kafka的复制机制既不是完全的同步复制，也不是单纯的异步复制。事实上，<br>同步复制要求所有能工作的Follower都复制完，这条消息才会被认为commit，这种复制方式极大的影响了吞吐率。<br>而异步复制方式下，Follower异步的从Leader复制数据，数据只要被Leader写入log就被认为已经commit，<br>这种情况下如果Follower都复制完都落后于Leader，而如果Leader突然宕机，则会丢失数据。<br>而Kafka的这种使用ISR的方式则很好的均衡了确保数据不丢失以及吞吐率。<br>Follower可以批量的从Leader复制数据，这样极大的提高复制性能（批量写磁盘），极大减少了Follower与Leader的差距  </p>
<hr>
<p>Checkpoint用在Follower failure是怎么解决HW的同步问题:<br>After a configured timeout period, the leader will drop the failed follower from its ISR<br>and writes will continue on the remaining replicas in ISR.<br>如果Follower失败了,在超过一定时间后,Leader会将这个失败的follower从ISR中移除(follower没有发送fetch请求)<br>由于ISR保存的是所有全部赶得上Leader的follower replicas,失败的follower肯定是赶不上了.<br>虽然ISR现在少了一个,但是并不会引起的数据的丢失,ISR中剩余的replicas会继续同步数据(只要ISR中有一个follower,就不会丢失数据)<br>(注意:这里讨论的是一个Partition的follower副本,而不是节点,如果是一个节点,它不止存储一个Partition,而且不都是follower)  </p>
<p>If the failed follower comes back, it first truncates its log to the last checkpointed HW.<br>It then starts to catch up all messages after its HW from the leader.<br>When the follower fully catches up, the leader will add it back to the current ISR.<br>如果失败的follower恢复过来,它首先将自己的日志截断到上次checkpointed时刻的HW.<br>因为checkpoint记录的是所有Partition的hw offset. 当follower失败时,checkpoint中关于这个Partition的HW就不会再更新了.<br>而这个时候存储的HW信息和follower partition replica的offset并不一定是一致的. 比如这个follower获取消息比较快,<br>但是ISR中有其他follower复制消息比较慢,这样Leader并不会很快地更新HW,这个快的follower的hw也不会更新(leader广播hw给follower)<br>这种情况下,这个follower日志的offset是比hw要大的.所以在它恢复之后,要将比hw多的部分截掉,然后继续从leader拉取消息(跟平时一样).<br>实际上,ISR中的每个follower日志的offset一定是比hw大的.因为只有ISR中所有follower都复制完消息,leader才会增加hw.<br>也就是说有可能有些follower复制完了,而有些follower还没有复制完,那么hw是不会增加的,复制完的follower的offset就比hw要大.  </p>
</blockquote>
<h2 id="Replica">Replica</h2><p>首先来看Partition的Replication副本是个什么概念. 每个Partition都可以有多个Replication.<br>其中Leader副本负责读写, Follower副本负责从Leader拉取数据. Replica分布在不同的Broker上.<br>所以Replica只需要两个属性: Partition(分区), brokerid(所在的Kafka节点).  </p>
<p><img src="http://img.blog.csdn.net/20160114142830405" alt="k_partition"></p>
<p>一个Replication有两个重要的元数据: HighWatermark和LogEndOffset.  </p>
<ul>
<li>HighWatermark是用来确保消费者能获取到的消息的最高水位,超过这个水位的消息是不会被客户端看到的.</li>
<li>由于Leader负责读写,所以HW只能由Leader更新,但是怎么时候更新,可能由follower在更新LEO时通知Leader修改.</li>
<li>LogEndOffset是所有的Replica都会有的:Leader在消息追加后会更新,follower在从Leader抓取消息也也会更新.</li>
</ul>
<p><img src="http://img.blog.csdn.net/20160114145533803" alt="k_update_leo"></p>
<blockquote>
<p>问:最后一个可选的Log是怎么用来判断是否是本地的Replica? Local和Remote又是针对什么而言?<br>答:一个Partition的所有Replicas都是保存在Leader节点的内存中的. 而不是让每个节点自己管理自己的信息,<br>如果这样的话,每个Kafka节点的信息就都是不一样的! 而分布式集群管理是要有一个中心来管理所有节点信息的.<br>因为现在是在Leader节点上,并且是由Leader管理所有的Replicas,Leader自己就是Local,其他Replics都是Remote!<br>即<code>Leader Replica = Local Replica</code>, <code>Follower Repicas = Remote Replicas</code>.  </p>
<p>问:因为Partitions是分布在不同的Kafka节点,本身每个节点记录的Partitions就是不一样的了.<br>答:没错,分布式节点保存的信息是不一样的,但是同一个Partition的所有Replicas应该是交给Leader管理的.<br>而follower上的Replicas并不需要管理自己的状态,因为Leader替他们管理好了.  </p>
</blockquote>
<p><img src="http://img.blog.csdn.net/20160114153213150" alt="k_local_remote"></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Replica</span>(</span><span class="keyword">val</span> brokerId: <span class="type">Int</span>, <span class="keyword">val</span> partition: <span class="type">Partition</span>, time: <span class="type">Time</span> = <span class="type">SystemTime</span>, initialHighWatermarkValue: <span class="type">Long</span> = <span class="number">0</span>L, <span class="keyword">val</span> log: <span class="type">Option</span>[<span class="type">Log</span>] = <span class="type">None</span>) &#123;</span><br><span class="line">  <span class="comment">// the high watermark offset value, in non-leader replicas only its message offsets are kept</span></span><br><span class="line">  <span class="annotation">@volatile</span> <span class="keyword">private</span>[<span class="keyword">this</span>] <span class="keyword">var</span> highWatermarkMetadata: <span class="type">LogOffsetMetadata</span> = <span class="keyword">new</span> <span class="type">LogOffsetMetadata</span>(initialHighWatermarkValue)</span><br><span class="line">  <span class="comment">// the log end offset value, kept in all replicas;</span></span><br><span class="line">  <span class="comment">// for local replica it is the log's end offset, for remote replicas its value is only updated by follower fetch</span></span><br><span class="line">  <span class="annotation">@volatile</span> <span class="keyword">private</span>[<span class="keyword">this</span>] <span class="keyword">var</span> logEndOffsetMetadata: <span class="type">LogOffsetMetadata</span> = <span class="type">LogOffsetMetadata</span>.<span class="type">UnknownOffsetMetadata</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">isLocal</span>:</span> <span class="type">Boolean</span> = log <span class="keyword">match</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="type">Some</span>(l) =&gt; <span class="literal">true</span>    <span class="comment">// 创建Replica时指定Log时, 则表示是本地的Replication</span></span><br><span class="line">    <span class="keyword">case</span> <span class="type">None</span> =&gt; <span class="literal">false</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 设置LEO: 不应该在Local Replication的Partition上设置LEO. 对于Local Replica,它是由Log的EndOffset指定,而不能调用改update方法</span></span><br><span class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">logEndOffset_=</span>(</span>newLogEndOffset: <span class="type">LogOffsetMetadata</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span> (!isLocal) logEndOffsetMetadata = newLogEndOffset</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 获取LEO</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">logEndOffset</span> =</span> <span class="keyword">if</span> (isLocal) log.get.logEndOffsetMetadata <span class="keyword">else</span> logEndOffsetMetadata</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 设置HW: 不应该在非Local Replication的Partition上设置HW, 即只能在Local Replica上设置, Local Replica也是Leader Replica</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">highWatermark_=</span>(</span>newHighWatermark: <span class="type">LogOffsetMetadata</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span> (isLocal) highWatermarkMetadata = newHighWatermark</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 获取HW</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">highWatermark</span> =</span> highWatermarkMetadata</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在Partition中创建Replica,如果不在assignedReplicaMap中,根据是否是本地(Leader)来创建Replica实例.<br>Local的Replica比Remote的多了offset和Log.Replica的isLocal()会根据是否有Log判断是不是Local.  </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getOrCreateReplica</span>(</span>replicaId: <span class="type">Int</span> = localBrokerId): <span class="type">Replica</span> = &#123;</span><br><span class="line">  <span class="keyword">val</span> replicaOpt = getReplica(replicaId)</span><br><span class="line">  replicaOpt <span class="keyword">match</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="type">Some</span>(replica) =&gt; replica</span><br><span class="line">    <span class="keyword">case</span> <span class="type">None</span> =&gt;</span><br><span class="line">      <span class="keyword">if</span> (isReplicaLocal(replicaId)) &#123;</span><br><span class="line">        <span class="keyword">val</span> config = <span class="type">LogConfig</span>.fromProps(logManager.defaultConfig.originals, <span class="type">AdminUtils</span>.fetchEntityConfig(zkUtils, <span class="type">ConfigType</span>.<span class="type">Topic</span>, topic))</span><br><span class="line">        <span class="comment">// TopicAndPartition的Log</span></span><br><span class="line">        <span class="keyword">val</span> log = logManager.createLog(<span class="type">TopicAndPartition</span>(topic, partitionId), config)</span><br><span class="line">        <span class="comment">// log.dirs是所有TopicAndPartition的父目录, 而checkpoints也是全局的</span></span><br><span class="line">        <span class="keyword">val</span> checkpoint = replicaManager.highWatermarkCheckpoints(log.dir.getParentFile.getAbsolutePath)</span><br><span class="line">        <span class="keyword">val</span> offsetMap = checkpoint.read</span><br><span class="line">        <span class="comment">// checkpoints中记录了所有Partition的offset信息, 所以可以根据TopicAndPartition找到对应的offset</span></span><br><span class="line">        <span class="keyword">if</span> (!offsetMap.contains(<span class="type">TopicAndPartition</span>(topic, partitionId))) info(<span class="string">"No checkpointed highwatermark is found for partition [%s,%d]"</span>.format(topic, partitionId))</span><br><span class="line">        <span class="keyword">val</span> offset = offsetMap.getOrElse(<span class="type">TopicAndPartition</span>(topic, partitionId), <span class="number">0</span>L).min(log.logEndOffset)</span><br><span class="line">        <span class="comment">// 本地的是Leader, 所以要给出offset和Log.</span></span><br><span class="line">        <span class="keyword">val</span> localReplica = <span class="keyword">new</span> <span class="type">Replica</span>(replicaId, <span class="keyword">this</span>, time, offset, <span class="type">Some</span>(log))</span><br><span class="line">        addReplicaIfNotExists(localReplica)</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// 远程的是follower.</span></span><br><span class="line">        <span class="keyword">val</span> remoteReplica = <span class="keyword">new</span> <span class="type">Replica</span>(replicaId, <span class="keyword">this</span>, time)</span><br><span class="line">        addReplicaIfNotExists(remoteReplica)</span><br><span class="line">      &#125;</span><br><span class="line">      getReplica(replicaId).get</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>注意上面的<code>log.dir</code>是TopicAndPartition的目录(每个TopicAndPartition目录是唯一的).<br><code>log.dir.getParentFile</code>指的是配置文件中的<code>log.dirs</code>,而不是Partition的目录.<br>而<code>log.dirs</code>是server.properties的log.dirs配置项,它是所有TopicAndPartition的父目录.  </p>
<blockquote>
<p>getOrCreateReplica被调用的地方是在ReplicaManager.becomeLeaderOrFollower-&gt;makeFollowers</p>
</blockquote>
<h3 id="OffsetCheckpoint">OffsetCheckpoint</h3><p>Local Replica的offset来源于High watermark的checkpoint(因为HW很重要,所有需要做检查点).<br>ReplicaManager的highWatermarkCheckpoints是一个Map:日志目录(log.dirs)-&gt;OffsetCheckpoint.  </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> highWatermarkCheckpoints = config.logDirs.map(dir =&gt; </span><br><span class="line">  (<span class="keyword">new</span> <span class="type">File</span>(dir).getAbsolutePath, <span class="keyword">new</span> <span class="type">OffsetCheckpoint</span>(<span class="keyword">new</span> <span class="type">File</span>(dir, <span class="type">ReplicaManager</span>.<span class="type">HighWatermarkFilename</span>)))</span><br><span class="line">).toMap</span><br></pre></td></tr></table></figure>
<p>下面的/data/kafka目录是server.properties中的log.dirs的配置项,会在这个目录下生成checkpoint文件.  </p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">➜  kafka  ll                                                                        ⬅️ <span class="built_in">log</span>.dirs目录</span><br><span class="line">-rw-r--r--  <span class="number">1</span> zhengqh  staff     <span class="number">0</span>B  <span class="number">1</span> <span class="number">14</span> <span class="number">16</span>:<span class="number">13</span> recovery-point-offset-checkpoint</span><br><span class="line">-rw-r--r--  <span class="number">1</span> zhengqh  staff    <span class="number">18</span>B  <span class="number">1</span> <span class="number">14</span> <span class="number">16</span>:<span class="number">13</span> replication-offset-checkpoint       ⬅️ offset-checkpoint文件</span><br><span class="line">drwxr-xr-x  <span class="number">4</span> zhengqh  staff   <span class="number">136</span>B  <span class="number">1</span> <span class="number">14</span> <span class="number">16</span>:<span class="number">13</span> wikipedia-<span class="number">0</span></span><br><span class="line">➜  kafka  ll wikipedia-<span class="number">0</span>                                                            ⬅️ topic-partition目录         </span><br><span class="line">-rw-r--r--  <span class="number">1</span> zhengqh  staff    <span class="number">10</span>M  <span class="number">1</span> <span class="number">14</span> <span class="number">16</span>:<span class="number">13</span> <span class="number">00000000000000000000.</span>index          ⬅️ Segment日志文件和索引文件</span><br><span class="line">-rw-r--r--  <span class="number">1</span> zhengqh  staff     <span class="number">0</span>B  <span class="number">1</span> <span class="number">14</span> <span class="number">16</span>:<span class="number">13</span> <span class="number">00000000000000000000.l</span>og</span><br></pre></td></tr></table></figure>
<p>ReplicaManager是管理所有的Partition的,而checkpoints里记录的offsetMap是所有Partition共用的.<br>所以可以根据某个特定的TopicAndPartition找到它在checkpoints中对应的offset,用来创建Replica.  </p>
<p><img src="http://img.blog.csdn.net/20160114163702208" alt="k_offset_checkpoint"></p>
<p>因为OffsetCheckpoint记录的是TopicAndPartition到offset的映射关系.所以这个类中只是文件的读写操作.  </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">OffsetCheckpoint</span>(</span><span class="keyword">val</span> file: <span class="type">File</span>) <span class="keyword">extends</span> <span class="type">Logging</span> &#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">write</span>(</span>offsets: <span class="type">Map</span>[<span class="type">TopicAndPartition</span>, <span class="type">Long</span>]) &#123;</span><br><span class="line">    <span class="comment">// write the current version and the number of entries, then the entries, finally flush to disk</span></span><br><span class="line">    offsets.foreach &#123; <span class="keyword">case</span> (topicPart, offset) =&gt;</span><br><span class="line">        writer.write(<span class="string">"%s %d %d"</span>.format(topicPart.topic, topicPart.partition, offset))</span><br><span class="line">        writer.newLine()</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">read</span>(</span>): <span class="type">Map</span>[<span class="type">TopicAndPartition</span>, <span class="type">Long</span>] = &#123;</span><br><span class="line">    <span class="keyword">var</span> offsets = <span class="type">Map</span>[<span class="type">TopicAndPartition</span>, <span class="type">Long</span>]()</span><br><span class="line">    line = reader.readLine()</span><br><span class="line">    <span class="keyword">while</span>(line != <span class="literal">null</span>) &#123;</span><br><span class="line">        <span class="keyword">val</span> pieces = line.split(<span class="string">"\\s+"</span>)              </span><br><span class="line">        <span class="keyword">val</span> topic = pieces(<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">val</span> partition = pieces(<span class="number">1</span>).toInt</span><br><span class="line">        <span class="keyword">val</span> offset = pieces(<span class="number">2</span>).toLong</span><br><span class="line">        offsets += (<span class="type">TopicAndPartition</span>(topic, partition) -&gt; offset)</span><br><span class="line">        line = reader.readLine()</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>ReplicaManager是在<code>becomeLeaderOrFollower</code>调度Checkpoint的写入,这个线程是定时运行的,确保HW是最新的.  </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">val</span> highWatermarkCheckPointThreadStarted = <span class="keyword">new</span> <span class="type">AtomicBoolean</span>(<span class="literal">false</span>)   <span class="comment">// 原子变量,确保只有一个线程刷写checkpoint文件</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">val</span> allPartitions = <span class="keyword">new</span> <span class="type">Pool</span>[(<span class="type">String</span>, <span class="type">Int</span>), <span class="type">Partition</span>]                <span class="comment">// 所有的Partitions</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">startHighWaterMarksCheckPointThread</span>(</span>) = &#123;</span><br><span class="line">  <span class="keyword">if</span>(highWatermarkCheckPointThreadStarted.compareAndSet(<span class="literal">false</span>, <span class="literal">true</span>))</span><br><span class="line">    scheduler.schedule(<span class="string">"highwatermark-checkpoint"</span>, checkpointHighWatermarks, period = config.replicaHighWatermarkCheckpointIntervalMs, unit = <span class="type">TimeUnit</span>.<span class="type">MILLISECONDS</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Flushes the highwatermark value for all partitions to the highwatermark file 把所有Partitions的HW值刷写到文件中</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">checkpointHighWatermarks</span>(</span>) &#123;</span><br><span class="line">  <span class="keyword">val</span> replicas = allPartitions.values.map(_.getReplica(config.brokerId)).collect&#123;<span class="keyword">case</span> <span class="type">Some</span>(replica) =&gt; replica&#125;</span><br><span class="line">  <span class="keyword">val</span> replicasByDir = replicas.filter(_.log.isDefined).groupBy(_.log.get.dir.getParentFile.getAbsolutePath)</span><br><span class="line">  <span class="keyword">for</span>((dir, reps) &lt;- replicasByDir) &#123;</span><br><span class="line">    <span class="keyword">val</span> hwms = reps.map(r =&gt; (<span class="keyword">new</span> <span class="type">TopicAndPartition</span>(r) -&gt; r.highWatermark.messageOffset)).toMap</span><br><span class="line">    highWatermarkCheckpoints(dir).write(hwms)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如何根据Partition得到offset: Partition-&gt;Replica-&gt;LogOffsetMetadata-&gt;messageOffset.  </p>
<ul>
<li>找出所有的Partitions,获取其Replica,确保有Replica的Partition</li>
<li>根据log.dirs重新分组(确保有Log), 每个log.dirs对应了replicas列表</li>
<li>对每个log.dirs, 循环replicas, 转换成TopicAndPartition到HW的映射</li>
<li>最终往每个log.dirs写入了属于这个dir的TopicAndPartition-&gt;offset信息</li>
</ul>
<blockquote>
<p>问:HW是由Leader更新的,Broker节点存储的并不都是Leader Partitions,在做checkpoint时是只对Leader Partition做吗?<br>答:不是的,ReplicaManager是对所有Partitions做checkpoint的.虽然只有Leader更新HW,但是Leader也会将HW广播给follower的.<br>当follower向leader fetch request的时候,leader会把hw也传给follower,这样follower也有了hw信息. 这样同一个Partition的<br>所有Replica都有了hw信息.目的是即使Leader挂掉了,这个hw仍然会保留在其他Replica上,其他replica成为leader后,hw也不会丢失.  </p>
<p>问:Replica的highWatermark_=方法不是只有Leader才能调用吗(isLocal),那么leader广播给follower的hw是如何被更新的?  </p>
</blockquote>
<h3 id="allPartitions">allPartitions</h3><p>allPartitions被放入也是在<code>becomeLeaderOrFollower</code>中.这说明一个Partition在Leader和follower转换时是要做很多工作的.  </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getOrCreatePartition</span>(</span>topic: <span class="type">String</span>, partitionId: <span class="type">Int</span>): <span class="type">Partition</span> = &#123;</span><br><span class="line">  <span class="keyword">var</span> partition = allPartitions.get((topic, partitionId))</span><br><span class="line">  <span class="keyword">if</span> (partition == <span class="literal">null</span>) &#123;</span><br><span class="line">    allPartitions.putIfNotExists((topic, partitionId), <span class="keyword">new</span> <span class="type">Partition</span>(topic, partitionId, time, <span class="keyword">this</span>))</span><br><span class="line">    partition = allPartitions.get((topic, partitionId))</span><br><span class="line">  &#125;</span><br><span class="line">  partition</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>allPartitions记录的是当前节点的所有Partitions.这些Partitions并不都是Leader.    </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">getLeaderPartitions</span>(</span>) : <span class="type">List</span>[<span class="type">Partition</span>] = &#123;</span><br><span class="line">  allPartitions.values.filter(_.leaderReplicaIfLocal().isDefined).toList</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">maybeShrinkIsr</span>(</span>) &#123;</span><br><span class="line">  allPartitions.values.foreach(_.maybeShrinkIsr(config.replicaLagTimeMaxMs))  <span class="comment">//评估ISR,查看是否有replicas可以从中移除</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>留个坑: becomeLeaderOrFollower的调用以及ISR收缩时对HW的影响.  </p>
</blockquote>
<h3 id="ReplicaManager-appendMessages">ReplicaManager.appendMessages</h3><p>在Log.append之后,需要通知follower获取这些新的消息.因为现在Leader的LEO已经更新了,follower需要及时获取落后的消息<br>如果Partition的ISR只有1个,说明没有其他Replication,则Leader的LEO更新后,其HW也要也要一起更新(当然这是特殊情况)  </p>
<p><img src="http://img.blog.csdn.net/20160114094002808" alt="k_hw_leo"></p>
<p>为了更方便地查看在append之后的操作,我把相关的代码都列在一起了.之前分析过的就省略了.  </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">appendToLocalLog</span>(</span>internalTopicsAllowed: <span class="type">Boolean</span>,...)&#123;</span><br><span class="line">  <span class="keyword">val</span> (info, leaderHWIncremented) = inReadLock(leaderIsrUpdateLock) &#123;</span><br><span class="line">        <span class="comment">// ① 写到Partition的Leader的那个Log</span></span><br><span class="line">        <span class="keyword">val</span> log = leaderReplica.log.get       </span><br><span class="line">        <span class="keyword">val</span> info = log.append(messages, assignOffsets = <span class="literal">true</span>)</span><br><span class="line">        <span class="comment">// ② probably unblock some follower fetch requests since log end offset has been updated</span></span><br><span class="line">        replicaManager.tryCompleteDelayedFetch(<span class="keyword">new</span> <span class="type">TopicPartitionOperationKey</span>(<span class="keyword">this</span>.topic, <span class="keyword">this</span>.partitionId))</span><br><span class="line">        <span class="comment">// ③ we may need to increment high watermark since ISR could be down to 1</span></span><br><span class="line">        (info, maybeIncrementLeaderHW(leaderReplica))</span><br><span class="line">  &#125;     </span><br><span class="line">  <span class="comment">// some delayed operations may be unblocked after HW changed </span></span><br><span class="line">  <span class="comment">// ④ 如果HW改变了,则一些延迟的请求(针对消费者)需要被解锁.当然如果HW没有变化,就不需要通知了</span></span><br><span class="line">  <span class="keyword">if</span> (leaderHWIncremented) tryCompleteDelayedRequests()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">appendMessages</span>(</span>timeout: <span class="type">Long</span>, ... )&#123;</span><br><span class="line">    <span class="keyword">val</span> localProduceResults = appendToLocalLog(internalTopicsAllowed, messagesPerPartition, requiredAcks)</span><br><span class="line">    <span class="keyword">val</span> produceStatus = localProduceResults.map &#123; <span class="keyword">case</span> (topicAndPartition, result) =&gt;</span><br><span class="line">      topicAndPartition -&gt; <span class="type">ProducePartitionStatus</span>(result.info.lastOffset + <span class="number">1</span>, <span class="type">ProducerResponseStatus</span>(result.errorCode, result.info.firstOffset)) <span class="comment">// required offset, response status</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (delayedRequestRequired(requiredAcks, messagesPerPartition, localProduceResults)) &#123;</span><br><span class="line">      <span class="comment">// ⑤ create delayed produce operation 创建延迟的Produce操作</span></span><br><span class="line">      <span class="keyword">val</span> produceMetadata = <span class="type">ProduceMetadata</span>(requiredAcks, produceStatus)</span><br><span class="line">      <span class="keyword">val</span> delayedProduce = <span class="keyword">new</span> <span class="type">DelayedProduce</span>(timeout, produceMetadata, <span class="keyword">this</span>, responseCallback)</span><br><span class="line">      <span class="comment">// create a list of (topic, partition) pairs to use as keys for this delayed produce operation</span></span><br><span class="line">      <span class="keyword">val</span> producerRequestKeys = messagesPerPartition.keys.map(<span class="keyword">new</span> <span class="type">TopicPartitionOperationKey</span>(_)).toSeq</span><br><span class="line">      <span class="comment">// ⑥ try to complete the request immediately, otherwise put it into the purgatory 尝试立即完成请求,否则放入十八层地狱中炼狱一番</span></span><br><span class="line">      <span class="comment">// this is because while the delayed produce operation is being created, new requests may arrive and hence make this operation completable.</span></span><br><span class="line">      delayedProducePurgatory.tryCompleteElseWatch(delayedProduce, producerRequestKeys)</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// we can respond immediately</span></span><br><span class="line">      <span class="keyword">val</span> produceResponseStatus = produceStatus.mapValues(status =&gt; status.responseStatus)</span><br><span class="line">      responseCallback(produceResponseStatus)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>满足下面的所有条件时,将会产生一个延迟的Produce请求,并且等待replication完成:  </p>
<ul>
<li>required acks = -1 : Producer需要等待所有ISR接收数据</li>
<li>there is data to append : 有数据</li>
<li>at least one partition append was successful (fewer errors than partitions) 至少一个Partition追加成功</li>
</ul>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">delayedRequestRequired</span>(</span>requiredAcks: <span class="type">Short</span>, messagesPerPartition: <span class="type">Map</span>[<span class="type">TopicAndPartition</span>, <span class="type">MessageSet</span>], localProduceResults: <span class="type">Map</span>[<span class="type">TopicAndPartition</span>, <span class="type">LogAppendResult</span>]): <span class="type">Boolean</span> = &#123;</span><br><span class="line">  requiredAcks == -<span class="number">1</span> &amp;&amp; messagesPerPartition.size &gt; <span class="number">0</span> &amp;&amp; localProduceResults.values.count(_.error.isDefined) &lt; messagesPerPartition.size</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Producer端的request.required.acks配置项,用来控制什么时候返回响应给客户端:  </p>
<table>
<thead>
<tr>
<th>acks</th>
<th>what happen</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>The producer never waits for an ack</td>
</tr>
<tr>
<td>1</td>
<td>The producer gets an ack after the leader replica has received the data</td>
</tr>
<tr>
<td>-1</td>
<td>The producer gets an ack after all ISRs receive the data</td>
</tr>
</tbody>
</table>
<h4 id="DelayedOperationPurgatory">DelayedOperationPurgatory</h4><p>上面出现了三个tryCompleteXXX(Fetch,Request,ElseWath)都是交给DelayedOperationPurgatory炼狱工厂.  </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ReplicaManager</span>:</span>  </span><br><span class="line">  <span class="keyword">val</span> delayedProducePurgatory = <span class="keyword">new</span> <span class="type">DelayedOperationPurgatory</span>[<span class="type">DelayedProduce</span>](purgatoryName = <span class="string">"Produce"</span>, config.brokerId, config.producerPurgatoryPurgeIntervalRequests)</span><br><span class="line">  <span class="keyword">val</span> delayedFetchPurgatory = <span class="keyword">new</span> <span class="type">DelayedOperationPurgatory</span>[<span class="type">DelayedFetch</span>](purgatoryName = <span class="string">"Fetch"</span>, config.brokerId, config.fetchPurgatoryPurgeIntervalRequests)</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">tryCompleteDelayedFetch</span>(</span>key: <span class="type">DelayedOperationKey</span>)   &#123; <span class="keyword">val</span> completed = delayedFetchPurgatory.checkAndComplete(key) &#125;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">tryCompleteDelayedProduce</span>(</span>key: <span class="type">DelayedOperationKey</span>) &#123; <span class="keyword">val</span> completed = delayedProducePurgatory.checkAndComplete(key) &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// A helper purgatory class for bookkeeping delayed operations with a timeout, and expiring timed out operations.</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DelayedOperationPurgatory</span>[</span><span class="type">T</span> &lt;: <span class="type">DelayedOperation</span>](purgatoryName: <span class="type">String</span>, brokerId: <span class="type">Int</span> = <span class="number">0</span>, purgeInterval: <span class="type">Int</span> = <span class="number">1000</span>)</span><br></pre></td></tr></table></figure>
<p>尝试完成<code>延迟的fetch</code>请求的触发条件:  </p>
<ul>
<li><code>Partition的HW发生变化</code> (正常的fetch–即consumer的fetch,因为HW是针对消费者而言,消费者最多只能到HW)</li>
<li>新的MessageSet追加到本地日志 (follower的fetch, 新的MessageSet有新的LEO, 而follower是跟踪LEO的)</li>
</ul>
<p>尝试完成<code>延迟的Producer</code>的触发条件:  </p>
<ul>
<li><code>Partition的HW发生变化</code> (对于acks=-1的情况)</li>
<li>收到了一个follower副本的fetch操作 (对于acks&gt;1的情况)</li>
</ul>
<blockquote>
<p>问题: DelayedOperationPurgatory的checkAndComplete方法肯定需要用到类型参数即DelayedOperation的子类.<br>但是以DelayedProduce为例,他是在ReplicationManager的appendToLocalLog之后才被创建的.<br>那么在appendToLocalLog中的tryCompleteDelayedXXX是不是因为没有真正创建DelayedProduce,而不会起作用?</p>
</blockquote>
<p>appendMessages中<code>delayed produce operation</code>是怎么一步一步堕落到十八层地狱的:  </p>
<figure class="highlight livescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">localProduceResults<span class="function"> -&gt;</span> <span class="function"><span class="params">(TopicAndPartition,LogAppendResult)</span> -&gt;</span> ProducePartitionStatus<span class="function"> -&gt;</span> ProduceMetadata<span class="function"> -&gt;</span> DelayedProduce</span><br><span class="line">本地(Leader)的生产结果<span class="function"> -&gt;</span>           日志追加结果<span class="function">               -&gt;</span> Produce的Partition状态<span class="function">  -&gt;</span> Produce的元数据<span class="function">  -&gt;</span> 延迟的Produce操作</span><br></pre></td></tr></table></figure>
<h4 id="DelayedOperation">DelayedOperation</h4><blockquote>
<p>An operation whose processing needs to be delayed for at most the given delayMs. For example<br>a delayed produce operation could be waiting for specified number of acks; or<br>delayed fetch operation could be waiting for a given number of bytes to accumulate.<br>一个操作的处理需要被延迟执行,但是最多只能延迟给定的delayMs时间. 比如<br>一个延迟的消息生产操作可能需要等待指定数量的acks(写到leader后,等待所有的ISR返回ack,leader再ack给客户端)<br>一个延迟的消息读取操作可能需要等待累积到指定数量的字节(并不是leader增加了一点hw,consumer就立即获取一丁点的数据)</p>
<p>The logic upon completing a delayed operation is defined in onComplete() and will be called exactly once.<br>Once an operation is completed, isCompleted() will return true. onComplete() can be triggered by either<br>forceComplete(), which forces calling onComplete() after delayMs if the operation is not yet completed,or<br>tryComplete(), which first checks if the operation can be completed by now, and if yes calls forceComplete().<br>完成一个延迟的操作定义在onComplete中,并且只会被调用一次.一旦一个操作完成了,isCompleted返回true.onComplete()被触发的条件:<br>forceComplete: 如果这个操作在过了delayMs后还没有完成,会强制调用onComplete.<br>tryComplete: 首先检查这个操作是否可以完成,如果可以完成,就调用forceComplete.  </p>
</blockquote>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">DelayedOperation</span>(</span>delayMs: <span class="type">Long</span>) <span class="keyword">extends</span> <span class="type">TimerTask</span> <span class="keyword">with</span> <span class="type">Logging</span> &#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="keyword">val</span> expirationMs = delayMs + <span class="type">System</span>.currentTimeMillis()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="IncrementLeaderHW">IncrementLeaderHW</h4><p>(可能)增加Partition的Hight Watermark(HW)的触发条件:  </p>
<ul>
<li><code>Partition的ISR发生变化</code> (假设某个很慢的节点落后很多从ISR中移除,而其他节点大部分都catch-up,就可以更新HW)</li>
<li>任何Replication的LEO(LogEndOffset)发生变化 (ISR中的follower节点有任何一个节点的LEO改变,看看所有ISR是否都复制了,也可以更新HW)</li>
</ul>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">maybeIncrementLeaderHW</span>(</span>leaderReplica: <span class="type">Replica</span>): <span class="type">Boolean</span> = &#123;</span><br><span class="line">  <span class="comment">// 所有inSync副本中最小的HW(因为每个follower的hw都可能不一样), 表示的是最新的hw</span></span><br><span class="line">  <span class="keyword">val</span> allLogEndOffsets = inSyncReplicas.map(_.logEndOffset)</span><br><span class="line">  <span class="keyword">val</span> newHighWatermark = allLogEndOffsets.min(<span class="keyword">new</span> <span class="type">LogOffsetMetadata</span>.<span class="type">OffsetOrdering</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Leader本身的hw, 是旧的</span></span><br><span class="line">  <span class="keyword">val</span> oldHighWatermark = leaderReplica.highWatermark  <span class="comment">// 是一个LogOffsetMetadata</span></span><br><span class="line">  <span class="keyword">if</span>(oldHighWatermark.precedes(newHighWatermark)) &#123;   <span class="comment">// 比较Leader的messageOffset是否小于ISR的</span></span><br><span class="line">    leaderReplica.highWatermark = newHighWatermark    <span class="comment">// Leader小于ISR, 更新Leader为ISR中最小的</span></span><br><span class="line">    <span class="literal">true</span>      </span><br><span class="line">  &#125;<span class="keyword">else</span> <span class="literal">false</span>     <span class="comment">// Returns true if the HW was incremented, and false otherwise.</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>leaderReplica是Partition的Leader副本,一个Partition只有一个Leader,读写都发生在Leader上</li>
<li>inSyncReplicas是Partition的follower中追赶上Leader的副本(并不是所有Follower都是InSync)</li>
</ul>
<p>在Log中append的updateLogEndOffset(LogAppendInfo.lastOffset+1)更新的是LogOffsetMetadata的messageOffset<br>而这里的oldHighWatermark和newHighWatermark也都是LogOffsetMetadata(最重要的就是messageOffset字段了)!<br>所以实际比较的是两个LogOffsetMetadata的messageOffset, 只有Leader的HW小于ISR,才需要更新Leader的HW.  </p>
<blockquote>
<p>HW表示的是所有ISR中的节点都已经复制完的消息.也是消费者所能获取到的消息的最大offset,所以叫做high watermark.  </p>
</blockquote>
<h2 id="Ref">Ref</h2><ul>
<li><a href="http://www.jasongj.com/2015/04/24/KafkaColumn2/" target="_blank" rel="external">http://www.jasongj.com/2015/04/24/KafkaColumn2/</a></li>
<li><a href="https://cwiki.apache.org/confluence/display/KAFKA/Kafka+Replication" target="_blank" rel="external">https://cwiki.apache.org/confluence/display/KAFKA/Kafka+Replication</a></li>
</ul>

      
    </div>
    
  </div>
  
    
<div class="copyright">
  <p><span>本文标题:</span><a href="/2016/01/14/2016-01-14-Kafka-ISR/">Kafka源码分析 ISR</a></p>
  <p><span>文章作者:</span><a href="/" title="访问 任何忧伤,都抵不过世界的美丽 的个人博客">任何忧伤,都抵不过世界的美丽</a></p>
  <p><span>发布时间:</span>2016年01月14日 - 00时00分</p>
  <p><span>最后更新:</span>2016年01月14日 - 23时43分</p>
  <p>
    <span>原始链接:</span><a href="/2016/01/14/2016-01-14-Kafka-ISR/" title="Kafka源码分析 ISR">http://github.com/zqhxuyuan/2016/01/14/2016-01-14-Kafka-ISR/</a>
    <span class="btn" data-clipboard-text="原文: http://github.com/zqhxuyuan/2016/01/14/2016-01-14-Kafka-ISR/　　作者: 任何忧伤,都抵不过世界的美丽" title="点击复制文章链接">
        <i class="fa fa-clipboard"></i>
    </span>
  </p>
  <p><span>许可协议:</span><i class="fa fa-creative-commons"></i> <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/3.0/cn/" title="中国大陆 (CC BY-NC-SA 3.0 CN)">"署名-非商用-相同方式共享 3.0"</a> 转载请保留原文链接及作者。</p>
  <script src="/js/clipboard.min.js"></script>
  <script> var clipboard = new Clipboard('.btn'); </script>
</div>
<style type="text/css">
  .copyright p .btn {
    margin-left: 1em;
  }
  .copyright:hover p .btn::after {
    content: "复制"
  }
  .copyright p .btn:hover {
      color: gray;
      cursor: pointer;
    };
</style>



<nav id="article-nav">
  
  
    <div id="article-nav-older" class="article-nav-title">
      <a href="/2016/01/13/2016-01-13-Kafka-Picture/">
        Kafka图文详解
      </a>
    </div>
  
</nav>

  
</article>

<!-- 默认显示文章目录，在文章---前输入toc: false关闭目录 -->
<!-- Show TOC and tocButton in default, Hide TOC via putting "toc: false" before "---" at [post].md -->
<div id="toc" class="toc-article">
<strong class="toc-title">文章目录</strong>
<ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Kafka_Replication"><span class="toc-number">1.</span> <span class="toc-text">Kafka Replication</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Replica"><span class="toc-number">2.</span> <span class="toc-text">Replica</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#OffsetCheckpoint"><span class="toc-number">2.1.</span> <span class="toc-text">OffsetCheckpoint</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#allPartitions"><span class="toc-number">2.2.</span> <span class="toc-text">allPartitions</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#ReplicaManager-appendMessages"><span class="toc-number">2.3.</span> <span class="toc-text">ReplicaManager.appendMessages</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#DelayedOperationPurgatory"><span class="toc-number">2.3.1.</span> <span class="toc-text">DelayedOperationPurgatory</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#DelayedOperation"><span class="toc-number">2.3.2.</span> <span class="toc-text">DelayedOperation</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#IncrementLeaderHW"><span class="toc-number">2.3.3.</span> <span class="toc-text">IncrementLeaderHW</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Ref"><span class="toc-number">3.</span> <span class="toc-text">Ref</span></a></li></ol>
</div>
<style type="text/css">
  .left-col .switch-btn {
    display: none;
  }
  .left-col .switch-area {
    display: none;
  }
</style>

<input type="button" id="tocButton" value="隐藏目录"  title="点击按钮隐藏或者显示文章目录">
<script type="text/javascript">
  var toc_button= document.getElementById("tocButton");
  var toc_div= document.getElementById("toc");
  /* Show or hide toc when click on tocButton.
  通过点击设置的按钮显示或者隐藏文章目录.*/
  toc_button.onclick=function(){
  if(toc_div.style.display=="none"){
  toc_div.style.display="block";
  toc_button.value="隐藏目录";
  document.getElementById("switch-btn").style.display="none";
  document.getElementById("switch-area").style.display="none";
  }
  else{
  toc_div.style.display="none";
  toc_button.value="显示目录";
  document.getElementById("switch-btn").style.display="block";
  document.getElementById("switch-area").style.display="block";
  }
  }
    if ($(".toc").length < 1) {
        $("#toc").css("display","none");
        $("#tocButton").css("display","none");
        $(".switch-btn").css("display","block");
        $(".switch-area").css("display","block");
    }
</script>


    <style>
        .toc {
            white-space: nowrap;
            overflow-x: hidden;
        }
    </style>

    <script>
        $(document).ready(function() {
            $(".toc li a").mouseover(function() {
                var title = $(this).attr('href');
                $(this).attr("title", title);
            });
        })
    </script>




<div class="share">
	<div class="bdsharebuttonbox">
	<a href="#" class="bds_more" data-cmd="more"></a>
	<a href="#" class="bds_tsina" data-cmd="tsina" title="分享到新浪微博"></a>
	<a href="#" class="bds_sqq" data-cmd="sqq" title="分享给 QQ 好友"></a>
	<a href="#" class="bds_copy" data-cmd="copy" title="复制网址"></a>
	<a href="#" class="bds_mail" data-cmd="mail" title="通过邮件分享"></a>
	<a href="#" class="bds_weixin" data-cmd="weixin" title="生成文章二维码"></a>
	</div>
	<script>
	window._bd_share_config={
		"common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"0","bdSize":"24"},"share":{}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];
	</script>
</div>







    <style type="text/css">
    #scroll {
      display: none;
    }
    </style>
    <div class="scroll">
    <a href="#" title="返回顶部"><i class="fa fa-arrow-up"></i></a>
    <a href="#comments" title="查看评论"><i class="fa fa-comments-o"></i></a>
    <a href="#footer" title="转到底部"><i class="fa fa-arrow-down"></i></a>
    </div>


  
  
    <div  class="post-nav-button">
    <a href="/" title="回到主页"><i class="fa fa-home"></i></a>
    <a href="/2016/01/13/2016-01-13-Kafka-Picture/" title="下一篇: Kafka图文详解">
    <i class="fa fa-angle-right"></i>
    </a>
    </div>
  
    



    
        <link rel="stylesheet" href="/fancybox/jquery.fancybox.css" type="text/css">
        <script>
        var yiliaConfig = {
        fancybox: true,
        mathjax: true,
        animate: true,
        isHome: false,
        isPost: true,
        isArchive: false,
        isTag: false,
        isCategory: false,
        open_in_new: false
        }
        </script>
        
</div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
      <div class="footer-left">
        &copy; 2016 任何忧伤,都抵不过世界的美丽
      </div>
        <div class="footer-right">
          <a href="http://hexo.io/" target="_blank" title="快速、简洁且高效的静态博客框架">Hexo</a>  Theme <a href="https://github.com/MOxFIVE/hexo-theme-yelee" target="_blank" title="简而不减双栏 Hexo 博客主题">Yelee</a> by MOxFIVE
        </div>
    </div>
    <div class="visit">
      <span id="busuanzi_container_site_pv" style='display:none'>
        <span id="site-visit" >本站到访数: 
        <span id="busuanzi_value_site_uv"></span>
        </span>
      </span>
      <span id="busuanzi_container_page_pv" style='display:none'>
        <span id="page-visit">, 本页阅读量: 
        <span id="busuanzi_value_page_pv"></span>
        </span>
      </span>
    </div>
  </div>
</footer>
    </div>
    

<script src="http://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js" type="text/javascript"></script>
<script src="/js/main.js" type="text/javascript"></script>

<script>
  var backgroundnum = 5;
  var backgroundimg = "url(/background/bg-x.jpg)".replace(/x/gi, Math.ceil(Math.random() * backgroundnum));

  $("body").css({"background": backgroundimg, "background-attachment": "fixed", "background-size": "cover"});
</script>




<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<div class="scroll" id="scroll">
<a href="#" title="返回顶部"><i class="fa fa-arrow-up"></i></a>
<a href="#footer" title="转到底部"><i class="fa fa-arrow-down"></i></a>
</div>

<script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>
  </div>
</body>
</html>